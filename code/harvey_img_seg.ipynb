{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE SEGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K1qeXTk22P5G"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import datetime\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the available CPU and GPU devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the path to train images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3UlFrQCxtyko"
   },
   "outputs": [],
   "source": [
    "train_x_loc = \"../data/train_images/\"\n",
    "train_y_loc = \"../data/train_masks/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the names of the image files and sort and store them in a list. This will later be iterated over to read and store the image and mask data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ahdPNGncxMTj"
   },
   "outputs": [],
   "source": [
    "img_names = [s[:-4] for s in os.listdir(train_x_loc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prevent clogging up the RAM, we will create batches of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images were split into batches of size 100.\n",
      "Number of batches =  3\n"
     ]
    }
   ],
   "source": [
    "img_names_batches = [img_names[i:i + TRAIN_BATCH_SIZE] for i in range(0, len(img_names), TRAIN_BATCH_SIZE)]\n",
    "print(\"Train images were split into batches of size {}.\".format(TRAIN_BATCH_SIZE))\n",
    "print(\"Number of batches = \",len(img_names_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 512\n",
    "N_CHANNEL = 3\n",
    "N_CLASSES = 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "    inputs = Input((INPUT_SIZE, INPUT_SIZE, N_CHANNEL))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    drop1 = Dropout(0.2)(pool1) # Dropout(0.2)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    drop2 = Dropout(0.2)(pool2) #Dropout(0.2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    drop3 = Dropout(0.2)(pool3) \n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    drop4 = Dropout(0.2)(pool4) # Dropout(0.2)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(N_CLASSES, (1, 1), activation=\"softmax\")(conv9) #\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In semantic segmentation, you need as many masks as you have object classes. \n",
    "In our dataset, each pixel in every mask has been assigned a single integer probability that it belongs to a \n",
    "certain class - 0 to 26. The correct class is the one with the highest probability. \n",
    "\n",
    "Sparse categorical crossentropy is more efficient than other loss functions when you're dealing with \n",
    "lots of classes and to perform pixel-wise multiclass prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating CallBacks\n",
    "\n",
    "A callback is an object that can perform actions at various stages of training (e.g. at the start or end of an epoch, before or after a single batch, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard visuluaziations\n",
    "# To visualize, execute the following commands in a new jupyter notebook:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /tmp/tboard_logs8\n",
    "tensorboard = TensorBoard(log_dir='/tmp/tboard_logs8', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "  def on_train_batch_begin(self, batch, logs=None):\n",
    "    print('\\nTraining: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    print('\\nTraining: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "  def on_test_batch_begin(self, batch, logs=None):\n",
    "    print('\\nEvaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "  def on_test_batch_end(self, batch, logs=None):\n",
    "    print('\\nEvaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_names_batches = [img_names_batches[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "print(len(img_names_batches[0]))\n",
    "print(len(img_names_batches[1]))\n",
    "print(len(img_names_batches[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " EPACHS set to  35\n",
      "No model set. Creating new model.\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 14:44:34.720799: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-08 14:44:34.720941: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet model created from scratch\n",
      "Reading train data\n",
      "x train ----  90\n",
      "x val ----  10\n",
      "Train and Validation data created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 14:44:52.455458: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\n",
      "Training: batch 0 begins at 14:44:52.465432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 14:44:52.798527: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: batch 0 ends at 14:44:54.890181\n",
      " 1/18 [>.............................] - ETA: 41s - loss: 3.2037 - accuracy: 0.0703\n",
      "Training: batch 1 begins at 14:44:54.909829\n",
      "\n",
      "Training: batch 1 ends at 14:44:56.513972\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 4.3631 - accuracy: 0.1129\n",
      "Training: batch 2 begins at 14:44:56.515270\n",
      "\n",
      "Training: batch 2 ends at 14:44:58.136202\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 3.9715 - accuracy: 0.1273\n",
      "Training: batch 3 begins at 14:44:58.137156\n",
      "\n",
      "Training: batch 3 ends at 14:44:59.739699\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 3.7609 - accuracy: 0.1273\n",
      "Training: batch 4 begins at 14:44:59.740683\n",
      "\n",
      "Training: batch 4 ends at 14:45:01.303258\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 3.6309 - accuracy: 0.1298\n",
      "Training: batch 5 begins at 14:45:01.304197\n",
      "\n",
      "Training: batch 5 ends at 14:45:02.918449\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 3.5468 - accuracy: 0.1288\n",
      "Training: batch 6 begins at 14:45:02.919455\n",
      "\n",
      "Training: batch 6 ends at 14:45:04.573937\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 3.4673 - accuracy: 0.1513\n",
      "Training: batch 7 begins at 14:45:04.574971\n",
      "\n",
      "Training: batch 7 ends at 14:45:06.196011\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 3.4091 - accuracy: 0.1645\n",
      "Training: batch 8 begins at 14:45:06.197386\n",
      "\n",
      "Training: batch 8 ends at 14:45:07.813246\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 3.3437 - accuracy: 0.1847\n",
      "Training: batch 9 begins at 14:45:07.814186\n",
      "\n",
      "Training: batch 9 ends at 14:45:09.415561\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 3.3228 - accuracy: 0.1847\n",
      "Training: batch 10 begins at 14:45:09.417113\n",
      "\n",
      "Training: batch 10 ends at 14:45:11.029778\n",
      "11/18 [=================>............] - ETA: 11s - loss: 3.2792 - accuracy: 0.1914\n",
      "Training: batch 11 begins at 14:45:11.030723\n",
      "\n",
      "Training: batch 11 ends at 14:45:12.592769\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 3.2549 - accuracy: 0.1964 \n",
      "Training: batch 12 begins at 14:45:12.593697\n",
      "\n",
      "Training: batch 12 ends at 14:45:14.190063\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 3.2313 - accuracy: 0.2039\n",
      "Training: batch 13 begins at 14:45:14.190956\n",
      "\n",
      "Training: batch 13 ends at 14:45:15.811093\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 3.1967 - accuracy: 0.2056\n",
      "Training: batch 14 begins at 14:45:15.812039\n",
      "\n",
      "Training: batch 14 ends at 14:45:17.399694\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 3.1712 - accuracy: 0.2088\n",
      "Training: batch 15 begins at 14:45:17.400878\n",
      "\n",
      "Training: batch 15 ends at 14:45:18.976851\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 3.1483 - accuracy: 0.2074\n",
      "Training: batch 16 begins at 14:45:18.977819\n",
      "\n",
      "Training: batch 16 ends at 14:45:20.571643\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 3.1163 - accuracy: 0.2127\n",
      "Training: batch 17 begins at 14:45:20.574257\n",
      "\n",
      "Training: batch 17 ends at 14:45:22.162414\n",
      "18/18 [==============================] - ETA: 0s - loss: 3.0794 - accuracy: 0.2169\n",
      "Evaluating: batch 0 begins at 14:45:22.284675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 14:45:22.374276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: batch 0 ends at 14:45:22.928249\n",
      "\n",
      "Evaluating: batch 1 begins at 14:45:22.928748\n",
      "\n",
      "Evaluating: batch 1 ends at 14:45:23.398501\n",
      "18/18 [==============================] - 31s 2s/step - loss: 3.0794 - accuracy: 0.2169 - val_loss: 2.2777 - val_accuracy: 0.3028\n",
      "Epoch 2/35\n",
      "\n",
      "Training: batch 0 begins at 14:45:23.408002\n",
      "\n",
      "Training: batch 0 ends at 14:45:24.996054\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 2.5636 - accuracy: 0.2301\n",
      "Training: batch 1 begins at 14:45:24.997053\n",
      "\n",
      "Training: batch 1 ends at 14:45:26.568486\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 2.4149 - accuracy: 0.2722\n",
      "Training: batch 2 begins at 14:45:26.569465\n",
      "\n",
      "Training: batch 2 ends at 14:45:28.180483\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 2.4923 - accuracy: 0.2442\n",
      "Training: batch 3 begins at 14:45:28.181463\n",
      "\n",
      "Training: batch 3 ends at 14:45:29.776717\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 2.4455 - accuracy: 0.2435\n",
      "Training: batch 4 begins at 14:45:29.777799\n",
      "\n",
      "Training: batch 4 ends at 14:45:31.371195\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 2.4425 - accuracy: 0.2371\n",
      "Training: batch 5 begins at 14:45:31.372170\n",
      "\n",
      "Training: batch 5 ends at 14:45:32.949585\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 2.4425 - accuracy: 0.2437\n",
      "Training: batch 6 begins at 14:45:32.950451\n",
      "\n",
      "Training: batch 6 ends at 14:45:34.526745\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 2.4516 - accuracy: 0.2390\n",
      "Training: batch 7 begins at 14:45:34.527779\n",
      "\n",
      "Training: batch 7 ends at 14:45:36.128024\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 2.4618 - accuracy: 0.2422\n",
      "Training: batch 8 begins at 14:45:36.129167\n",
      "\n",
      "Training: batch 8 ends at 14:45:37.697903\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 2.4272 - accuracy: 0.2445\n",
      "Training: batch 9 begins at 14:45:37.698909\n",
      "\n",
      "Training: batch 9 ends at 14:45:39.300599\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 2.4236 - accuracy: 0.2462\n",
      "Training: batch 10 begins at 14:45:39.301570\n",
      "\n",
      "Training: batch 10 ends at 14:45:40.891890\n",
      "11/18 [=================>............] - ETA: 11s - loss: 2.4180 - accuracy: 0.2578\n",
      "Training: batch 11 begins at 14:45:40.892796\n",
      "\n",
      "Training: batch 11 ends at 14:45:42.490147\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 2.3963 - accuracy: 0.2575 \n",
      "Training: batch 12 begins at 14:45:42.491225\n",
      "\n",
      "Training: batch 12 ends at 14:45:44.073298\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 2.3889 - accuracy: 0.2573\n",
      "Training: batch 13 begins at 14:45:44.074322\n",
      "\n",
      "Training: batch 13 ends at 14:45:45.641684\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 2.3693 - accuracy: 0.2540\n",
      "Training: batch 14 begins at 14:45:45.642662\n",
      "\n",
      "Training: batch 14 ends at 14:45:47.236875\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 2.3494 - accuracy: 0.2620\n",
      "Training: batch 15 begins at 14:45:47.237817\n",
      "\n",
      "Training: batch 15 ends at 14:45:48.820277\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 2.3366 - accuracy: 0.2578\n",
      "Training: batch 16 begins at 14:45:48.821146\n",
      "\n",
      "Training: batch 16 ends at 14:45:50.406931\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 2.3230 - accuracy: 0.2587\n",
      "Training: batch 17 begins at 14:45:50.408482\n",
      "\n",
      "Training: batch 17 ends at 14:45:52.042602\n",
      "18/18 [==============================] - ETA: 0s - loss: 2.3093 - accuracy: 0.2630\n",
      "Evaluating: batch 0 begins at 14:45:52.053967\n",
      "\n",
      "Evaluating: batch 0 ends at 14:45:52.584240\n",
      "\n",
      "Evaluating: batch 1 begins at 14:45:52.584745\n",
      "\n",
      "Evaluating: batch 1 ends at 14:45:53.059723\n",
      "18/18 [==============================] - 30s 2s/step - loss: 2.3093 - accuracy: 0.2630 - val_loss: 1.9480 - val_accuracy: 0.2981\n",
      "Epoch 3/35\n",
      "\n",
      "Training: batch 0 begins at 14:45:53.069344\n",
      "\n",
      "Training: batch 0 ends at 14:45:54.698899\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 2.0889 - accuracy: 0.2535\n",
      "Training: batch 1 begins at 14:45:54.700196\n",
      "\n",
      "Training: batch 1 ends at 14:45:56.345551\n",
      " 2/18 [==>...........................] - ETA: 26s - loss: 2.1117 - accuracy: 0.2936\n",
      "Training: batch 2 begins at 14:45:56.346562\n",
      "\n",
      "Training: batch 2 ends at 14:45:57.949236\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 2.0949 - accuracy: 0.2748\n",
      "Training: batch 3 begins at 14:45:57.950155\n",
      "\n",
      "Training: batch 3 ends at 14:45:59.541576\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 2.1026 - accuracy: 0.2624\n",
      "Training: batch 4 begins at 14:45:59.542688\n",
      "\n",
      "Training: batch 4 ends at 14:46:01.161494\n",
      " 5/18 [=======>......................] - ETA: 21s - loss: 2.1141 - accuracy: 0.2854\n",
      "Training: batch 5 begins at 14:46:01.162415\n",
      "\n",
      "Training: batch 5 ends at 14:46:02.791266\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 2.1124 - accuracy: 0.2926\n",
      "Training: batch 6 begins at 14:46:02.792244\n",
      "\n",
      "Training: batch 6 ends at 14:46:04.389521\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 2.0777 - accuracy: 0.2946\n",
      "Training: batch 7 begins at 14:46:04.390982\n",
      "\n",
      "Training: batch 7 ends at 14:46:06.095647\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 2.0620 - accuracy: 0.3063\n",
      "Training: batch 8 begins at 14:46:06.096623\n",
      "\n",
      "Training: batch 8 ends at 14:46:07.711138\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 2.0428 - accuracy: 0.3100\n",
      "Training: batch 9 begins at 14:46:07.712416\n",
      "\n",
      "Training: batch 9 ends at 14:46:09.370126\n",
      "10/18 [===============>..............] - ETA: 13s - loss: 2.0632 - accuracy: 0.2956\n",
      "Training: batch 10 begins at 14:46:09.371108\n",
      "\n",
      "Training: batch 10 ends at 14:46:10.968260\n",
      "11/18 [=================>............] - ETA: 11s - loss: 2.0412 - accuracy: 0.3017\n",
      "Training: batch 11 begins at 14:46:10.969174\n",
      "\n",
      "Training: batch 11 ends at 14:46:12.559297\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 2.0331 - accuracy: 0.3067 \n",
      "Training: batch 12 begins at 14:46:12.560265\n",
      "\n",
      "Training: batch 12 ends at 14:46:14.161706\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 2.0347 - accuracy: 0.3034\n",
      "Training: batch 13 begins at 14:46:14.162635\n",
      "\n",
      "Training: batch 13 ends at 14:46:15.776106\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 2.0350 - accuracy: 0.3025\n",
      "Training: batch 14 begins at 14:46:15.777193\n",
      "\n",
      "Training: batch 14 ends at 14:46:17.404506\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 2.0253 - accuracy: 0.2991\n",
      "Training: batch 15 begins at 14:46:17.405538\n",
      "\n",
      "Training: batch 15 ends at 14:46:18.998141\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 2.0354 - accuracy: 0.2950\n",
      "Training: batch 16 begins at 14:46:18.999122\n",
      "\n",
      "Training: batch 16 ends at 14:46:20.591460\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 2.0283 - accuracy: 0.2932\n",
      "Training: batch 17 begins at 14:46:20.592566\n",
      "\n",
      "Training: batch 17 ends at 14:46:22.205987\n",
      "18/18 [==============================] - ETA: 0s - loss: 2.0207 - accuracy: 0.2948\n",
      "Evaluating: batch 0 begins at 14:46:22.217059\n",
      "\n",
      "Evaluating: batch 0 ends at 14:46:22.749852\n",
      "\n",
      "Evaluating: batch 1 begins at 14:46:22.750378\n",
      "\n",
      "Evaluating: batch 1 ends at 14:46:23.225477\n",
      "18/18 [==============================] - 30s 2s/step - loss: 2.0207 - accuracy: 0.2948 - val_loss: 1.7674 - val_accuracy: 0.3107\n",
      "Epoch 4/35\n",
      "\n",
      "Training: batch 0 begins at 14:46:23.235613\n",
      "\n",
      "Training: batch 0 ends at 14:46:24.831683\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.8208 - accuracy: 0.3575\n",
      "Training: batch 1 begins at 14:46:24.832815\n",
      "\n",
      "Training: batch 1 ends at 14:46:26.401085\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.9218 - accuracy: 0.3119\n",
      "Training: batch 2 begins at 14:46:26.402039\n",
      "\n",
      "Training: batch 2 ends at 14:46:27.992771\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.9321 - accuracy: 0.2962\n",
      "Training: batch 3 begins at 14:46:27.993674\n",
      "\n",
      "Training: batch 3 ends at 14:46:29.560998\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.9333 - accuracy: 0.2984\n",
      "Training: batch 4 begins at 14:46:29.561913\n",
      "\n",
      "Training: batch 4 ends at 14:46:31.165147\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.9823 - accuracy: 0.2842\n",
      "Training: batch 5 begins at 14:46:31.166104\n",
      "\n",
      "Training: batch 5 ends at 14:46:32.758578\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.9350 - accuracy: 0.3072\n",
      "Training: batch 6 begins at 14:46:32.759567\n",
      "\n",
      "Training: batch 6 ends at 14:46:34.382139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.9055 - accuracy: 0.3301\n",
      "Training: batch 7 begins at 14:46:34.383258\n",
      "\n",
      "Training: batch 7 ends at 14:46:35.997073\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.8971 - accuracy: 0.3230\n",
      "Training: batch 8 begins at 14:46:35.998072\n",
      "\n",
      "Training: batch 8 ends at 14:46:37.726634\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.8786 - accuracy: 0.3114\n",
      "Training: batch 9 begins at 14:46:37.727537\n",
      "\n",
      "Training: batch 9 ends at 14:46:39.321355\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.8850 - accuracy: 0.3118\n",
      "Training: batch 10 begins at 14:46:39.322294\n",
      "\n",
      "Training: batch 10 ends at 14:46:40.986899\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.8939 - accuracy: 0.3135\n",
      "Training: batch 11 begins at 14:46:40.987973\n",
      "\n",
      "Training: batch 11 ends at 14:46:42.603450\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.8796 - accuracy: 0.3232 \n",
      "Training: batch 12 begins at 14:46:42.604585\n",
      "\n",
      "Training: batch 12 ends at 14:46:44.197970\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.8759 - accuracy: 0.3313\n",
      "Training: batch 13 begins at 14:46:44.198903\n",
      "\n",
      "Training: batch 13 ends at 14:46:45.786694\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.8673 - accuracy: 0.3390\n",
      "Training: batch 14 begins at 14:46:45.787650\n",
      "\n",
      "Training: batch 14 ends at 14:46:47.427637\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.8856 - accuracy: 0.3409\n",
      "Training: batch 15 begins at 14:46:47.428889\n",
      "\n",
      "Training: batch 15 ends at 14:46:49.017356\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.8685 - accuracy: 0.3444\n",
      "Training: batch 16 begins at 14:46:49.018314\n",
      "\n",
      "Training: batch 16 ends at 14:46:50.622227\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.8613 - accuracy: 0.3465\n",
      "Training: batch 17 begins at 14:46:50.623188\n",
      "\n",
      "Training: batch 17 ends at 14:46:52.210165\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.8628 - accuracy: 0.3435\n",
      "Evaluating: batch 0 begins at 14:46:52.220582\n",
      "\n",
      "Evaluating: batch 0 ends at 14:46:52.756047\n",
      "\n",
      "Evaluating: batch 1 begins at 14:46:52.756526\n",
      "\n",
      "Evaluating: batch 1 ends at 14:46:53.227331\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.8628 - accuracy: 0.3435 - val_loss: 1.7259 - val_accuracy: 0.3745\n",
      "Epoch 5/35\n",
      "\n",
      "Training: batch 0 begins at 14:46:53.237219\n",
      "\n",
      "Training: batch 0 ends at 14:46:54.842901\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.8331 - accuracy: 0.3594\n",
      "Training: batch 1 begins at 14:46:54.843776\n",
      "\n",
      "Training: batch 1 ends at 14:46:56.467542\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.7449 - accuracy: 0.4242\n",
      "Training: batch 2 begins at 14:46:56.468494\n",
      "\n",
      "Training: batch 2 ends at 14:46:58.064321\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.8278 - accuracy: 0.3933\n",
      "Training: batch 3 begins at 14:46:58.065339\n",
      "\n",
      "Training: batch 3 ends at 14:46:59.670186\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.8624 - accuracy: 0.3706\n",
      "Training: batch 4 begins at 14:46:59.671179\n",
      "\n",
      "Training: batch 4 ends at 14:47:01.255816\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.8243 - accuracy: 0.3532\n",
      "Training: batch 5 begins at 14:47:01.256815\n",
      "\n",
      "Training: batch 5 ends at 14:47:02.884959\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.7860 - accuracy: 0.3667\n",
      "Training: batch 6 begins at 14:47:02.885924\n",
      "\n",
      "Training: batch 6 ends at 14:47:04.501748\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.7723 - accuracy: 0.3785\n",
      "Training: batch 7 begins at 14:47:04.502775\n",
      "\n",
      "Training: batch 7 ends at 14:47:06.117030\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.8057 - accuracy: 0.3672\n",
      "Training: batch 8 begins at 14:47:06.118182\n",
      "\n",
      "Training: batch 8 ends at 14:47:07.725645\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.8068 - accuracy: 0.3740\n",
      "Training: batch 9 begins at 14:47:07.726569\n",
      "\n",
      "Training: batch 9 ends at 14:47:09.334808\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.7919 - accuracy: 0.3800\n",
      "Training: batch 10 begins at 14:47:09.335934\n",
      "\n",
      "Training: batch 10 ends at 14:47:10.939404\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.8045 - accuracy: 0.3806\n",
      "Training: batch 11 begins at 14:47:10.940322\n",
      "\n",
      "Training: batch 11 ends at 14:47:12.519222\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.7906 - accuracy: 0.3872 \n",
      "Training: batch 12 begins at 14:47:12.520145\n",
      "\n",
      "Training: batch 12 ends at 14:47:14.115504\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.7795 - accuracy: 0.3921\n",
      "Training: batch 13 begins at 14:47:14.116409\n",
      "\n",
      "Training: batch 13 ends at 14:47:15.719046\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.7607 - accuracy: 0.3926\n",
      "Training: batch 14 begins at 14:47:15.719929\n",
      "\n",
      "Training: batch 14 ends at 14:47:17.300549\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.7704 - accuracy: 0.3875\n",
      "Training: batch 15 begins at 14:47:17.301454\n",
      "\n",
      "Training: batch 15 ends at 14:47:18.885327\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.7731 - accuracy: 0.3853\n",
      "Training: batch 16 begins at 14:47:18.886369\n",
      "\n",
      "Training: batch 16 ends at 14:47:20.487492\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.7669 - accuracy: 0.3780\n",
      "Training: batch 17 begins at 14:47:20.488443\n",
      "\n",
      "Training: batch 17 ends at 14:47:22.059952\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.7771 - accuracy: 0.3701\n",
      "Evaluating: batch 0 begins at 14:47:22.070367\n",
      "\n",
      "Evaluating: batch 0 ends at 14:47:22.605931\n",
      "\n",
      "Evaluating: batch 1 begins at 14:47:22.606418\n",
      "\n",
      "Evaluating: batch 1 ends at 14:47:23.081353\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.7771 - accuracy: 0.3701 - val_loss: 1.6496 - val_accuracy: 0.3956\n",
      "Epoch 6/35\n",
      "\n",
      "Training: batch 0 begins at 14:47:23.091015\n",
      "\n",
      "Training: batch 0 ends at 14:47:24.709122\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.6371 - accuracy: 0.3929\n",
      "Training: batch 1 begins at 14:47:24.711000\n",
      "\n",
      "Training: batch 1 ends at 14:47:26.301753\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.7603 - accuracy: 0.3664\n",
      "Training: batch 2 begins at 14:47:26.302846\n",
      "\n",
      "Training: batch 2 ends at 14:47:27.916404\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.7718 - accuracy: 0.3526\n",
      "Training: batch 3 begins at 14:47:27.917413\n",
      "\n",
      "Training: batch 3 ends at 14:47:29.528139\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.7453 - accuracy: 0.3569\n",
      "Training: batch 4 begins at 14:47:29.529104\n",
      "\n",
      "Training: batch 4 ends at 14:47:31.119184\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.7175 - accuracy: 0.3677\n",
      "Training: batch 5 begins at 14:47:31.120193\n",
      "\n",
      "Training: batch 5 ends at 14:47:32.731621\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.7081 - accuracy: 0.3852\n",
      "Training: batch 6 begins at 14:47:32.732600\n",
      "\n",
      "Training: batch 6 ends at 14:47:34.337174\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.6774 - accuracy: 0.4000\n",
      "Training: batch 7 begins at 14:47:34.338101\n",
      "\n",
      "Training: batch 7 ends at 14:47:35.938058\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.6658 - accuracy: 0.4004\n",
      "Training: batch 8 begins at 14:47:35.939074\n",
      "\n",
      "Training: batch 8 ends at 14:47:37.532384\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.6555 - accuracy: 0.4135\n",
      "Training: batch 9 begins at 14:47:37.533296\n",
      "\n",
      "Training: batch 9 ends at 14:47:39.141894\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.6445 - accuracy: 0.4188\n",
      "Training: batch 10 begins at 14:47:39.142908\n",
      "\n",
      "Training: batch 10 ends at 14:47:40.743259\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.6694 - accuracy: 0.4230\n",
      "Training: batch 11 begins at 14:47:40.744260\n",
      "\n",
      "Training: batch 11 ends at 14:47:42.357678\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.6694 - accuracy: 0.4290 \n",
      "Training: batch 12 begins at 14:47:42.358729\n",
      "\n",
      "Training: batch 12 ends at 14:47:43.955843\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.6653 - accuracy: 0.4293\n",
      "Training: batch 13 begins at 14:47:43.957010\n",
      "\n",
      "Training: batch 13 ends at 14:47:45.558568\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.6666 - accuracy: 0.4256\n",
      "Training: batch 14 begins at 14:47:45.559620\n",
      "\n",
      "Training: batch 14 ends at 14:47:47.152244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/18 [========================>.....] - ETA: 4s - loss: 1.6683 - accuracy: 0.4244\n",
      "Training: batch 15 begins at 14:47:47.153404\n",
      "\n",
      "Training: batch 15 ends at 14:47:48.772631\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.6741 - accuracy: 0.4173\n",
      "Training: batch 16 begins at 14:47:48.773555\n",
      "\n",
      "Training: batch 16 ends at 14:47:50.367787\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.6821 - accuracy: 0.4143\n",
      "Training: batch 17 begins at 14:47:50.368942\n",
      "\n",
      "Training: batch 17 ends at 14:47:51.959016\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.6789 - accuracy: 0.4142\n",
      "Evaluating: batch 0 begins at 14:47:51.970342\n",
      "\n",
      "Evaluating: batch 0 ends at 14:47:52.504386\n",
      "\n",
      "Evaluating: batch 1 begins at 14:47:52.505021\n",
      "\n",
      "Evaluating: batch 1 ends at 14:47:52.985392\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.6789 - accuracy: 0.4142 - val_loss: 1.6184 - val_accuracy: 0.4049\n",
      "Epoch 7/35\n",
      "\n",
      "Training: batch 0 begins at 14:47:52.995409\n",
      "\n",
      "Training: batch 0 ends at 14:47:54.619878\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.7082 - accuracy: 0.3563\n",
      "Training: batch 1 begins at 14:47:54.620930\n",
      "\n",
      "Training: batch 1 ends at 14:47:56.214398\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.7765 - accuracy: 0.3631\n",
      "Training: batch 2 begins at 14:47:56.215355\n",
      "\n",
      "Training: batch 2 ends at 14:47:57.816552\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.6687 - accuracy: 0.4187\n",
      "Training: batch 3 begins at 14:47:57.817452\n",
      "\n",
      "Training: batch 3 ends at 14:47:59.416895\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.6416 - accuracy: 0.4277\n",
      "Training: batch 4 begins at 14:47:59.418016\n",
      "\n",
      "Training: batch 4 ends at 14:48:01.022074\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.6338 - accuracy: 0.4403\n",
      "Training: batch 5 begins at 14:48:01.023029\n",
      "\n",
      "Training: batch 5 ends at 14:48:02.635461\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.6739 - accuracy: 0.4334\n",
      "Training: batch 6 begins at 14:48:02.636401\n",
      "\n",
      "Training: batch 6 ends at 14:48:04.234585\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.6459 - accuracy: 0.4390\n",
      "Training: batch 7 begins at 14:48:04.235508\n",
      "\n",
      "Training: batch 7 ends at 14:48:05.862698\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.6458 - accuracy: 0.4372\n",
      "Training: batch 8 begins at 14:48:05.863721\n",
      "\n",
      "Training: batch 8 ends at 14:48:07.461948\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.7010 - accuracy: 0.4316\n",
      "Training: batch 9 begins at 14:48:07.462943\n",
      "\n",
      "Training: batch 9 ends at 14:48:09.037295\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.6899 - accuracy: 0.4205\n",
      "Training: batch 10 begins at 14:48:09.038440\n",
      "\n",
      "Training: batch 10 ends at 14:48:10.629969\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.6919 - accuracy: 0.4202\n",
      "Training: batch 11 begins at 14:48:10.630857\n",
      "\n",
      "Training: batch 11 ends at 14:48:12.211593\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.7077 - accuracy: 0.4158 \n",
      "Training: batch 12 begins at 14:48:12.212565\n",
      "\n",
      "Training: batch 12 ends at 14:48:13.791906\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.7166 - accuracy: 0.4162\n",
      "Training: batch 13 begins at 14:48:13.792867\n",
      "\n",
      "Training: batch 13 ends at 14:48:15.410115\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.7109 - accuracy: 0.4186\n",
      "Training: batch 14 begins at 14:48:15.411104\n",
      "\n",
      "Training: batch 14 ends at 14:48:17.001587\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.7179 - accuracy: 0.4130\n",
      "Training: batch 15 begins at 14:48:17.002553\n",
      "\n",
      "Training: batch 15 ends at 14:48:18.610683\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.7151 - accuracy: 0.4152\n",
      "Training: batch 16 begins at 14:48:18.611647\n",
      "\n",
      "Training: batch 16 ends at 14:48:20.194320\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.7076 - accuracy: 0.4206\n",
      "Training: batch 17 begins at 14:48:20.195370\n",
      "\n",
      "Training: batch 17 ends at 14:48:21.794498\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.6962 - accuracy: 0.4259\n",
      "Evaluating: batch 0 begins at 14:48:21.805152\n",
      "\n",
      "Evaluating: batch 0 ends at 14:48:22.333289\n",
      "\n",
      "Evaluating: batch 1 begins at 14:48:22.333766\n",
      "\n",
      "Evaluating: batch 1 ends at 14:48:22.812362\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.6962 - accuracy: 0.4259 - val_loss: 1.6245 - val_accuracy: 0.3814\n",
      "Epoch 8/35\n",
      "\n",
      "Training: batch 0 begins at 14:48:22.822597\n",
      "\n",
      "Training: batch 0 ends at 14:48:24.419992\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.8769 - accuracy: 0.2773\n",
      "Training: batch 1 begins at 14:48:24.421310\n",
      "\n",
      "Training: batch 1 ends at 14:48:26.020597\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.7195 - accuracy: 0.3091\n",
      "Training: batch 2 begins at 14:48:26.021521\n",
      "\n",
      "Training: batch 2 ends at 14:48:27.620986\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.6560 - accuracy: 0.3711\n",
      "Training: batch 3 begins at 14:48:27.621998\n",
      "\n",
      "Training: batch 3 ends at 14:48:29.197463\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.7131 - accuracy: 0.3651\n",
      "Training: batch 4 begins at 14:48:29.199269\n",
      "\n",
      "Training: batch 4 ends at 14:48:30.830633\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.7234 - accuracy: 0.3744\n",
      "Training: batch 5 begins at 14:48:30.831581\n",
      "\n",
      "Training: batch 5 ends at 14:48:32.436637\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.6606 - accuracy: 0.4003\n",
      "Training: batch 6 begins at 14:48:32.437600\n",
      "\n",
      "Training: batch 6 ends at 14:48:34.024931\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.6559 - accuracy: 0.3971\n",
      "Training: batch 7 begins at 14:48:34.025882\n",
      "\n",
      "Training: batch 7 ends at 14:48:35.627143\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.6225 - accuracy: 0.4173\n",
      "Training: batch 8 begins at 14:48:35.628114\n",
      "\n",
      "Training: batch 8 ends at 14:48:37.226319\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.5995 - accuracy: 0.4273\n",
      "Training: batch 9 begins at 14:48:37.227398\n",
      "\n",
      "Training: batch 9 ends at 14:48:38.861131\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.6173 - accuracy: 0.4295\n",
      "Training: batch 10 begins at 14:48:38.862132\n",
      "\n",
      "Training: batch 10 ends at 14:48:40.476030\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.6639 - accuracy: 0.4281\n",
      "Training: batch 11 begins at 14:48:40.477087\n",
      "\n",
      "Training: batch 11 ends at 14:48:42.072209\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.6710 - accuracy: 0.4250 \n",
      "Training: batch 12 begins at 14:48:42.073182\n",
      "\n",
      "Training: batch 12 ends at 14:48:43.671547\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.6774 - accuracy: 0.4192\n",
      "Training: batch 13 begins at 14:48:43.672664\n",
      "\n",
      "Training: batch 13 ends at 14:48:45.267683\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.6709 - accuracy: 0.4237\n",
      "Training: batch 14 begins at 14:48:45.268615\n",
      "\n",
      "Training: batch 14 ends at 14:48:46.872415\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.6722 - accuracy: 0.4266\n",
      "Training: batch 15 begins at 14:48:46.873385\n",
      "\n",
      "Training: batch 15 ends at 14:48:48.476507\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.6678 - accuracy: 0.4307\n",
      "Training: batch 16 begins at 14:48:48.477607\n",
      "\n",
      "Training: batch 16 ends at 14:48:50.072842\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.6614 - accuracy: 0.4341\n",
      "Training: batch 17 begins at 14:48:50.073792\n",
      "\n",
      "Training: batch 17 ends at 14:48:51.656060\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.6722 - accuracy: 0.4320\n",
      "Evaluating: batch 0 begins at 14:48:51.666621\n",
      "\n",
      "Evaluating: batch 0 ends at 14:48:52.195872\n",
      "\n",
      "Evaluating: batch 1 begins at 14:48:52.196417\n",
      "\n",
      "Evaluating: batch 1 ends at 14:48:52.668705\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.6722 - accuracy: 0.4320 - val_loss: 1.5831 - val_accuracy: 0.4507\n",
      "Epoch 9/35\n",
      "\n",
      "Training: batch 0 begins at 14:48:52.678797\n",
      "\n",
      "Training: batch 0 ends at 14:48:54.293552\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.6500 - accuracy: 0.4273\n",
      "Training: batch 1 begins at 14:48:54.294480\n",
      "\n",
      "Training: batch 1 ends at 14:48:55.893636\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.6233 - accuracy: 0.4058\n",
      "Training: batch 2 begins at 14:48:55.894620\n",
      "\n",
      "Training: batch 2 ends at 14:48:57.504184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.7003 - accuracy: 0.3613\n",
      "Training: batch 3 begins at 14:48:57.505155\n",
      "\n",
      "Training: batch 3 ends at 14:48:59.091317\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.6496 - accuracy: 0.3880\n",
      "Training: batch 4 begins at 14:48:59.092329\n",
      "\n",
      "Training: batch 4 ends at 14:49:00.669414\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.6486 - accuracy: 0.3956\n",
      "Training: batch 5 begins at 14:49:00.671215\n",
      "\n",
      "Training: batch 5 ends at 14:49:02.278255\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.6653 - accuracy: 0.4159\n",
      "Training: batch 6 begins at 14:49:02.279217\n",
      "\n",
      "Training: batch 6 ends at 14:49:03.891612\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.6600 - accuracy: 0.4215\n",
      "Training: batch 7 begins at 14:49:03.892535\n",
      "\n",
      "Training: batch 7 ends at 14:49:05.502918\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.6840 - accuracy: 0.4051\n",
      "Training: batch 8 begins at 14:49:05.504721\n",
      "\n",
      "Training: batch 8 ends at 14:49:07.117168\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.6963 - accuracy: 0.4044\n",
      "Training: batch 9 begins at 14:49:07.118109\n",
      "\n",
      "Training: batch 9 ends at 14:49:08.691769\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.6616 - accuracy: 0.4232\n",
      "Training: batch 10 begins at 14:49:08.692651\n",
      "\n",
      "Training: batch 10 ends at 14:49:10.311337\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.6388 - accuracy: 0.4270\n",
      "Training: batch 11 begins at 14:49:10.312273\n",
      "\n",
      "Training: batch 11 ends at 14:49:11.900892\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.6384 - accuracy: 0.4281 \n",
      "Training: batch 12 begins at 14:49:11.901917\n",
      "\n",
      "Training: batch 12 ends at 14:49:13.490126\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.6263 - accuracy: 0.4370\n",
      "Training: batch 13 begins at 14:49:13.491316\n",
      "\n",
      "Training: batch 13 ends at 14:49:15.086633\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.6153 - accuracy: 0.4457\n",
      "Training: batch 14 begins at 14:49:15.087704\n",
      "\n",
      "Training: batch 14 ends at 14:49:16.700087\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.6011 - accuracy: 0.4542\n",
      "Training: batch 15 begins at 14:49:16.701030\n",
      "\n",
      "Training: batch 15 ends at 14:49:18.301844\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.6062 - accuracy: 0.4512\n",
      "Training: batch 16 begins at 14:49:18.302813\n",
      "\n",
      "Training: batch 16 ends at 14:49:19.906020\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.6003 - accuracy: 0.4548\n",
      "Training: batch 17 begins at 14:49:19.906973\n",
      "\n",
      "Training: batch 17 ends at 14:49:21.496837\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.6027 - accuracy: 0.4531\n",
      "Evaluating: batch 0 begins at 14:49:21.507004\n",
      "\n",
      "Evaluating: batch 0 ends at 14:49:22.043402\n",
      "\n",
      "Evaluating: batch 1 begins at 14:49:22.043952\n",
      "\n",
      "Evaluating: batch 1 ends at 14:49:22.522723\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.6027 - accuracy: 0.4531 - val_loss: 1.5771 - val_accuracy: 0.4551\n",
      "Epoch 10/35\n",
      "\n",
      "Training: batch 0 begins at 14:49:22.532381\n",
      "\n",
      "Training: batch 0 ends at 14:49:24.132057\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.4687 - accuracy: 0.4845\n",
      "Training: batch 1 begins at 14:49:24.132966\n",
      "\n",
      "Training: batch 1 ends at 14:49:25.737671\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.5035 - accuracy: 0.4929\n",
      "Training: batch 2 begins at 14:49:25.738698\n",
      "\n",
      "Training: batch 2 ends at 14:49:27.345917\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.5043 - accuracy: 0.4892\n",
      "Training: batch 3 begins at 14:49:27.346923\n",
      "\n",
      "Training: batch 3 ends at 14:49:28.941125\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.4717 - accuracy: 0.5069\n",
      "Training: batch 4 begins at 14:49:28.942389\n",
      "\n",
      "Training: batch 4 ends at 14:49:30.536494\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.5043 - accuracy: 0.4902\n",
      "Training: batch 5 begins at 14:49:30.537421\n",
      "\n",
      "Training: batch 5 ends at 14:49:32.097284\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.5249 - accuracy: 0.4799\n",
      "Training: batch 6 begins at 14:49:32.098205\n",
      "\n",
      "Training: batch 6 ends at 14:49:33.701244\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.5133 - accuracy: 0.4796\n",
      "Training: batch 7 begins at 14:49:33.702206\n",
      "\n",
      "Training: batch 7 ends at 14:49:35.298741\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.5254 - accuracy: 0.4689\n",
      "Training: batch 8 begins at 14:49:35.299688\n",
      "\n",
      "Training: batch 8 ends at 14:49:36.911140\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.5550 - accuracy: 0.4711\n",
      "Training: batch 9 begins at 14:49:36.912276\n",
      "\n",
      "Training: batch 9 ends at 14:49:38.490343\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.5485 - accuracy: 0.4742\n",
      "Training: batch 10 begins at 14:49:38.491328\n",
      "\n",
      "Training: batch 10 ends at 14:49:40.083988\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.5534 - accuracy: 0.4696\n",
      "Training: batch 11 begins at 14:49:40.086118\n",
      "\n",
      "Training: batch 11 ends at 14:49:41.706712\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.5676 - accuracy: 0.4660 \n",
      "Training: batch 12 begins at 14:49:41.707757\n",
      "\n",
      "Training: batch 12 ends at 14:49:43.307956\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.5808 - accuracy: 0.4633\n",
      "Training: batch 13 begins at 14:49:43.308971\n",
      "\n",
      "Training: batch 13 ends at 14:49:44.914312\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.5976 - accuracy: 0.4571\n",
      "Training: batch 14 begins at 14:49:44.915260\n",
      "\n",
      "Training: batch 14 ends at 14:49:46.517685\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.5922 - accuracy: 0.4613\n",
      "Training: batch 15 begins at 14:49:46.518644\n",
      "\n",
      "Training: batch 15 ends at 14:49:48.112133\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.5995 - accuracy: 0.4646\n",
      "Training: batch 16 begins at 14:49:48.113064\n",
      "\n",
      "Training: batch 16 ends at 14:49:49.734720\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.5975 - accuracy: 0.4613\n",
      "Training: batch 17 begins at 14:49:49.737184\n",
      "\n",
      "Training: batch 17 ends at 14:49:51.333808\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.5787 - accuracy: 0.4692\n",
      "Evaluating: batch 0 begins at 14:49:51.344198\n",
      "\n",
      "Evaluating: batch 0 ends at 14:49:51.875913\n",
      "\n",
      "Evaluating: batch 1 begins at 14:49:51.876428\n",
      "\n",
      "Evaluating: batch 1 ends at 14:49:52.347749\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.5787 - accuracy: 0.4692 - val_loss: 1.5401 - val_accuracy: 0.4339\n",
      "Epoch 11/35\n",
      "\n",
      "Training: batch 0 begins at 14:49:52.357676\n",
      "\n",
      "Training: batch 0 ends at 14:49:53.970098\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.6538 - accuracy: 0.5172\n",
      "Training: batch 1 begins at 14:49:53.971129\n",
      "\n",
      "Training: batch 1 ends at 14:49:55.579626\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.6356 - accuracy: 0.4692\n",
      "Training: batch 2 begins at 14:49:55.580787\n",
      "\n",
      "Training: batch 2 ends at 14:49:57.156032\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.5701 - accuracy: 0.4878\n",
      "Training: batch 3 begins at 14:49:57.157171\n",
      "\n",
      "Training: batch 3 ends at 14:49:58.763603\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.5717 - accuracy: 0.4916\n",
      "Training: batch 4 begins at 14:49:58.764674\n",
      "\n",
      "Training: batch 4 ends at 14:50:00.360886\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.5697 - accuracy: 0.4746\n",
      "Training: batch 5 begins at 14:50:00.361962\n",
      "\n",
      "Training: batch 5 ends at 14:50:01.965473\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.5934 - accuracy: 0.4532\n",
      "Training: batch 6 begins at 14:50:01.966355\n",
      "\n",
      "Training: batch 6 ends at 14:50:03.580867\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.5702 - accuracy: 0.4651\n",
      "Training: batch 7 begins at 14:50:03.581875\n",
      "\n",
      "Training: batch 7 ends at 14:50:05.189754\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.6222 - accuracy: 0.4356\n",
      "Training: batch 8 begins at 14:50:05.190714\n",
      "\n",
      "Training: batch 8 ends at 14:50:06.781357\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.5906 - accuracy: 0.4507\n",
      "Training: batch 9 begins at 14:50:06.782333\n",
      "\n",
      "Training: batch 9 ends at 14:50:08.376963\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.5833 - accuracy: 0.4525\n",
      "Training: batch 10 begins at 14:50:08.377923\n",
      "\n",
      "Training: batch 10 ends at 14:50:09.971183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 [=================>............] - ETA: 11s - loss: 1.5877 - accuracy: 0.4652\n",
      "Training: batch 11 begins at 14:50:09.972104\n",
      "\n",
      "Training: batch 11 ends at 14:50:11.569612\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.5701 - accuracy: 0.4712 \n",
      "Training: batch 12 begins at 14:50:11.571347\n",
      "\n",
      "Training: batch 12 ends at 14:50:13.165455\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.5525 - accuracy: 0.4749\n",
      "Training: batch 13 begins at 14:50:13.166617\n",
      "\n",
      "Training: batch 13 ends at 14:50:14.745123\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.5370 - accuracy: 0.4835\n",
      "Training: batch 14 begins at 14:50:14.746156\n",
      "\n",
      "Training: batch 14 ends at 14:50:16.332438\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.5298 - accuracy: 0.4848\n",
      "Training: batch 15 begins at 14:50:16.333378\n",
      "\n",
      "Training: batch 15 ends at 14:50:17.929703\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.5375 - accuracy: 0.4786\n",
      "Training: batch 16 begins at 14:50:17.931538\n",
      "\n",
      "Training: batch 16 ends at 14:50:19.529812\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.5343 - accuracy: 0.4810\n",
      "Training: batch 17 begins at 14:50:19.530765\n",
      "\n",
      "Training: batch 17 ends at 14:50:21.091502\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.5442 - accuracy: 0.4743\n",
      "Evaluating: batch 0 begins at 14:50:21.102465\n",
      "\n",
      "Evaluating: batch 0 ends at 14:50:21.631613\n",
      "\n",
      "Evaluating: batch 1 begins at 14:50:21.632141\n",
      "\n",
      "Evaluating: batch 1 ends at 14:50:22.103289\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.5442 - accuracy: 0.4743 - val_loss: 1.4810 - val_accuracy: 0.4628\n",
      "Epoch 12/35\n",
      "\n",
      "Training: batch 0 begins at 14:50:22.113441\n",
      "\n",
      "Training: batch 0 ends at 14:50:23.735476\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.4609 - accuracy: 0.5612\n",
      "Training: batch 1 begins at 14:50:23.736667\n",
      "\n",
      "Training: batch 1 ends at 14:50:25.333886\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.4272 - accuracy: 0.5014\n",
      "Training: batch 2 begins at 14:50:25.335008\n",
      "\n",
      "Training: batch 2 ends at 14:50:26.921970\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.4721 - accuracy: 0.5008\n",
      "Training: batch 3 begins at 14:50:26.922929\n",
      "\n",
      "Training: batch 3 ends at 14:50:28.520846\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.4844 - accuracy: 0.4904\n",
      "Training: batch 4 begins at 14:50:28.521778\n",
      "\n",
      "Training: batch 4 ends at 14:50:30.112869\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.4693 - accuracy: 0.4882\n",
      "Training: batch 5 begins at 14:50:30.113830\n",
      "\n",
      "Training: batch 5 ends at 14:50:31.709351\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.5146 - accuracy: 0.4913\n",
      "Training: batch 6 begins at 14:50:31.710229\n",
      "\n",
      "Training: batch 6 ends at 14:50:33.284767\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.5119 - accuracy: 0.4897\n",
      "Training: batch 7 begins at 14:50:33.285747\n",
      "\n",
      "Training: batch 7 ends at 14:50:34.873581\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.5285 - accuracy: 0.4815\n",
      "Training: batch 8 begins at 14:50:34.874616\n",
      "\n",
      "Training: batch 8 ends at 14:50:36.510780\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.5147 - accuracy: 0.4832\n",
      "Training: batch 9 begins at 14:50:36.511954\n",
      "\n",
      "Training: batch 9 ends at 14:50:38.103855\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.4950 - accuracy: 0.4883\n",
      "Training: batch 10 begins at 14:50:38.105260\n",
      "\n",
      "Training: batch 10 ends at 14:50:39.710993\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.5043 - accuracy: 0.4821\n",
      "Training: batch 11 begins at 14:50:39.712006\n",
      "\n",
      "Training: batch 11 ends at 14:50:41.294232\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.5020 - accuracy: 0.4812 \n",
      "Training: batch 12 begins at 14:50:41.295201\n",
      "\n",
      "Training: batch 12 ends at 14:50:42.912830\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.5022 - accuracy: 0.4813\n",
      "Training: batch 13 begins at 14:50:42.913856\n",
      "\n",
      "Training: batch 13 ends at 14:50:44.508790\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.5032 - accuracy: 0.4819\n",
      "Training: batch 14 begins at 14:50:44.509944\n",
      "\n",
      "Training: batch 14 ends at 14:50:46.107195\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.5166 - accuracy: 0.4798\n",
      "Training: batch 15 begins at 14:50:46.108127\n",
      "\n",
      "Training: batch 15 ends at 14:50:47.710988\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.5075 - accuracy: 0.4865\n",
      "Training: batch 16 begins at 14:50:47.711975\n",
      "\n",
      "Training: batch 16 ends at 14:50:49.322695\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.5089 - accuracy: 0.4909\n",
      "Training: batch 17 begins at 14:50:49.323725\n",
      "\n",
      "Training: batch 17 ends at 14:50:50.916466\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.5140 - accuracy: 0.4893\n",
      "Evaluating: batch 0 begins at 14:50:50.926611\n",
      "\n",
      "Evaluating: batch 0 ends at 14:50:51.455137\n",
      "\n",
      "Evaluating: batch 1 begins at 14:50:51.455664\n",
      "\n",
      "Evaluating: batch 1 ends at 14:50:51.933551\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.5140 - accuracy: 0.4893 - val_loss: 1.5119 - val_accuracy: 0.4332\n",
      "Epoch 13/35\n",
      "\n",
      "Training: batch 0 begins at 14:50:51.943786\n",
      "\n",
      "Training: batch 0 ends at 14:50:53.542291\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.5301 - accuracy: 0.4756\n",
      "Training: batch 1 begins at 14:50:53.543382\n",
      "\n",
      "Training: batch 1 ends at 14:50:55.155507\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.5369 - accuracy: 0.4327\n",
      "Training: batch 2 begins at 14:50:55.156478\n",
      "\n",
      "Training: batch 2 ends at 14:50:56.759677\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.5726 - accuracy: 0.4419\n",
      "Training: batch 3 begins at 14:50:56.760757\n",
      "\n",
      "Training: batch 3 ends at 14:50:58.405444\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.5132 - accuracy: 0.4770\n",
      "Training: batch 4 begins at 14:50:58.406764\n",
      "\n",
      "Training: batch 4 ends at 14:50:59.990388\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.5248 - accuracy: 0.4767\n",
      "Training: batch 5 begins at 14:50:59.991374\n",
      "\n",
      "Training: batch 5 ends at 14:51:01.585820\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.5107 - accuracy: 0.4785\n",
      "Training: batch 6 begins at 14:51:01.586768\n",
      "\n",
      "Training: batch 6 ends at 14:51:03.200422\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.5153 - accuracy: 0.4833\n",
      "Training: batch 7 begins at 14:51:03.201349\n",
      "\n",
      "Training: batch 7 ends at 14:51:04.817298\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.5089 - accuracy: 0.4806\n",
      "Training: batch 8 begins at 14:51:04.818272\n",
      "\n",
      "Training: batch 8 ends at 14:51:06.401200\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.5190 - accuracy: 0.4792\n",
      "Training: batch 9 begins at 14:51:06.402237\n",
      "\n",
      "Training: batch 9 ends at 14:51:08.019108\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.5021 - accuracy: 0.4828\n",
      "Training: batch 10 begins at 14:51:08.020196\n",
      "\n",
      "Training: batch 10 ends at 14:51:09.638333\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.5165 - accuracy: 0.4726\n",
      "Training: batch 11 begins at 14:51:09.639339\n",
      "\n",
      "Training: batch 11 ends at 14:51:11.242025\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.5145 - accuracy: 0.4772 \n",
      "Training: batch 12 begins at 14:51:11.243023\n",
      "\n",
      "Training: batch 12 ends at 14:51:12.845059\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.4940 - accuracy: 0.4922\n",
      "Training: batch 13 begins at 14:51:12.846100\n",
      "\n",
      "Training: batch 13 ends at 14:51:14.454337\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.4953 - accuracy: 0.4876\n",
      "Training: batch 14 begins at 14:51:14.455267\n",
      "\n",
      "Training: batch 14 ends at 14:51:16.055843\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.4928 - accuracy: 0.4914\n",
      "Training: batch 15 begins at 14:51:16.056792\n",
      "\n",
      "Training: batch 15 ends at 14:51:17.651428\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.4933 - accuracy: 0.4905\n",
      "Training: batch 16 begins at 14:51:17.652434\n",
      "\n",
      "Training: batch 16 ends at 14:51:19.248588\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.5078 - accuracy: 0.4934\n",
      "Training: batch 17 begins at 14:51:19.249590\n",
      "\n",
      "Training: batch 17 ends at 14:51:20.858926\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.5130 - accuracy: 0.4927\n",
      "Evaluating: batch 0 begins at 14:51:20.870235\n",
      "\n",
      "Evaluating: batch 0 ends at 14:51:21.397868\n",
      "\n",
      "Evaluating: batch 1 begins at 14:51:21.398385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: batch 1 ends at 14:51:21.880962\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.5130 - accuracy: 0.4927 - val_loss: 1.7093 - val_accuracy: 0.3528\n",
      "Epoch 14/35\n",
      "\n",
      "Training: batch 0 begins at 14:51:21.890868\n",
      "\n",
      "Training: batch 0 ends at 14:51:23.499105\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.6616 - accuracy: 0.4812\n",
      "Training: batch 1 begins at 14:51:23.500015\n",
      "\n",
      "Training: batch 1 ends at 14:51:25.105179\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.5241 - accuracy: 0.4978\n",
      "Training: batch 2 begins at 14:51:25.106116\n",
      "\n",
      "Training: batch 2 ends at 14:51:26.710279\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.5145 - accuracy: 0.4763\n",
      "Training: batch 3 begins at 14:51:26.711197\n",
      "\n",
      "Training: batch 3 ends at 14:51:28.301407\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.5077 - accuracy: 0.5026\n",
      "Training: batch 4 begins at 14:51:28.302356\n",
      "\n",
      "Training: batch 4 ends at 14:51:29.901437\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.5046 - accuracy: 0.4976\n",
      "Training: batch 5 begins at 14:51:29.902756\n",
      "\n",
      "Training: batch 5 ends at 14:51:31.495702\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.5111 - accuracy: 0.4903\n",
      "Training: batch 6 begins at 14:51:31.496618\n",
      "\n",
      "Training: batch 6 ends at 14:51:33.107425\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.5081 - accuracy: 0.4916\n",
      "Training: batch 7 begins at 14:51:33.108390\n",
      "\n",
      "Training: batch 7 ends at 14:51:34.716162\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.4967 - accuracy: 0.4856\n",
      "Training: batch 8 begins at 14:51:34.717118\n",
      "\n",
      "Training: batch 8 ends at 14:51:36.305539\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.5123 - accuracy: 0.4878\n",
      "Training: batch 9 begins at 14:51:36.306542\n",
      "\n",
      "Training: batch 9 ends at 14:51:37.903177\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.5216 - accuracy: 0.4813\n",
      "Training: batch 10 begins at 14:51:37.904191\n",
      "\n",
      "Training: batch 10 ends at 14:51:39.508568\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.5280 - accuracy: 0.4752\n",
      "Training: batch 11 begins at 14:51:39.509593\n",
      "\n",
      "Training: batch 11 ends at 14:51:41.105628\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.5312 - accuracy: 0.4786 \n",
      "Training: batch 12 begins at 14:51:41.106644\n",
      "\n",
      "Training: batch 12 ends at 14:51:42.714175\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.5359 - accuracy: 0.4788\n",
      "Training: batch 13 begins at 14:51:42.715238\n",
      "\n",
      "Training: batch 13 ends at 14:51:44.296174\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.5307 - accuracy: 0.4807\n",
      "Training: batch 14 begins at 14:51:44.297143\n",
      "\n",
      "Training: batch 14 ends at 14:51:45.916061\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.5453 - accuracy: 0.4720\n",
      "Training: batch 15 begins at 14:51:45.916975\n",
      "\n",
      "Training: batch 15 ends at 14:51:47.494096\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.5323 - accuracy: 0.4830\n",
      "Training: batch 16 begins at 14:51:47.495136\n",
      "\n",
      "Training: batch 16 ends at 14:51:49.079124\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.5253 - accuracy: 0.4878\n",
      "Training: batch 17 begins at 14:51:49.080076\n",
      "\n",
      "Training: batch 17 ends at 14:51:50.656455\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.5419 - accuracy: 0.4803\n",
      "Evaluating: batch 0 begins at 14:51:50.667950\n",
      "\n",
      "Evaluating: batch 0 ends at 14:51:51.198354\n",
      "\n",
      "Evaluating: batch 1 begins at 14:51:51.198862\n",
      "\n",
      "Evaluating: batch 1 ends at 14:51:51.674245\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.5419 - accuracy: 0.4803 - val_loss: 1.4659 - val_accuracy: 0.4750\n",
      "Epoch 15/35\n",
      "\n",
      "Training: batch 0 begins at 14:51:51.684580\n",
      "\n",
      "Training: batch 0 ends at 14:51:53.308424\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.6001 - accuracy: 0.5077\n",
      "Training: batch 1 begins at 14:51:53.309633\n",
      "\n",
      "Training: batch 1 ends at 14:51:54.938087\n",
      " 2/18 [==>...........................] - ETA: 26s - loss: 1.5945 - accuracy: 0.4795\n",
      "Training: batch 2 begins at 14:51:54.939121\n",
      "\n",
      "Training: batch 2 ends at 14:51:56.538516\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.5512 - accuracy: 0.4905\n",
      "Training: batch 3 begins at 14:51:56.539479\n",
      "\n",
      "Training: batch 3 ends at 14:51:58.130086\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.5811 - accuracy: 0.4690\n",
      "Training: batch 4 begins at 14:51:58.131097\n",
      "\n",
      "Training: batch 4 ends at 14:51:59.735915\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.5590 - accuracy: 0.4666\n",
      "Training: batch 5 begins at 14:51:59.736999\n",
      "\n",
      "Training: batch 5 ends at 14:52:01.348558\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.5338 - accuracy: 0.4761\n",
      "Training: batch 6 begins at 14:52:01.349539\n",
      "\n",
      "Training: batch 6 ends at 14:52:02.965768\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.5282 - accuracy: 0.4752\n",
      "Training: batch 7 begins at 14:52:02.966705\n",
      "\n",
      "Training: batch 7 ends at 14:52:04.539615\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.5195 - accuracy: 0.4727\n",
      "Training: batch 8 begins at 14:52:04.540608\n",
      "\n",
      "Training: batch 8 ends at 14:52:06.124640\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.5459 - accuracy: 0.4640\n",
      "Training: batch 9 begins at 14:52:06.125926\n",
      "\n",
      "Training: batch 9 ends at 14:52:07.717303\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.5146 - accuracy: 0.4761\n",
      "Training: batch 10 begins at 14:52:07.718253\n",
      "\n",
      "Training: batch 10 ends at 14:52:09.305115\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.5189 - accuracy: 0.4757\n",
      "Training: batch 11 begins at 14:52:09.306059\n",
      "\n",
      "Training: batch 11 ends at 14:52:10.924270\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.5032 - accuracy: 0.4838 \n",
      "Training: batch 12 begins at 14:52:10.925199\n",
      "\n",
      "Training: batch 12 ends at 14:52:12.509573\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.4817 - accuracy: 0.4898\n",
      "Training: batch 13 begins at 14:52:12.510606\n",
      "\n",
      "Training: batch 13 ends at 14:52:14.103298\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.5130 - accuracy: 0.4756\n",
      "Training: batch 14 begins at 14:52:14.104365\n",
      "\n",
      "Training: batch 14 ends at 14:52:15.702161\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.5027 - accuracy: 0.4818\n",
      "Training: batch 15 begins at 14:52:15.703251\n",
      "\n",
      "Training: batch 15 ends at 14:52:17.304446\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.5010 - accuracy: 0.4824\n",
      "Training: batch 16 begins at 14:52:17.305439\n",
      "\n",
      "Training: batch 16 ends at 14:52:18.897913\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.4892 - accuracy: 0.4896\n",
      "Training: batch 17 begins at 14:52:18.898850\n",
      "\n",
      "Training: batch 17 ends at 14:52:20.496928\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.4874 - accuracy: 0.4909\n",
      "Evaluating: batch 0 begins at 14:52:20.507052\n",
      "\n",
      "Evaluating: batch 0 ends at 14:52:21.062046\n",
      "\n",
      "Evaluating: batch 1 begins at 14:52:21.062539\n",
      "\n",
      "Evaluating: batch 1 ends at 14:52:21.543633\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.4874 - accuracy: 0.4909 - val_loss: 1.5499 - val_accuracy: 0.4169\n",
      "Epoch 16/35\n",
      "\n",
      "Training: batch 0 begins at 14:52:21.556182\n",
      "\n",
      "Training: batch 0 ends at 14:52:23.212730\n",
      " 1/18 [>.............................] - ETA: 28s - loss: 1.3689 - accuracy: 0.4862\n",
      "Training: batch 1 begins at 14:52:23.213798\n",
      "\n",
      "Training: batch 1 ends at 14:52:24.920425\n",
      " 2/18 [==>...........................] - ETA: 27s - loss: 1.5273 - accuracy: 0.4519\n",
      "Training: batch 2 begins at 14:52:24.921294\n",
      "\n",
      "Training: batch 2 ends at 14:52:26.563279\n",
      " 3/18 [====>.........................] - ETA: 25s - loss: 1.4436 - accuracy: 0.5102\n",
      "Training: batch 3 begins at 14:52:26.564191\n",
      "\n",
      "Training: batch 3 ends at 14:52:28.168071\n",
      " 4/18 [=====>........................] - ETA: 23s - loss: 1.4089 - accuracy: 0.5328\n",
      "Training: batch 4 begins at 14:52:28.169380\n",
      "\n",
      "Training: batch 4 ends at 14:52:29.757559\n",
      " 5/18 [=======>......................] - ETA: 21s - loss: 1.4370 - accuracy: 0.5236\n",
      "Training: batch 5 begins at 14:52:29.758604\n",
      "\n",
      "Training: batch 5 ends at 14:52:31.344034\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.4192 - accuracy: 0.5274\n",
      "Training: batch 6 begins at 14:52:31.344950\n",
      "\n",
      "Training: batch 6 ends at 14:52:32.988357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.4529 - accuracy: 0.5098\n",
      "Training: batch 7 begins at 14:52:32.989314\n",
      "\n",
      "Training: batch 7 ends at 14:52:34.584678\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.4610 - accuracy: 0.5056\n",
      "Training: batch 8 begins at 14:52:34.585634\n",
      "\n",
      "Training: batch 8 ends at 14:52:36.193162\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.4640 - accuracy: 0.5023\n",
      "Training: batch 9 begins at 14:52:36.194312\n",
      "\n",
      "Training: batch 9 ends at 14:52:37.796067\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.4427 - accuracy: 0.5135\n",
      "Training: batch 10 begins at 14:52:37.796954\n",
      "\n",
      "Training: batch 10 ends at 14:52:39.456570\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.4570 - accuracy: 0.5161\n",
      "Training: batch 11 begins at 14:52:39.457461\n",
      "\n",
      "Training: batch 11 ends at 14:52:41.091552\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.4476 - accuracy: 0.5148 \n",
      "Training: batch 12 begins at 14:52:41.092589\n",
      "\n",
      "Training: batch 12 ends at 14:52:42.706756\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.4528 - accuracy: 0.5121\n",
      "Training: batch 13 begins at 14:52:42.707705\n",
      "\n",
      "Training: batch 13 ends at 14:52:44.313727\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.4616 - accuracy: 0.5089\n",
      "Training: batch 14 begins at 14:52:44.314844\n",
      "\n",
      "Training: batch 14 ends at 14:52:45.934044\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.4473 - accuracy: 0.5150\n",
      "Training: batch 15 begins at 14:52:45.935007\n",
      "\n",
      "Training: batch 15 ends at 14:52:47.497962\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.4415 - accuracy: 0.5166\n",
      "Training: batch 16 begins at 14:52:47.498936\n",
      "\n",
      "Training: batch 16 ends at 14:52:49.102446\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.4402 - accuracy: 0.5210\n",
      "Training: batch 17 begins at 14:52:49.104195\n",
      "\n",
      "Training: batch 17 ends at 14:52:50.729922\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.4332 - accuracy: 0.5248\n",
      "Evaluating: batch 0 begins at 14:52:50.741155\n",
      "\n",
      "Evaluating: batch 0 ends at 14:52:51.270505\n",
      "\n",
      "Evaluating: batch 1 begins at 14:52:51.271078\n",
      "\n",
      "Evaluating: batch 1 ends at 14:52:51.743949\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.4332 - accuracy: 0.5248 - val_loss: 1.4587 - val_accuracy: 0.4909\n",
      "Epoch 17/35\n",
      "\n",
      "Training: batch 0 begins at 14:52:51.753920\n",
      "\n",
      "Training: batch 0 ends at 14:52:53.358028\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.4912 - accuracy: 0.5457\n",
      "Training: batch 1 begins at 14:52:53.358936\n",
      "\n",
      "Training: batch 1 ends at 14:52:54.955998\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.3708 - accuracy: 0.5294\n",
      "Training: batch 2 begins at 14:52:54.957075\n",
      "\n",
      "Training: batch 2 ends at 14:52:56.536204\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.4267 - accuracy: 0.5112\n",
      "Training: batch 3 begins at 14:52:56.537147\n",
      "\n",
      "Training: batch 3 ends at 14:52:58.118876\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.4660 - accuracy: 0.4998\n",
      "Training: batch 4 begins at 14:52:58.120077\n",
      "\n",
      "Training: batch 4 ends at 14:52:59.717708\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.4550 - accuracy: 0.4940\n",
      "Training: batch 5 begins at 14:52:59.718681\n",
      "\n",
      "Training: batch 5 ends at 14:53:01.306147\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.4611 - accuracy: 0.4915\n",
      "Training: batch 6 begins at 14:53:01.307241\n",
      "\n",
      "Training: batch 6 ends at 14:53:02.902997\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.4338 - accuracy: 0.5000\n",
      "Training: batch 7 begins at 14:53:02.903940\n",
      "\n",
      "Training: batch 7 ends at 14:53:04.466603\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.4537 - accuracy: 0.4951\n",
      "Training: batch 8 begins at 14:53:04.467882\n",
      "\n",
      "Training: batch 8 ends at 14:53:06.057579\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.4328 - accuracy: 0.5073\n",
      "Training: batch 9 begins at 14:53:06.058680\n",
      "\n",
      "Training: batch 9 ends at 14:53:07.616935\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.4478 - accuracy: 0.5083\n",
      "Training: batch 10 begins at 14:53:07.617917\n",
      "\n",
      "Training: batch 10 ends at 14:53:09.195225\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.4666 - accuracy: 0.5102\n",
      "Training: batch 11 begins at 14:53:09.196126\n",
      "\n",
      "Training: batch 11 ends at 14:53:10.779186\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.4809 - accuracy: 0.5001 \n",
      "Training: batch 12 begins at 14:53:10.780245\n",
      "\n",
      "Training: batch 12 ends at 14:53:12.372119\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.4806 - accuracy: 0.5003\n",
      "Training: batch 13 begins at 14:53:12.373020\n",
      "\n",
      "Training: batch 13 ends at 14:53:13.971046\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.4888 - accuracy: 0.4968\n",
      "Training: batch 14 begins at 14:53:13.972110\n",
      "\n",
      "Training: batch 14 ends at 14:53:15.568202\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.4817 - accuracy: 0.5016\n",
      "Training: batch 15 begins at 14:53:15.569176\n",
      "\n",
      "Training: batch 15 ends at 14:53:17.172945\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.4771 - accuracy: 0.5048\n",
      "Training: batch 16 begins at 14:53:17.173880\n",
      "\n",
      "Training: batch 16 ends at 14:53:18.781637\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.4677 - accuracy: 0.5094\n",
      "Training: batch 17 begins at 14:53:18.782697\n",
      "\n",
      "Training: batch 17 ends at 14:53:20.381687\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.4703 - accuracy: 0.5057\n",
      "Evaluating: batch 0 begins at 14:53:20.392074\n",
      "\n",
      "Evaluating: batch 0 ends at 14:53:20.931603\n",
      "\n",
      "Evaluating: batch 1 begins at 14:53:20.932122\n",
      "\n",
      "Evaluating: batch 1 ends at 14:53:21.405203\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.4703 - accuracy: 0.5057 - val_loss: 1.4271 - val_accuracy: 0.5455\n",
      "Epoch 18/35\n",
      "\n",
      "Training: batch 0 begins at 14:53:21.415140\n",
      "\n",
      "Training: batch 0 ends at 14:53:23.007936\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.8344 - accuracy: 0.3524\n",
      "Training: batch 1 begins at 14:53:23.008941\n",
      "\n",
      "Training: batch 1 ends at 14:53:24.598603\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.5641 - accuracy: 0.4531\n",
      "Training: batch 2 begins at 14:53:24.599552\n",
      "\n",
      "Training: batch 2 ends at 14:53:26.199757\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.4670 - accuracy: 0.5026\n",
      "Training: batch 3 begins at 14:53:26.200705\n",
      "\n",
      "Training: batch 3 ends at 14:53:27.794115\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.4391 - accuracy: 0.5245\n",
      "Training: batch 4 begins at 14:53:27.795172\n",
      "\n",
      "Training: batch 4 ends at 14:53:29.411612\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.4174 - accuracy: 0.5358\n",
      "Training: batch 5 begins at 14:53:29.412646\n",
      "\n",
      "Training: batch 5 ends at 14:53:31.009868\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.4828 - accuracy: 0.5003\n",
      "Training: batch 6 begins at 14:53:31.012832\n",
      "\n",
      "Training: batch 6 ends at 14:53:32.601186\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.4517 - accuracy: 0.5173\n",
      "Training: batch 7 begins at 14:53:32.602105\n",
      "\n",
      "Training: batch 7 ends at 14:53:34.201897\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.4493 - accuracy: 0.5137\n",
      "Training: batch 8 begins at 14:53:34.202938\n",
      "\n",
      "Training: batch 8 ends at 14:53:35.831768\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.4517 - accuracy: 0.5172\n",
      "Training: batch 9 begins at 14:53:35.833866\n",
      "\n",
      "Training: batch 9 ends at 14:53:37.461313\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.4627 - accuracy: 0.5199\n",
      "Training: batch 10 begins at 14:53:37.462225\n",
      "\n",
      "Training: batch 10 ends at 14:53:39.057247\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.4644 - accuracy: 0.5192\n",
      "Training: batch 11 begins at 14:53:39.058316\n",
      "\n",
      "Training: batch 11 ends at 14:53:40.648198\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.4600 - accuracy: 0.5213 \n",
      "Training: batch 12 begins at 14:53:40.649255\n",
      "\n",
      "Training: batch 12 ends at 14:53:42.249125\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.4728 - accuracy: 0.5140\n",
      "Training: batch 13 begins at 14:53:42.250517\n",
      "\n",
      "Training: batch 13 ends at 14:53:43.824298\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.4771 - accuracy: 0.5085\n",
      "Training: batch 14 begins at 14:53:43.825256\n",
      "\n",
      "Training: batch 14 ends at 14:53:45.414389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/18 [========================>.....] - ETA: 4s - loss: 1.4794 - accuracy: 0.5049\n",
      "Training: batch 15 begins at 14:53:45.415259\n",
      "\n",
      "Training: batch 15 ends at 14:53:47.019967\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.4830 - accuracy: 0.5000\n",
      "Training: batch 16 begins at 14:53:47.020934\n",
      "\n",
      "Training: batch 16 ends at 14:53:48.592135\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.4658 - accuracy: 0.5076\n",
      "Training: batch 17 begins at 14:53:48.593112\n",
      "\n",
      "Training: batch 17 ends at 14:53:50.185729\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.4667 - accuracy: 0.5101\n",
      "Evaluating: batch 0 begins at 14:53:50.196147\n",
      "\n",
      "Evaluating: batch 0 ends at 14:53:50.719227\n",
      "\n",
      "Evaluating: batch 1 begins at 14:53:50.719722\n",
      "\n",
      "Evaluating: batch 1 ends at 14:53:51.196433\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.4667 - accuracy: 0.5101 - val_loss: 1.4908 - val_accuracy: 0.4512\n",
      "Epoch 19/35\n",
      "\n",
      "Training: batch 0 begins at 14:53:51.206517\n",
      "\n",
      "Training: batch 0 ends at 14:53:52.821211\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.6270 - accuracy: 0.4334\n",
      "Training: batch 1 begins at 14:53:52.822165\n",
      "\n",
      "Training: batch 1 ends at 14:53:54.446052\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.6128 - accuracy: 0.4341\n",
      "Training: batch 2 begins at 14:53:54.447029\n",
      "\n",
      "Training: batch 2 ends at 14:53:56.126344\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.5295 - accuracy: 0.4532\n",
      "Training: batch 3 begins at 14:53:56.127422\n",
      "\n",
      "Training: batch 3 ends at 14:53:57.747749\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.5248 - accuracy: 0.4584\n",
      "Training: batch 4 begins at 14:53:57.748836\n",
      "\n",
      "Training: batch 4 ends at 14:53:59.337154\n",
      " 5/18 [=======>......................] - ETA: 21s - loss: 1.4827 - accuracy: 0.4751\n",
      "Training: batch 5 begins at 14:53:59.338037\n",
      "\n",
      "Training: batch 5 ends at 14:54:00.933738\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.4797 - accuracy: 0.4744\n",
      "Training: batch 6 begins at 14:54:00.934746\n",
      "\n",
      "Training: batch 6 ends at 14:54:02.536840\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.5184 - accuracy: 0.4703\n",
      "Training: batch 7 begins at 14:54:02.537748\n",
      "\n",
      "Training: batch 7 ends at 14:54:04.111942\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.5226 - accuracy: 0.4639\n",
      "Training: batch 8 begins at 14:54:04.112940\n",
      "\n",
      "Training: batch 8 ends at 14:54:05.708841\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.4981 - accuracy: 0.4787\n",
      "Training: batch 9 begins at 14:54:05.709764\n",
      "\n",
      "Training: batch 9 ends at 14:54:07.295351\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.4752 - accuracy: 0.4867\n",
      "Training: batch 10 begins at 14:54:07.296341\n",
      "\n",
      "Training: batch 10 ends at 14:54:08.872196\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.4616 - accuracy: 0.4956\n",
      "Training: batch 11 begins at 14:54:08.873188\n",
      "\n",
      "Training: batch 11 ends at 14:54:10.486379\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.4491 - accuracy: 0.4992 \n",
      "Training: batch 12 begins at 14:54:10.487711\n",
      "\n",
      "Training: batch 12 ends at 14:54:12.093966\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.4436 - accuracy: 0.5041\n",
      "Training: batch 13 begins at 14:54:12.095028\n",
      "\n",
      "Training: batch 13 ends at 14:54:13.689809\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.4365 - accuracy: 0.5085\n",
      "Training: batch 14 begins at 14:54:13.690725\n",
      "\n",
      "Training: batch 14 ends at 14:54:15.281828\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.4132 - accuracy: 0.5157\n",
      "Training: batch 15 begins at 14:54:15.282955\n",
      "\n",
      "Training: batch 15 ends at 14:54:16.878704\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.4241 - accuracy: 0.5147\n",
      "Training: batch 16 begins at 14:54:16.879641\n",
      "\n",
      "Training: batch 16 ends at 14:54:18.490810\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.4136 - accuracy: 0.5194\n",
      "Training: batch 17 begins at 14:54:18.491886\n",
      "\n",
      "Training: batch 17 ends at 14:54:20.105179\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.4093 - accuracy: 0.5208\n",
      "Evaluating: batch 0 begins at 14:54:20.115374\n",
      "\n",
      "Evaluating: batch 0 ends at 14:54:20.646772\n",
      "\n",
      "Evaluating: batch 1 begins at 14:54:20.647257\n",
      "\n",
      "Evaluating: batch 1 ends at 14:54:21.120684\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.4093 - accuracy: 0.5208 - val_loss: 1.3341 - val_accuracy: 0.5117\n",
      "Epoch 20/35\n",
      "\n",
      "Training: batch 0 begins at 14:54:21.130478\n",
      "\n",
      "Training: batch 0 ends at 14:54:22.750011\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.3317 - accuracy: 0.5238\n",
      "Training: batch 1 begins at 14:54:22.750965\n",
      "\n",
      "Training: batch 1 ends at 14:54:24.350358\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.4215 - accuracy: 0.5287\n",
      "Training: batch 2 begins at 14:54:24.351523\n",
      "\n",
      "Training: batch 2 ends at 14:54:25.947978\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.3908 - accuracy: 0.5430\n",
      "Training: batch 3 begins at 14:54:25.948927\n",
      "\n",
      "Training: batch 3 ends at 14:54:27.554356\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.4433 - accuracy: 0.5302\n",
      "Training: batch 4 begins at 14:54:27.555286\n",
      "\n",
      "Training: batch 4 ends at 14:54:29.143557\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.3756 - accuracy: 0.5516\n",
      "Training: batch 5 begins at 14:54:29.144575\n",
      "\n",
      "Training: batch 5 ends at 14:54:30.708047\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3653 - accuracy: 0.5423\n",
      "Training: batch 6 begins at 14:54:30.709339\n",
      "\n",
      "Training: batch 6 ends at 14:54:32.304745\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3352 - accuracy: 0.5520\n",
      "Training: batch 7 begins at 14:54:32.305700\n",
      "\n",
      "Training: batch 7 ends at 14:54:33.892306\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3557 - accuracy: 0.5484\n",
      "Training: batch 8 begins at 14:54:33.893274\n",
      "\n",
      "Training: batch 8 ends at 14:54:35.494222\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.3343 - accuracy: 0.5557\n",
      "Training: batch 9 begins at 14:54:35.495244\n",
      "\n",
      "Training: batch 9 ends at 14:54:37.102754\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.3093 - accuracy: 0.5602\n",
      "Training: batch 10 begins at 14:54:37.103746\n",
      "\n",
      "Training: batch 10 ends at 14:54:38.711813\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3461 - accuracy: 0.5463\n",
      "Training: batch 11 begins at 14:54:38.712820\n",
      "\n",
      "Training: batch 11 ends at 14:54:40.307579\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.3768 - accuracy: 0.5320 \n",
      "Training: batch 12 begins at 14:54:40.308468\n",
      "\n",
      "Training: batch 12 ends at 14:54:41.901319\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.3919 - accuracy: 0.5286\n",
      "Training: batch 13 begins at 14:54:41.902289\n",
      "\n",
      "Training: batch 13 ends at 14:54:43.503172\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3898 - accuracy: 0.5310\n",
      "Training: batch 14 begins at 14:54:43.504056\n",
      "\n",
      "Training: batch 14 ends at 14:54:45.071112\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3995 - accuracy: 0.5267\n",
      "Training: batch 15 begins at 14:54:45.072265\n",
      "\n",
      "Training: batch 15 ends at 14:54:46.655835\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.4335 - accuracy: 0.5177\n",
      "Training: batch 16 begins at 14:54:46.656760\n",
      "\n",
      "Training: batch 16 ends at 14:54:48.256804\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.4304 - accuracy: 0.5171\n",
      "Training: batch 17 begins at 14:54:48.257737\n",
      "\n",
      "Training: batch 17 ends at 14:54:49.856021\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.4436 - accuracy: 0.5168\n",
      "Evaluating: batch 0 begins at 14:54:49.866492\n",
      "\n",
      "Evaluating: batch 0 ends at 14:54:50.395334\n",
      "\n",
      "Evaluating: batch 1 begins at 14:54:50.395863\n",
      "\n",
      "Evaluating: batch 1 ends at 14:54:50.872742\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.4436 - accuracy: 0.5168 - val_loss: 1.6020 - val_accuracy: 0.4402\n",
      "Epoch 21/35\n",
      "\n",
      "Training: batch 0 begins at 14:54:50.883071\n",
      "\n",
      "Training: batch 0 ends at 14:54:52.468249\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 1.4252 - accuracy: 0.5051\n",
      "Training: batch 1 begins at 14:54:52.469216\n",
      "\n",
      "Training: batch 1 ends at 14:54:54.051498\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.4160 - accuracy: 0.5350\n",
      "Training: batch 2 begins at 14:54:54.052405\n",
      "\n",
      "Training: batch 2 ends at 14:54:55.645732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.2901 - accuracy: 0.5934\n",
      "Training: batch 3 begins at 14:54:55.646787\n",
      "\n",
      "Training: batch 3 ends at 14:54:57.244939\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.3351 - accuracy: 0.5818\n",
      "Training: batch 4 begins at 14:54:57.245897\n",
      "\n",
      "Training: batch 4 ends at 14:54:58.831510\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.3475 - accuracy: 0.5802\n",
      "Training: batch 5 begins at 14:54:58.832737\n",
      "\n",
      "Training: batch 5 ends at 14:55:00.412216\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3533 - accuracy: 0.5681\n",
      "Training: batch 6 begins at 14:55:00.413219\n",
      "\n",
      "Training: batch 6 ends at 14:55:02.018804\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3777 - accuracy: 0.5477\n",
      "Training: batch 7 begins at 14:55:02.019828\n",
      "\n",
      "Training: batch 7 ends at 14:55:03.614367\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3511 - accuracy: 0.5579\n",
      "Training: batch 8 begins at 14:55:03.615286\n",
      "\n",
      "Training: batch 8 ends at 14:55:05.215026\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.3375 - accuracy: 0.5592\n",
      "Training: batch 9 begins at 14:55:05.217113\n",
      "\n",
      "Training: batch 9 ends at 14:55:06.820112\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.3529 - accuracy: 0.5568\n",
      "Training: batch 10 begins at 14:55:06.821086\n",
      "\n",
      "Training: batch 10 ends at 14:55:08.416880\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3945 - accuracy: 0.5425\n",
      "Training: batch 11 begins at 14:55:08.417784\n",
      "\n",
      "Training: batch 11 ends at 14:55:10.022474\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.4120 - accuracy: 0.5369 \n",
      "Training: batch 12 begins at 14:55:10.023526\n",
      "\n",
      "Training: batch 12 ends at 14:55:11.614861\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.4118 - accuracy: 0.5399\n",
      "Training: batch 13 begins at 14:55:11.615902\n",
      "\n",
      "Training: batch 13 ends at 14:55:13.200693\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.4025 - accuracy: 0.5385\n",
      "Training: batch 14 begins at 14:55:13.201629\n",
      "\n",
      "Training: batch 14 ends at 14:55:14.788954\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.4062 - accuracy: 0.5319\n",
      "Training: batch 15 begins at 14:55:14.790107\n",
      "\n",
      "Training: batch 15 ends at 14:55:16.389602\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.4023 - accuracy: 0.5343\n",
      "Training: batch 16 begins at 14:55:16.390487\n",
      "\n",
      "Training: batch 16 ends at 14:55:17.962709\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.4009 - accuracy: 0.5323\n",
      "Training: batch 17 begins at 14:55:17.963681\n",
      "\n",
      "Training: batch 17 ends at 14:55:19.566177\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3967 - accuracy: 0.5341\n",
      "Evaluating: batch 0 begins at 14:55:19.576942\n",
      "\n",
      "Evaluating: batch 0 ends at 14:55:20.103803\n",
      "\n",
      "Evaluating: batch 1 begins at 14:55:20.104325\n",
      "\n",
      "Evaluating: batch 1 ends at 14:55:20.581094\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3967 - accuracy: 0.5341 - val_loss: 1.5146 - val_accuracy: 0.4424\n",
      "Epoch 22/35\n",
      "\n",
      "Training: batch 0 begins at 14:55:20.591345\n",
      "\n",
      "Training: batch 0 ends at 14:55:22.177295\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 1.2762 - accuracy: 0.5941\n",
      "Training: batch 1 begins at 14:55:22.178642\n",
      "\n",
      "Training: batch 1 ends at 14:55:23.788596\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.3158 - accuracy: 0.5724\n",
      "Training: batch 2 begins at 14:55:23.789652\n",
      "\n",
      "Training: batch 2 ends at 14:55:25.382073\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.3264 - accuracy: 0.5669\n",
      "Training: batch 3 begins at 14:55:25.382988\n",
      "\n",
      "Training: batch 3 ends at 14:55:26.968537\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.3494 - accuracy: 0.5474\n",
      "Training: batch 4 begins at 14:55:26.969509\n",
      "\n",
      "Training: batch 4 ends at 14:55:28.566342\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.4207 - accuracy: 0.5153\n",
      "Training: batch 5 begins at 14:55:28.567262\n",
      "\n",
      "Training: batch 5 ends at 14:55:30.154872\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3850 - accuracy: 0.5286\n",
      "Training: batch 6 begins at 14:55:30.155829\n",
      "\n",
      "Training: batch 6 ends at 14:55:31.734173\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3743 - accuracy: 0.5398\n",
      "Training: batch 7 begins at 14:55:31.735115\n",
      "\n",
      "Training: batch 7 ends at 14:55:33.328294\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3648 - accuracy: 0.5326\n",
      "Training: batch 8 begins at 14:55:33.329279\n",
      "\n",
      "Training: batch 8 ends at 14:55:34.905853\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.4005 - accuracy: 0.5219\n",
      "Training: batch 9 begins at 14:55:34.907021\n",
      "\n",
      "Training: batch 9 ends at 14:55:36.490493\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.3800 - accuracy: 0.5281\n",
      "Training: batch 10 begins at 14:55:36.491448\n",
      "\n",
      "Training: batch 10 ends at 14:55:38.082858\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3653 - accuracy: 0.5360\n",
      "Training: batch 11 begins at 14:55:38.083766\n",
      "\n",
      "Training: batch 11 ends at 14:55:39.663987\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.3587 - accuracy: 0.5362 \n",
      "Training: batch 12 begins at 14:55:39.664966\n",
      "\n",
      "Training: batch 12 ends at 14:55:41.280413\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.3591 - accuracy: 0.5372\n",
      "Training: batch 13 begins at 14:55:41.281433\n",
      "\n",
      "Training: batch 13 ends at 14:55:42.880315\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3642 - accuracy: 0.5378\n",
      "Training: batch 14 begins at 14:55:42.881631\n",
      "\n",
      "Training: batch 14 ends at 14:55:44.456982\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3557 - accuracy: 0.5410\n",
      "Training: batch 15 begins at 14:55:44.457951\n",
      "\n",
      "Training: batch 15 ends at 14:55:46.028012\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.3418 - accuracy: 0.5470\n",
      "Training: batch 16 begins at 14:55:46.028930\n",
      "\n",
      "Training: batch 16 ends at 14:55:47.619751\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.3529 - accuracy: 0.5438\n",
      "Training: batch 17 begins at 14:55:47.620739\n",
      "\n",
      "Training: batch 17 ends at 14:55:49.197051\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3609 - accuracy: 0.5392\n",
      "Evaluating: batch 0 begins at 14:55:49.207690\n",
      "\n",
      "Evaluating: batch 0 ends at 14:55:49.739983\n",
      "\n",
      "Evaluating: batch 1 begins at 14:55:49.740479\n",
      "\n",
      "Evaluating: batch 1 ends at 14:55:50.214841\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3609 - accuracy: 0.5392 - val_loss: 1.3387 - val_accuracy: 0.5023\n",
      "Epoch 23/35\n",
      "\n",
      "Training: batch 0 begins at 14:55:50.225056\n",
      "\n",
      "Training: batch 0 ends at 14:55:51.829025\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2366 - accuracy: 0.6172\n",
      "Training: batch 1 begins at 14:55:51.829954\n",
      "\n",
      "Training: batch 1 ends at 14:55:53.410916\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.1974 - accuracy: 0.6019\n",
      "Training: batch 2 begins at 14:55:53.411929\n",
      "\n",
      "Training: batch 2 ends at 14:55:54.964094\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.2002 - accuracy: 0.5668\n",
      "Training: batch 3 begins at 14:55:54.965496\n",
      "\n",
      "Training: batch 3 ends at 14:55:56.573554\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1994 - accuracy: 0.5786\n",
      "Training: batch 4 begins at 14:55:56.574657\n",
      "\n",
      "Training: batch 4 ends at 14:55:58.157424\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2275 - accuracy: 0.5621\n",
      "Training: batch 5 begins at 14:55:58.158437\n",
      "\n",
      "Training: batch 5 ends at 14:55:59.755321\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2582 - accuracy: 0.5563\n",
      "Training: batch 6 begins at 14:55:59.756415\n",
      "\n",
      "Training: batch 6 ends at 14:56:01.374504\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2947 - accuracy: 0.5386\n",
      "Training: batch 7 begins at 14:56:01.375550\n",
      "\n",
      "Training: batch 7 ends at 14:56:02.968812\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.2952 - accuracy: 0.5529\n",
      "Training: batch 8 begins at 14:56:02.969700\n",
      "\n",
      "Training: batch 8 ends at 14:56:04.547930\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2959 - accuracy: 0.5446\n",
      "Training: batch 9 begins at 14:56:04.548939\n",
      "\n",
      "Training: batch 9 ends at 14:56:06.110248\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2764 - accuracy: 0.5502\n",
      "Training: batch 10 begins at 14:56:06.111171\n",
      "\n",
      "Training: batch 10 ends at 14:56:07.709488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 [=================>............] - ETA: 11s - loss: 1.2604 - accuracy: 0.5554\n",
      "Training: batch 11 begins at 14:56:07.710903\n",
      "\n",
      "Training: batch 11 ends at 14:56:09.295063\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2882 - accuracy: 0.5440 \n",
      "Training: batch 12 begins at 14:56:09.296039\n",
      "\n",
      "Training: batch 12 ends at 14:56:10.875440\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.3119 - accuracy: 0.5388\n",
      "Training: batch 13 begins at 14:56:10.876504\n",
      "\n",
      "Training: batch 13 ends at 14:56:12.470644\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3102 - accuracy: 0.5419\n",
      "Training: batch 14 begins at 14:56:12.471557\n",
      "\n",
      "Training: batch 14 ends at 14:56:14.053222\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2984 - accuracy: 0.5457\n",
      "Training: batch 15 begins at 14:56:14.054234\n",
      "\n",
      "Training: batch 15 ends at 14:56:15.641205\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.3147 - accuracy: 0.5443\n",
      "Training: batch 16 begins at 14:56:15.642225\n",
      "\n",
      "Training: batch 16 ends at 14:56:17.237448\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.3186 - accuracy: 0.5444\n",
      "Training: batch 17 begins at 14:56:17.238394\n",
      "\n",
      "Training: batch 17 ends at 14:56:18.817628\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3349 - accuracy: 0.5415\n",
      "Evaluating: batch 0 begins at 14:56:18.827786\n",
      "\n",
      "Evaluating: batch 0 ends at 14:56:19.359065\n",
      "\n",
      "Evaluating: batch 1 begins at 14:56:19.359585\n",
      "\n",
      "Evaluating: batch 1 ends at 14:56:19.831844\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3349 - accuracy: 0.5415 - val_loss: 1.3664 - val_accuracy: 0.5141\n",
      "Epoch 24/35\n",
      "\n",
      "Training: batch 0 begins at 14:56:19.841755\n",
      "\n",
      "Training: batch 0 ends at 14:56:21.438230\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2200 - accuracy: 0.5685\n",
      "Training: batch 1 begins at 14:56:21.439306\n",
      "\n",
      "Training: batch 1 ends at 14:56:23.012625\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2064 - accuracy: 0.5845\n",
      "Training: batch 2 begins at 14:56:23.013535\n",
      "\n",
      "Training: batch 2 ends at 14:56:24.605399\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.2651 - accuracy: 0.5692\n",
      "Training: batch 3 begins at 14:56:24.606389\n",
      "\n",
      "Training: batch 3 ends at 14:56:26.205574\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.2462 - accuracy: 0.5779\n",
      "Training: batch 4 begins at 14:56:26.206627\n",
      "\n",
      "Training: batch 4 ends at 14:56:27.797713\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2873 - accuracy: 0.5590\n",
      "Training: batch 5 begins at 14:56:27.798866\n",
      "\n",
      "Training: batch 5 ends at 14:56:29.374313\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2968 - accuracy: 0.5532\n",
      "Training: batch 6 begins at 14:56:29.375446\n",
      "\n",
      "Training: batch 6 ends at 14:56:30.960769\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3010 - accuracy: 0.5499\n",
      "Training: batch 7 begins at 14:56:30.961759\n",
      "\n",
      "Training: batch 7 ends at 14:56:32.546446\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3312 - accuracy: 0.5448\n",
      "Training: batch 8 begins at 14:56:32.547321\n",
      "\n",
      "Training: batch 8 ends at 14:56:34.125719\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.3428 - accuracy: 0.5407\n",
      "Training: batch 9 begins at 14:56:34.126757\n",
      "\n",
      "Training: batch 9 ends at 14:56:35.725883\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.3559 - accuracy: 0.5347\n",
      "Training: batch 10 begins at 14:56:35.727128\n",
      "\n",
      "Training: batch 10 ends at 14:56:37.321763\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3618 - accuracy: 0.5335\n",
      "Training: batch 11 begins at 14:56:37.322766\n",
      "\n",
      "Training: batch 11 ends at 14:56:38.897304\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.3430 - accuracy: 0.5416 \n",
      "Training: batch 12 begins at 14:56:38.898755\n",
      "\n",
      "Training: batch 12 ends at 14:56:40.511067\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.3222 - accuracy: 0.5510\n",
      "Training: batch 13 begins at 14:56:40.512030\n",
      "\n",
      "Training: batch 13 ends at 14:56:42.095930\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3188 - accuracy: 0.5481\n",
      "Training: batch 14 begins at 14:56:42.096940\n",
      "\n",
      "Training: batch 14 ends at 14:56:43.701288\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3367 - accuracy: 0.5486\n",
      "Training: batch 15 begins at 14:56:43.702222\n",
      "\n",
      "Training: batch 15 ends at 14:56:45.291215\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.3477 - accuracy: 0.5443\n",
      "Training: batch 16 begins at 14:56:45.292249\n",
      "\n",
      "Training: batch 16 ends at 14:56:46.894654\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.3405 - accuracy: 0.5464\n",
      "Training: batch 17 begins at 14:56:46.895544\n",
      "\n",
      "Training: batch 17 ends at 14:56:48.510625\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3292 - accuracy: 0.5487\n",
      "Evaluating: batch 0 begins at 14:56:48.521143\n",
      "\n",
      "Evaluating: batch 0 ends at 14:56:49.049701\n",
      "\n",
      "Evaluating: batch 1 begins at 14:56:49.050232\n",
      "\n",
      "Evaluating: batch 1 ends at 14:56:49.524413\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3292 - accuracy: 0.5487 - val_loss: 1.3847 - val_accuracy: 0.4862\n",
      "Epoch 25/35\n",
      "\n",
      "Training: batch 0 begins at 14:56:49.534407\n",
      "\n",
      "Training: batch 0 ends at 14:56:51.144321\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.1722 - accuracy: 0.5931\n",
      "Training: batch 1 begins at 14:56:51.145202\n",
      "\n",
      "Training: batch 1 ends at 14:56:52.749500\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.1754 - accuracy: 0.6174\n",
      "Training: batch 2 begins at 14:56:52.750673\n",
      "\n",
      "Training: batch 2 ends at 14:56:54.327147\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.2289 - accuracy: 0.5959\n",
      "Training: batch 3 begins at 14:56:54.328141\n",
      "\n",
      "Training: batch 3 ends at 14:56:55.927323\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1984 - accuracy: 0.6000\n",
      "Training: batch 4 begins at 14:56:55.928266\n",
      "\n",
      "Training: batch 4 ends at 14:56:57.521020\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2206 - accuracy: 0.5827\n",
      "Training: batch 5 begins at 14:56:57.521945\n",
      "\n",
      "Training: batch 5 ends at 14:56:59.114237\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2000 - accuracy: 0.5844\n",
      "Training: batch 6 begins at 14:56:59.115496\n",
      "\n",
      "Training: batch 6 ends at 14:57:00.733266\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2292 - accuracy: 0.5776\n",
      "Training: batch 7 begins at 14:57:00.734219\n",
      "\n",
      "Training: batch 7 ends at 14:57:02.329732\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.2280 - accuracy: 0.5833\n",
      "Training: batch 8 begins at 14:57:02.330834\n",
      "\n",
      "Training: batch 8 ends at 14:57:03.935906\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2230 - accuracy: 0.5851\n",
      "Training: batch 9 begins at 14:57:03.936861\n",
      "\n",
      "Training: batch 9 ends at 14:57:05.544342\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2232 - accuracy: 0.5839\n",
      "Training: batch 10 begins at 14:57:05.545259\n",
      "\n",
      "Training: batch 10 ends at 14:57:07.112157\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2173 - accuracy: 0.5849\n",
      "Training: batch 11 begins at 14:57:07.113104\n",
      "\n",
      "Training: batch 11 ends at 14:57:08.722015\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2308 - accuracy: 0.5813 \n",
      "Training: batch 12 begins at 14:57:08.723079\n",
      "\n",
      "Training: batch 12 ends at 14:57:10.315563\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2258 - accuracy: 0.5832\n",
      "Training: batch 13 begins at 14:57:10.316521\n",
      "\n",
      "Training: batch 13 ends at 14:57:11.916370\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2345 - accuracy: 0.5818\n",
      "Training: batch 14 begins at 14:57:11.917323\n",
      "\n",
      "Training: batch 14 ends at 14:57:13.515201\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2553 - accuracy: 0.5726\n",
      "Training: batch 15 begins at 14:57:13.516110\n",
      "\n",
      "Training: batch 15 ends at 14:57:15.087090\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2842 - accuracy: 0.5609\n",
      "Training: batch 16 begins at 14:57:15.087986\n",
      "\n",
      "Training: batch 16 ends at 14:57:16.686471\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.3137 - accuracy: 0.5485\n",
      "Training: batch 17 begins at 14:57:16.687441\n",
      "\n",
      "Training: batch 17 ends at 14:57:18.278345\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3280 - accuracy: 0.5425\n",
      "Evaluating: batch 0 begins at 14:57:18.289019\n",
      "\n",
      "Evaluating: batch 0 ends at 14:57:18.827346\n",
      "\n",
      "Evaluating: batch 1 begins at 14:57:18.827890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: batch 1 ends at 14:57:19.300904\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3280 - accuracy: 0.5425 - val_loss: 1.2860 - val_accuracy: 0.5752\n",
      "Epoch 26/35\n",
      "\n",
      "Training: batch 0 begins at 14:57:19.310820\n",
      "\n",
      "Training: batch 0 ends at 14:57:20.902034\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.4181 - accuracy: 0.5434\n",
      "Training: batch 1 begins at 14:57:20.903071\n",
      "\n",
      "Training: batch 1 ends at 14:57:22.510915\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.3559 - accuracy: 0.5800\n",
      "Training: batch 2 begins at 14:57:22.511841\n",
      "\n",
      "Training: batch 2 ends at 14:57:24.099345\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.3367 - accuracy: 0.5695\n",
      "Training: batch 3 begins at 14:57:24.100351\n",
      "\n",
      "Training: batch 3 ends at 14:57:25.704059\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.3131 - accuracy: 0.5726\n",
      "Training: batch 4 begins at 14:57:25.705357\n",
      "\n",
      "Training: batch 4 ends at 14:57:27.291839\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.3267 - accuracy: 0.5576\n",
      "Training: batch 5 begins at 14:57:27.292924\n",
      "\n",
      "Training: batch 5 ends at 14:57:28.911161\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3589 - accuracy: 0.5349\n",
      "Training: batch 6 begins at 14:57:28.912127\n",
      "\n",
      "Training: batch 6 ends at 14:57:30.516428\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3564 - accuracy: 0.5402\n",
      "Training: batch 7 begins at 14:57:30.517325\n",
      "\n",
      "Training: batch 7 ends at 14:57:32.108511\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.3767 - accuracy: 0.5280\n",
      "Training: batch 8 begins at 14:57:32.109427\n",
      "\n",
      "Training: batch 8 ends at 14:57:33.703274\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.3631 - accuracy: 0.5322\n",
      "Training: batch 9 begins at 14:57:33.704251\n",
      "\n",
      "Training: batch 9 ends at 14:57:35.296677\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.3885 - accuracy: 0.5253\n",
      "Training: batch 10 begins at 14:57:35.297636\n",
      "\n",
      "Training: batch 10 ends at 14:57:36.898682\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3793 - accuracy: 0.5229\n",
      "Training: batch 11 begins at 14:57:36.899656\n",
      "\n",
      "Training: batch 11 ends at 14:57:38.464045\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.3958 - accuracy: 0.5176 \n",
      "Training: batch 12 begins at 14:57:38.464934\n",
      "\n",
      "Training: batch 12 ends at 14:57:40.066271\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.3727 - accuracy: 0.5260\n",
      "Training: batch 13 begins at 14:57:40.067164\n",
      "\n",
      "Training: batch 13 ends at 14:57:41.649504\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3619 - accuracy: 0.5266\n",
      "Training: batch 14 begins at 14:57:41.650685\n",
      "\n",
      "Training: batch 14 ends at 14:57:43.258060\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3635 - accuracy: 0.5236\n",
      "Training: batch 15 begins at 14:57:43.258981\n",
      "\n",
      "Training: batch 15 ends at 14:57:44.872530\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.3597 - accuracy: 0.5223\n",
      "Training: batch 16 begins at 14:57:44.873461\n",
      "\n",
      "Training: batch 16 ends at 14:57:46.463352\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.3727 - accuracy: 0.5178\n",
      "Training: batch 17 begins at 14:57:46.464222\n",
      "\n",
      "Training: batch 17 ends at 14:57:48.067618\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3764 - accuracy: 0.5170\n",
      "Evaluating: batch 0 begins at 14:57:48.077793\n",
      "\n",
      "Evaluating: batch 0 ends at 14:57:48.608641\n",
      "\n",
      "Evaluating: batch 1 begins at 14:57:48.609135\n",
      "\n",
      "Evaluating: batch 1 ends at 14:57:49.079770\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3764 - accuracy: 0.5170 - val_loss: 1.4046 - val_accuracy: 0.5129\n",
      "Epoch 27/35\n",
      "\n",
      "Training: batch 0 begins at 14:57:49.089538\n",
      "\n",
      "Training: batch 0 ends at 14:57:50.667824\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 1.4234 - accuracy: 0.5711\n",
      "Training: batch 1 begins at 14:57:50.668818\n",
      "\n",
      "Training: batch 1 ends at 14:57:52.268468\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.3136 - accuracy: 0.5813\n",
      "Training: batch 2 begins at 14:57:52.269587\n",
      "\n",
      "Training: batch 2 ends at 14:57:53.874778\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.3705 - accuracy: 0.5624\n",
      "Training: batch 3 begins at 14:57:53.875702\n",
      "\n",
      "Training: batch 3 ends at 14:57:55.465159\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.3326 - accuracy: 0.5626\n",
      "Training: batch 4 begins at 14:57:55.466061\n",
      "\n",
      "Training: batch 4 ends at 14:57:57.063225\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.3030 - accuracy: 0.5681\n",
      "Training: batch 5 begins at 14:57:57.064171\n",
      "\n",
      "Training: batch 5 ends at 14:57:58.666389\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3207 - accuracy: 0.5715\n",
      "Training: batch 6 begins at 14:57:58.667342\n",
      "\n",
      "Training: batch 6 ends at 14:58:00.251894\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3029 - accuracy: 0.5792\n",
      "Training: batch 7 begins at 14:58:00.253002\n",
      "\n",
      "Training: batch 7 ends at 14:58:01.842857\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.2779 - accuracy: 0.5915\n",
      "Training: batch 8 begins at 14:58:01.843773\n",
      "\n",
      "Training: batch 8 ends at 14:58:03.423938\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2855 - accuracy: 0.5838\n",
      "Training: batch 9 begins at 14:58:03.424950\n",
      "\n",
      "Training: batch 9 ends at 14:58:05.023328\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2658 - accuracy: 0.5908\n",
      "Training: batch 10 begins at 14:58:05.024233\n",
      "\n",
      "Training: batch 10 ends at 14:58:06.601086\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3219 - accuracy: 0.5739\n",
      "Training: batch 11 begins at 14:58:06.602023\n",
      "\n",
      "Training: batch 11 ends at 14:58:08.184204\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.3201 - accuracy: 0.5738 \n",
      "Training: batch 12 begins at 14:58:08.185110\n",
      "\n",
      "Training: batch 12 ends at 14:58:09.754131\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.3418 - accuracy: 0.5640\n",
      "Training: batch 13 begins at 14:58:09.755141\n",
      "\n",
      "Training: batch 13 ends at 14:58:11.361985\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3422 - accuracy: 0.5656\n",
      "Training: batch 14 begins at 14:58:11.362940\n",
      "\n",
      "Training: batch 14 ends at 14:58:12.962730\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3553 - accuracy: 0.5600\n",
      "Training: batch 15 begins at 14:58:12.963648\n",
      "\n",
      "Training: batch 15 ends at 14:58:14.557161\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.3494 - accuracy: 0.5585\n",
      "Training: batch 16 begins at 14:58:14.558106\n",
      "\n",
      "Training: batch 16 ends at 14:58:16.140212\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.3524 - accuracy: 0.5587\n",
      "Training: batch 17 begins at 14:58:16.141285\n",
      "\n",
      "Training: batch 17 ends at 14:58:17.729586\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3436 - accuracy: 0.5579\n",
      "Evaluating: batch 0 begins at 14:58:17.740443\n",
      "\n",
      "Evaluating: batch 0 ends at 14:58:18.282803\n",
      "\n",
      "Evaluating: batch 1 begins at 14:58:18.283273\n",
      "\n",
      "Evaluating: batch 1 ends at 14:58:18.764676\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3436 - accuracy: 0.5579 - val_loss: 1.2820 - val_accuracy: 0.5526\n",
      "Epoch 28/35\n",
      "\n",
      "Training: batch 0 begins at 14:58:18.774953\n",
      "\n",
      "Training: batch 0 ends at 14:58:20.385711\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2526 - accuracy: 0.5859\n",
      "Training: batch 1 begins at 14:58:20.386736\n",
      "\n",
      "Training: batch 1 ends at 14:58:21.949315\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2716 - accuracy: 0.5972\n",
      "Training: batch 2 begins at 14:58:21.950224\n",
      "\n",
      "Training: batch 2 ends at 14:58:23.530015\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.2363 - accuracy: 0.6014\n",
      "Training: batch 3 begins at 14:58:23.530901\n",
      "\n",
      "Training: batch 3 ends at 14:58:25.124429\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1884 - accuracy: 0.6138\n",
      "Training: batch 4 begins at 14:58:25.125588\n",
      "\n",
      "Training: batch 4 ends at 14:58:26.723920\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2527 - accuracy: 0.5919\n",
      "Training: batch 5 begins at 14:58:26.724844\n",
      "\n",
      "Training: batch 5 ends at 14:58:28.323303\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.1926 - accuracy: 0.6125\n",
      "Training: batch 6 begins at 14:58:28.324343\n",
      "\n",
      "Training: batch 6 ends at 14:58:29.918599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2405 - accuracy: 0.5989\n",
      "Training: batch 7 begins at 14:58:29.919598\n",
      "\n",
      "Training: batch 7 ends at 14:58:31.481879\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.2601 - accuracy: 0.5859\n",
      "Training: batch 8 begins at 14:58:31.482928\n",
      "\n",
      "Training: batch 8 ends at 14:58:33.065299\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2571 - accuracy: 0.5815\n",
      "Training: batch 9 begins at 14:58:33.066290\n",
      "\n",
      "Training: batch 9 ends at 14:58:34.647181\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2680 - accuracy: 0.5749\n",
      "Training: batch 10 begins at 14:58:34.648229\n",
      "\n",
      "Training: batch 10 ends at 14:58:36.239978\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2919 - accuracy: 0.5682\n",
      "Training: batch 11 begins at 14:58:36.240948\n",
      "\n",
      "Training: batch 11 ends at 14:58:37.846848\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2894 - accuracy: 0.5686 \n",
      "Training: batch 12 begins at 14:58:37.847878\n",
      "\n",
      "Training: batch 12 ends at 14:58:39.449323\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2737 - accuracy: 0.5742\n",
      "Training: batch 13 begins at 14:58:39.450433\n",
      "\n",
      "Training: batch 13 ends at 14:58:41.049434\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2752 - accuracy: 0.5724\n",
      "Training: batch 14 begins at 14:58:41.050347\n",
      "\n",
      "Training: batch 14 ends at 14:58:42.637583\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2716 - accuracy: 0.5714\n",
      "Training: batch 15 begins at 14:58:42.638555\n",
      "\n",
      "Training: batch 15 ends at 14:58:44.229441\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2835 - accuracy: 0.5674\n",
      "Training: batch 16 begins at 14:58:44.230389\n",
      "\n",
      "Training: batch 16 ends at 14:58:45.799332\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2944 - accuracy: 0.5621\n",
      "Training: batch 17 begins at 14:58:45.800210\n",
      "\n",
      "Training: batch 17 ends at 14:58:47.381390\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2850 - accuracy: 0.5669\n",
      "Evaluating: batch 0 begins at 14:58:47.392237\n",
      "\n",
      "Evaluating: batch 0 ends at 14:58:47.922383\n",
      "\n",
      "Evaluating: batch 1 begins at 14:58:47.922890\n",
      "\n",
      "Evaluating: batch 1 ends at 14:58:48.399813\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2850 - accuracy: 0.5669 - val_loss: 1.2446 - val_accuracy: 0.5929\n",
      "Epoch 29/35\n",
      "\n",
      "Training: batch 0 begins at 14:58:48.410178\n",
      "\n",
      "Training: batch 0 ends at 14:58:50.013697\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2177 - accuracy: 0.6374\n",
      "Training: batch 1 begins at 14:58:50.014602\n",
      "\n",
      "Training: batch 1 ends at 14:58:51.576306\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2835 - accuracy: 0.5545\n",
      "Training: batch 2 begins at 14:58:51.577316\n",
      "\n",
      "Training: batch 2 ends at 14:58:53.176834\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.2794 - accuracy: 0.5716\n",
      "Training: batch 3 begins at 14:58:53.177909\n",
      "\n",
      "Training: batch 3 ends at 14:58:54.786206\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.2818 - accuracy: 0.5870\n",
      "Training: batch 4 begins at 14:58:54.787117\n",
      "\n",
      "Training: batch 4 ends at 14:58:56.383419\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.3138 - accuracy: 0.5633\n",
      "Training: batch 5 begins at 14:58:56.384332\n",
      "\n",
      "Training: batch 5 ends at 14:58:57.972954\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3006 - accuracy: 0.5615\n",
      "Training: batch 6 begins at 14:58:57.973864\n",
      "\n",
      "Training: batch 6 ends at 14:58:59.561789\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3175 - accuracy: 0.5617\n",
      "Training: batch 7 begins at 14:58:59.562692\n",
      "\n",
      "Training: batch 7 ends at 14:59:01.156908\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3022 - accuracy: 0.5671\n",
      "Training: batch 8 begins at 14:59:01.159228\n",
      "\n",
      "Training: batch 8 ends at 14:59:02.775349\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2943 - accuracy: 0.5701\n",
      "Training: batch 9 begins at 14:59:02.776276\n",
      "\n",
      "Training: batch 9 ends at 14:59:04.356496\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2924 - accuracy: 0.5694\n",
      "Training: batch 10 begins at 14:59:04.357441\n",
      "\n",
      "Training: batch 10 ends at 14:59:05.959300\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2816 - accuracy: 0.5712\n",
      "Training: batch 11 begins at 14:59:05.960264\n",
      "\n",
      "Training: batch 11 ends at 14:59:07.545624\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2909 - accuracy: 0.5662 \n",
      "Training: batch 12 begins at 14:59:07.546667\n",
      "\n",
      "Training: batch 12 ends at 14:59:09.114071\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2877 - accuracy: 0.5721\n",
      "Training: batch 13 begins at 14:59:09.114974\n",
      "\n",
      "Training: batch 13 ends at 14:59:10.720765\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3029 - accuracy: 0.5684\n",
      "Training: batch 14 begins at 14:59:10.721780\n",
      "\n",
      "Training: batch 14 ends at 14:59:12.295372\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3100 - accuracy: 0.5614\n",
      "Training: batch 15 begins at 14:59:12.296312\n",
      "\n",
      "Training: batch 15 ends at 14:59:13.917877\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2907 - accuracy: 0.5709\n",
      "Training: batch 16 begins at 14:59:13.918828\n",
      "\n",
      "Training: batch 16 ends at 14:59:15.507806\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2812 - accuracy: 0.5763\n",
      "Training: batch 17 begins at 14:59:15.508736\n",
      "\n",
      "Training: batch 17 ends at 14:59:17.096928\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2904 - accuracy: 0.5699\n",
      "Evaluating: batch 0 begins at 14:59:17.107724\n",
      "\n",
      "Evaluating: batch 0 ends at 14:59:17.634003\n",
      "\n",
      "Evaluating: batch 1 begins at 14:59:17.634542\n",
      "\n",
      "Evaluating: batch 1 ends at 14:59:18.113780\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2904 - accuracy: 0.5699 - val_loss: 1.3732 - val_accuracy: 0.5045\n",
      "Epoch 30/35\n",
      "\n",
      "Training: batch 0 begins at 14:59:18.124007\n",
      "\n",
      "Training: batch 0 ends at 14:59:19.720970\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.4125 - accuracy: 0.5265\n",
      "Training: batch 1 begins at 14:59:19.723516\n",
      "\n",
      "Training: batch 1 ends at 14:59:21.343026\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2299 - accuracy: 0.5955\n",
      "Training: batch 2 begins at 14:59:21.343917\n",
      "\n",
      "Training: batch 2 ends at 14:59:22.913551\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.3513 - accuracy: 0.5151\n",
      "Training: batch 3 begins at 14:59:22.914496\n",
      "\n",
      "Training: batch 3 ends at 14:59:24.523317\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.3253 - accuracy: 0.5282\n",
      "Training: batch 4 begins at 14:59:24.524903\n",
      "\n",
      "Training: batch 4 ends at 14:59:26.138178\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2369 - accuracy: 0.5684\n",
      "Training: batch 5 begins at 14:59:26.139105\n",
      "\n",
      "Training: batch 5 ends at 14:59:27.751157\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2119 - accuracy: 0.5711\n",
      "Training: batch 6 begins at 14:59:27.752093\n",
      "\n",
      "Training: batch 6 ends at 14:59:29.347952\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2084 - accuracy: 0.5751\n",
      "Training: batch 7 begins at 14:59:29.348922\n",
      "\n",
      "Training: batch 7 ends at 14:59:30.953904\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.2079 - accuracy: 0.5751\n",
      "Training: batch 8 begins at 14:59:30.954977\n",
      "\n",
      "Training: batch 8 ends at 14:59:32.537468\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2362 - accuracy: 0.5683\n",
      "Training: batch 9 begins at 14:59:32.538417\n",
      "\n",
      "Training: batch 9 ends at 14:59:34.133552\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2378 - accuracy: 0.5662\n",
      "Training: batch 10 begins at 14:59:34.134463\n",
      "\n",
      "Training: batch 10 ends at 14:59:35.719664\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2466 - accuracy: 0.5657\n",
      "Training: batch 11 begins at 14:59:35.720619\n",
      "\n",
      "Training: batch 11 ends at 14:59:37.301468\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2555 - accuracy: 0.5624 \n",
      "Training: batch 12 begins at 14:59:37.302423\n",
      "\n",
      "Training: batch 12 ends at 14:59:38.898690\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2540 - accuracy: 0.5664\n",
      "Training: batch 13 begins at 14:59:38.899797\n",
      "\n",
      "Training: batch 13 ends at 14:59:40.472658\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2410 - accuracy: 0.5679\n",
      "Training: batch 14 begins at 14:59:40.473620\n",
      "\n",
      "Training: batch 14 ends at 14:59:42.053448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2624 - accuracy: 0.5594\n",
      "Training: batch 15 begins at 14:59:42.054535\n",
      "\n",
      "Training: batch 15 ends at 14:59:43.658927\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2730 - accuracy: 0.5576\n",
      "Training: batch 16 begins at 14:59:43.660139\n",
      "\n",
      "Training: batch 16 ends at 14:59:45.246757\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2765 - accuracy: 0.5561\n",
      "Training: batch 17 begins at 14:59:45.247745\n",
      "\n",
      "Training: batch 17 ends at 14:59:46.842062\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2682 - accuracy: 0.5632\n",
      "Evaluating: batch 0 begins at 14:59:46.852324\n",
      "\n",
      "Evaluating: batch 0 ends at 14:59:47.380136\n",
      "\n",
      "Evaluating: batch 1 begins at 14:59:47.380660\n",
      "\n",
      "Evaluating: batch 1 ends at 14:59:47.855745\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2682 - accuracy: 0.5632 - val_loss: 1.2581 - val_accuracy: 0.5687\n",
      "Epoch 31/35\n",
      "\n",
      "Training: batch 0 begins at 14:59:47.865784\n",
      "\n",
      "Training: batch 0 ends at 14:59:49.453841\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.4574 - accuracy: 0.4568\n",
      "Training: batch 1 begins at 14:59:49.454934\n",
      "\n",
      "Training: batch 1 ends at 14:59:51.073829\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2675 - accuracy: 0.5588\n",
      "Training: batch 2 begins at 14:59:51.075038\n",
      "\n",
      "Training: batch 2 ends at 14:59:52.661178\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.2774 - accuracy: 0.5676\n",
      "Training: batch 3 begins at 14:59:52.662144\n",
      "\n",
      "Training: batch 3 ends at 14:59:54.264444\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.2530 - accuracy: 0.5714\n",
      "Training: batch 4 begins at 14:59:54.265516\n",
      "\n",
      "Training: batch 4 ends at 14:59:55.849518\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2761 - accuracy: 0.5678\n",
      "Training: batch 5 begins at 14:59:55.850471\n",
      "\n",
      "Training: batch 5 ends at 14:59:57.428526\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2946 - accuracy: 0.5698\n",
      "Training: batch 6 begins at 14:59:57.429531\n",
      "\n",
      "Training: batch 6 ends at 14:59:59.034913\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3072 - accuracy: 0.5677\n",
      "Training: batch 7 begins at 14:59:59.035791\n",
      "\n",
      "Training: batch 7 ends at 15:00:00.637467\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3301 - accuracy: 0.5569\n",
      "Training: batch 8 begins at 15:00:00.638447\n",
      "\n",
      "Training: batch 8 ends at 15:00:02.247897\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.3377 - accuracy: 0.5539\n",
      "Training: batch 9 begins at 15:00:02.248810\n",
      "\n",
      "Training: batch 9 ends at 15:00:03.818353\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.3092 - accuracy: 0.5646\n",
      "Training: batch 10 begins at 15:00:03.819379\n",
      "\n",
      "Training: batch 10 ends at 15:00:05.401904\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3100 - accuracy: 0.5613\n",
      "Training: batch 11 begins at 15:00:05.403091\n",
      "\n",
      "Training: batch 11 ends at 15:00:06.997957\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.3113 - accuracy: 0.5571 \n",
      "Training: batch 12 begins at 15:00:06.998909\n",
      "\n",
      "Training: batch 12 ends at 15:00:08.566765\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.3055 - accuracy: 0.5615\n",
      "Training: batch 13 begins at 15:00:08.567793\n",
      "\n",
      "Training: batch 13 ends at 15:00:10.135388\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2999 - accuracy: 0.5666\n",
      "Training: batch 14 begins at 15:00:10.136241\n",
      "\n",
      "Training: batch 14 ends at 15:00:11.734970\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3051 - accuracy: 0.5591\n",
      "Training: batch 15 begins at 15:00:11.735915\n",
      "\n",
      "Training: batch 15 ends at 15:00:13.318975\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.3047 - accuracy: 0.5606\n",
      "Training: batch 16 begins at 15:00:13.320031\n",
      "\n",
      "Training: batch 16 ends at 15:00:14.902814\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.3036 - accuracy: 0.5599\n",
      "Training: batch 17 begins at 15:00:14.903806\n",
      "\n",
      "Training: batch 17 ends at 15:00:16.495062\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3001 - accuracy: 0.5609\n",
      "Evaluating: batch 0 begins at 15:00:16.505718\n",
      "\n",
      "Evaluating: batch 0 ends at 15:00:17.035010\n",
      "\n",
      "Evaluating: batch 1 begins at 15:00:17.035509\n",
      "\n",
      "Evaluating: batch 1 ends at 15:00:17.518628\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3001 - accuracy: 0.5609 - val_loss: 1.5322 - val_accuracy: 0.4578\n",
      "Epoch 32/35\n",
      "\n",
      "Training: batch 0 begins at 15:00:17.528731\n",
      "\n",
      "Training: batch 0 ends at 15:00:19.140317\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.5871 - accuracy: 0.4244\n",
      "Training: batch 1 begins at 15:00:19.141297\n",
      "\n",
      "Training: batch 1 ends at 15:00:20.738939\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.4048 - accuracy: 0.5310\n",
      "Training: batch 2 begins at 15:00:20.740616\n",
      "\n",
      "Training: batch 2 ends at 15:00:22.371401\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.4046 - accuracy: 0.4984\n",
      "Training: batch 3 begins at 15:00:22.372382\n",
      "\n",
      "Training: batch 3 ends at 15:00:23.969614\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.3702 - accuracy: 0.5026\n",
      "Training: batch 4 begins at 15:00:23.970742\n",
      "\n",
      "Training: batch 4 ends at 15:00:25.576393\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.3419 - accuracy: 0.5106\n",
      "Training: batch 5 begins at 15:00:25.577330\n",
      "\n",
      "Training: batch 5 ends at 15:00:27.164495\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3547 - accuracy: 0.5100\n",
      "Training: batch 6 begins at 15:00:27.165437\n",
      "\n",
      "Training: batch 6 ends at 15:00:28.758524\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3503 - accuracy: 0.5169\n",
      "Training: batch 7 begins at 15:00:28.759463\n",
      "\n",
      "Training: batch 7 ends at 15:00:30.373930\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.3683 - accuracy: 0.5180\n",
      "Training: batch 8 begins at 15:00:30.374838\n",
      "\n",
      "Training: batch 8 ends at 15:00:31.964367\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.3509 - accuracy: 0.5198\n",
      "Training: batch 9 begins at 15:00:31.965293\n",
      "\n",
      "Training: batch 9 ends at 15:00:33.550805\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.3506 - accuracy: 0.5201\n",
      "Training: batch 10 begins at 15:00:33.551864\n",
      "\n",
      "Training: batch 10 ends at 15:00:35.151523\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3323 - accuracy: 0.5287\n",
      "Training: batch 11 begins at 15:00:35.152487\n",
      "\n",
      "Training: batch 11 ends at 15:00:36.756497\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.3257 - accuracy: 0.5307 \n",
      "Training: batch 12 begins at 15:00:36.757694\n",
      "\n",
      "Training: batch 12 ends at 15:00:38.397284\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.3364 - accuracy: 0.5264\n",
      "Training: batch 13 begins at 15:00:38.398448\n",
      "\n",
      "Training: batch 13 ends at 15:00:39.995252\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3240 - accuracy: 0.5289\n",
      "Training: batch 14 begins at 15:00:39.996267\n",
      "\n",
      "Training: batch 14 ends at 15:00:41.580402\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3193 - accuracy: 0.5354\n",
      "Training: batch 15 begins at 15:00:41.581453\n",
      "\n",
      "Training: batch 15 ends at 15:00:43.187202\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.3043 - accuracy: 0.5434\n",
      "Training: batch 16 begins at 15:00:43.188307\n",
      "\n",
      "Training: batch 16 ends at 15:00:44.759017\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.3165 - accuracy: 0.5397\n",
      "Training: batch 17 begins at 15:00:44.759901\n",
      "\n",
      "Training: batch 17 ends at 15:00:46.375496\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3239 - accuracy: 0.5366\n",
      "Evaluating: batch 0 begins at 15:00:46.385636\n",
      "\n",
      "Evaluating: batch 0 ends at 15:00:46.916414\n",
      "\n",
      "Evaluating: batch 1 begins at 15:00:46.916943\n",
      "\n",
      "Evaluating: batch 1 ends at 15:00:47.388169\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3239 - accuracy: 0.5366 - val_loss: 1.2915 - val_accuracy: 0.5057\n",
      "Epoch 33/35\n",
      "\n",
      "Training: batch 0 begins at 15:00:47.398303\n",
      "\n",
      "Training: batch 0 ends at 15:00:48.997569\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2981 - accuracy: 0.5295\n",
      "Training: batch 1 begins at 15:00:48.998535\n",
      "\n",
      "Training: batch 1 ends at 15:00:50.578954\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2013 - accuracy: 0.5725\n",
      "Training: batch 2 begins at 15:00:50.580071\n",
      "\n",
      "Training: batch 2 ends at 15:00:52.163285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.1422 - accuracy: 0.6066\n",
      "Training: batch 3 begins at 15:00:52.164290\n",
      "\n",
      "Training: batch 3 ends at 15:00:53.765194\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1669 - accuracy: 0.5970\n",
      "Training: batch 4 begins at 15:00:53.766182\n",
      "\n",
      "Training: batch 4 ends at 15:00:55.373355\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2054 - accuracy: 0.5763\n",
      "Training: batch 5 begins at 15:00:55.374769\n",
      "\n",
      "Training: batch 5 ends at 15:00:56.991828\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2457 - accuracy: 0.5710\n",
      "Training: batch 6 begins at 15:00:56.992846\n",
      "\n",
      "Training: batch 6 ends at 15:00:58.583793\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2505 - accuracy: 0.5662\n",
      "Training: batch 7 begins at 15:00:58.584712\n",
      "\n",
      "Training: batch 7 ends at 15:01:00.177487\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.2342 - accuracy: 0.5690\n",
      "Training: batch 8 begins at 15:01:00.178485\n",
      "\n",
      "Training: batch 8 ends at 15:01:01.781679\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2354 - accuracy: 0.5738\n",
      "Training: batch 9 begins at 15:01:01.782567\n",
      "\n",
      "Training: batch 9 ends at 15:01:03.370907\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2661 - accuracy: 0.5639\n",
      "Training: batch 10 begins at 15:01:03.372861\n",
      "\n",
      "Training: batch 10 ends at 15:01:04.987625\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2848 - accuracy: 0.5582\n",
      "Training: batch 11 begins at 15:01:04.988525\n",
      "\n",
      "Training: batch 11 ends at 15:01:06.569380\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2763 - accuracy: 0.5622 \n",
      "Training: batch 12 begins at 15:01:06.570535\n",
      "\n",
      "Training: batch 12 ends at 15:01:08.162809\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2834 - accuracy: 0.5586\n",
      "Training: batch 13 begins at 15:01:08.163729\n",
      "\n",
      "Training: batch 13 ends at 15:01:09.775324\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2670 - accuracy: 0.5645\n",
      "Training: batch 14 begins at 15:01:09.776230\n",
      "\n",
      "Training: batch 14 ends at 15:01:11.389377\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2614 - accuracy: 0.5659\n",
      "Training: batch 15 begins at 15:01:11.390346\n",
      "\n",
      "Training: batch 15 ends at 15:01:12.993752\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2722 - accuracy: 0.5630\n",
      "Training: batch 16 begins at 15:01:12.994888\n",
      "\n",
      "Training: batch 16 ends at 15:01:14.571428\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2740 - accuracy: 0.5639\n",
      "Training: batch 17 begins at 15:01:14.572393\n",
      "\n",
      "Training: batch 17 ends at 15:01:16.168159\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2876 - accuracy: 0.5613\n",
      "Evaluating: batch 0 begins at 15:01:16.178645\n",
      "\n",
      "Evaluating: batch 0 ends at 15:01:16.709020\n",
      "\n",
      "Evaluating: batch 1 begins at 15:01:16.709522\n",
      "\n",
      "Evaluating: batch 1 ends at 15:01:17.188659\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2876 - accuracy: 0.5613 - val_loss: 1.3479 - val_accuracy: 0.5291\n",
      "Epoch 34/35\n",
      "\n",
      "Training: batch 0 begins at 15:01:17.198649\n",
      "\n",
      "Training: batch 0 ends at 15:01:18.798227\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.6792 - accuracy: 0.3963\n",
      "Training: batch 1 begins at 15:01:18.799221\n",
      "\n",
      "Training: batch 1 ends at 15:01:20.396307\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.4614 - accuracy: 0.4487\n",
      "Training: batch 2 begins at 15:01:20.397237\n",
      "\n",
      "Training: batch 2 ends at 15:01:21.985039\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.3714 - accuracy: 0.4883\n",
      "Training: batch 3 begins at 15:01:21.986059\n",
      "\n",
      "Training: batch 3 ends at 15:01:23.530818\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.3578 - accuracy: 0.5102\n",
      "Training: batch 4 begins at 15:01:23.531972\n",
      "\n",
      "Training: batch 4 ends at 15:01:25.136097\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.3430 - accuracy: 0.5174\n",
      "Training: batch 5 begins at 15:01:25.137094\n",
      "\n",
      "Training: batch 5 ends at 15:01:26.737850\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3445 - accuracy: 0.5258\n",
      "Training: batch 6 begins at 15:01:26.738914\n",
      "\n",
      "Training: batch 6 ends at 15:01:28.371599\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3456 - accuracy: 0.5213\n",
      "Training: batch 7 begins at 15:01:28.372544\n",
      "\n",
      "Training: batch 7 ends at 15:01:29.950227\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3213 - accuracy: 0.5293\n",
      "Training: batch 8 begins at 15:01:29.951245\n",
      "\n",
      "Training: batch 8 ends at 15:01:31.501529\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2889 - accuracy: 0.5414\n",
      "Training: batch 9 begins at 15:01:31.502480\n",
      "\n",
      "Training: batch 9 ends at 15:01:33.096523\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2719 - accuracy: 0.5517\n",
      "Training: batch 10 begins at 15:01:33.097569\n",
      "\n",
      "Training: batch 10 ends at 15:01:34.678613\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2747 - accuracy: 0.5557\n",
      "Training: batch 11 begins at 15:01:34.679791\n",
      "\n",
      "Training: batch 11 ends at 15:01:36.286138\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2642 - accuracy: 0.5621 \n",
      "Training: batch 12 begins at 15:01:36.287118\n",
      "\n",
      "Training: batch 12 ends at 15:01:37.877628\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2714 - accuracy: 0.5606\n",
      "Training: batch 13 begins at 15:01:37.878544\n",
      "\n",
      "Training: batch 13 ends at 15:01:39.474605\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2684 - accuracy: 0.5592\n",
      "Training: batch 14 begins at 15:01:39.475601\n",
      "\n",
      "Training: batch 14 ends at 15:01:41.028571\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2575 - accuracy: 0.5661\n",
      "Training: batch 15 begins at 15:01:41.029480\n",
      "\n",
      "Training: batch 15 ends at 15:01:42.629177\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2514 - accuracy: 0.5704\n",
      "Training: batch 16 begins at 15:01:42.630117\n",
      "\n",
      "Training: batch 16 ends at 15:01:44.224265\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2684 - accuracy: 0.5662\n",
      "Training: batch 17 begins at 15:01:44.225272\n",
      "\n",
      "Training: batch 17 ends at 15:01:45.809476\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2694 - accuracy: 0.5659\n",
      "Evaluating: batch 0 begins at 15:01:45.820045\n",
      "\n",
      "Evaluating: batch 0 ends at 15:01:46.345877\n",
      "\n",
      "Evaluating: batch 1 begins at 15:01:46.346377\n",
      "\n",
      "Evaluating: batch 1 ends at 15:01:46.823356\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2694 - accuracy: 0.5659 - val_loss: 1.1973 - val_accuracy: 0.6095\n",
      "Epoch 35/35\n",
      "\n",
      "Training: batch 0 begins at 15:01:46.833526\n",
      "\n",
      "Training: batch 0 ends at 15:01:48.418606\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 1.1146 - accuracy: 0.6564\n",
      "Training: batch 1 begins at 15:01:48.419682\n",
      "\n",
      "Training: batch 1 ends at 15:01:50.006865\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.3209 - accuracy: 0.5778\n",
      "Training: batch 2 begins at 15:01:50.007847\n",
      "\n",
      "Training: batch 2 ends at 15:01:51.606600\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.3589 - accuracy: 0.5491\n",
      "Training: batch 3 begins at 15:01:51.607546\n",
      "\n",
      "Training: batch 3 ends at 15:01:53.210039\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.3069 - accuracy: 0.5591\n",
      "Training: batch 4 begins at 15:01:53.210997\n",
      "\n",
      "Training: batch 4 ends at 15:01:54.811984\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.3008 - accuracy: 0.5634\n",
      "Training: batch 5 begins at 15:01:54.812928\n",
      "\n",
      "Training: batch 5 ends at 15:01:56.420175\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2938 - accuracy: 0.5636\n",
      "Training: batch 6 begins at 15:01:56.421125\n",
      "\n",
      "Training: batch 6 ends at 15:01:58.022326\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2999 - accuracy: 0.5582\n",
      "Training: batch 7 begins at 15:01:58.023410\n",
      "\n",
      "Training: batch 7 ends at 15:01:59.609964\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.2579 - accuracy: 0.5715\n",
      "Training: batch 8 begins at 15:01:59.610937\n",
      "\n",
      "Training: batch 8 ends at 15:02:01.208094\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2378 - accuracy: 0.5803\n",
      "Training: batch 9 begins at 15:02:01.209061\n",
      "\n",
      "Training: batch 9 ends at 15:02:02.793968\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2251 - accuracy: 0.5825\n",
      "Training: batch 10 begins at 15:02:02.794864\n",
      "\n",
      "Training: batch 10 ends at 15:02:04.375010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 [=================>............] - ETA: 11s - loss: 1.2298 - accuracy: 0.5832\n",
      "Training: batch 11 begins at 15:02:04.375961\n",
      "\n",
      "Training: batch 11 ends at 15:02:05.959789\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2672 - accuracy: 0.5741 \n",
      "Training: batch 12 begins at 15:02:05.960767\n",
      "\n",
      "Training: batch 12 ends at 15:02:07.522202\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2682 - accuracy: 0.5709\n",
      "Training: batch 13 begins at 15:02:07.523211\n",
      "\n",
      "Training: batch 13 ends at 15:02:09.091138\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2648 - accuracy: 0.5663\n",
      "Training: batch 14 begins at 15:02:09.092187\n",
      "\n",
      "Training: batch 14 ends at 15:02:10.675662\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2605 - accuracy: 0.5677\n",
      "Training: batch 15 begins at 15:02:10.676604\n",
      "\n",
      "Training: batch 15 ends at 15:02:12.263995\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2677 - accuracy: 0.5657\n",
      "Training: batch 16 begins at 15:02:12.264996\n",
      "\n",
      "Training: batch 16 ends at 15:02:13.832356\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2597 - accuracy: 0.5682\n",
      "Training: batch 17 begins at 15:02:13.833305\n",
      "\n",
      "Training: batch 17 ends at 15:02:15.412182\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2602 - accuracy: 0.5688\n",
      "Evaluating: batch 0 begins at 15:02:15.422277\n",
      "\n",
      "Evaluating: batch 0 ends at 15:02:15.937925\n",
      "\n",
      "Evaluating: batch 1 begins at 15:02:15.938442\n",
      "\n",
      "Evaluating: batch 1 ends at 15:02:16.407768\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2602 - accuracy: 0.5688 - val_loss: 1.1843 - val_accuracy: 0.5998\n",
      "Saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 15:02:16.928665: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/training_15/assets\n",
      "Saved the model at saved_models/training_15/\n",
      " EPACHS set to  35\n",
      "UNet model loaded from  saved_models/training_15/\n",
      "Reading train data\n",
      "x train ----  90\n",
      "x val ----  10\n",
      "Train and Validation data created\n",
      "Epoch 1/35\n",
      "\n",
      "Training: batch 0 begins at 15:02:37.134705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 15:02:37.429658: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: batch 0 ends at 15:02:39.684303\n",
      " 1/18 [>.............................] - ETA: 43s - loss: 1.0518 - accuracy: 0.6406\n",
      "Training: batch 1 begins at 15:02:39.701202\n",
      "\n",
      "Training: batch 1 ends at 15:02:41.292446\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.5610 - accuracy: 0.5156\n",
      "Training: batch 2 begins at 15:02:41.293439\n",
      "\n",
      "Training: batch 2 ends at 15:02:42.903549\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.4916 - accuracy: 0.5090\n",
      "Training: batch 3 begins at 15:02:42.904538\n",
      "\n",
      "Training: batch 3 ends at 15:02:44.449159\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.4339 - accuracy: 0.5232\n",
      "Training: batch 4 begins at 15:02:44.450182\n",
      "\n",
      "Training: batch 4 ends at 15:02:46.039003\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.4333 - accuracy: 0.5176\n",
      "Training: batch 5 begins at 15:02:46.040028\n",
      "\n",
      "Training: batch 5 ends at 15:02:47.635543\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.4246 - accuracy: 0.5210\n",
      "Training: batch 6 begins at 15:02:47.636575\n",
      "\n",
      "Training: batch 6 ends at 15:02:49.227515\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.4054 - accuracy: 0.5306\n",
      "Training: batch 7 begins at 15:02:49.228587\n",
      "\n",
      "Training: batch 7 ends at 15:02:50.794769\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3960 - accuracy: 0.5374\n",
      "Training: batch 8 begins at 15:02:50.795860\n",
      "\n",
      "Training: batch 8 ends at 15:02:52.380191\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.4363 - accuracy: 0.5299\n",
      "Training: batch 9 begins at 15:02:52.381253\n",
      "\n",
      "Training: batch 9 ends at 15:02:53.968665\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.4358 - accuracy: 0.5290\n",
      "Training: batch 10 begins at 15:02:53.969855\n",
      "\n",
      "Training: batch 10 ends at 15:02:55.544500\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.4439 - accuracy: 0.5221\n",
      "Training: batch 11 begins at 15:02:55.545580\n",
      "\n",
      "Training: batch 11 ends at 15:02:57.122923\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.4836 - accuracy: 0.5066 \n",
      "Training: batch 12 begins at 15:02:57.123929\n",
      "\n",
      "Training: batch 12 ends at 15:02:58.700217\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.4560 - accuracy: 0.5117\n",
      "Training: batch 13 begins at 15:02:58.701234\n",
      "\n",
      "Training: batch 13 ends at 15:03:00.304057\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.4388 - accuracy: 0.5184\n",
      "Training: batch 14 begins at 15:03:00.305325\n",
      "\n",
      "Training: batch 14 ends at 15:03:01.897227\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.4150 - accuracy: 0.5263\n",
      "Training: batch 15 begins at 15:03:01.898280\n",
      "\n",
      "Training: batch 15 ends at 15:03:03.484601\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.4113 - accuracy: 0.5248\n",
      "Training: batch 16 begins at 15:03:03.485707\n",
      "\n",
      "Training: batch 16 ends at 15:03:05.070559\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.4159 - accuracy: 0.5273\n",
      "Training: batch 17 begins at 15:03:05.071615\n",
      "\n",
      "Training: batch 17 ends at 15:03:06.655988\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.4254 - accuracy: 0.5207\n",
      "Evaluating: batch 0 begins at 15:03:06.780991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 15:03:06.836079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: batch 0 ends at 15:03:07.394398\n",
      "\n",
      "Evaluating: batch 1 begins at 15:03:07.394921\n",
      "\n",
      "Evaluating: batch 1 ends at 15:03:07.870959\n",
      "18/18 [==============================] - 31s 2s/step - loss: 1.4254 - accuracy: 0.5207 - val_loss: 1.3508 - val_accuracy: 0.5333\n",
      "Epoch 2/35\n",
      "\n",
      "Training: batch 0 begins at 15:03:07.880690\n",
      "\n",
      "Training: batch 0 ends at 15:03:09.484975\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.3899 - accuracy: 0.4941\n",
      "Training: batch 1 begins at 15:03:09.486132\n",
      "\n",
      "Training: batch 1 ends at 15:03:11.076772\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2920 - accuracy: 0.5024\n",
      "Training: batch 2 begins at 15:03:11.077905\n",
      "\n",
      "Training: batch 2 ends at 15:03:12.682935\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.4152 - accuracy: 0.4543\n",
      "Training: batch 3 begins at 15:03:12.683970\n",
      "\n",
      "Training: batch 3 ends at 15:03:14.253313\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.4670 - accuracy: 0.4324\n",
      "Training: batch 4 begins at 15:03:14.254491\n",
      "\n",
      "Training: batch 4 ends at 15:03:15.846152\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.4128 - accuracy: 0.4564\n",
      "Training: batch 5 begins at 15:03:15.847238\n",
      "\n",
      "Training: batch 5 ends at 15:03:17.432510\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.3868 - accuracy: 0.4778\n",
      "Training: batch 6 begins at 15:03:17.433554\n",
      "\n",
      "Training: batch 6 ends at 15:03:19.060687\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.3619 - accuracy: 0.4928\n",
      "Training: batch 7 begins at 15:03:19.061777\n",
      "\n",
      "Training: batch 7 ends at 15:03:20.656837\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.3581 - accuracy: 0.5093\n",
      "Training: batch 8 begins at 15:03:20.657903\n",
      "\n",
      "Training: batch 8 ends at 15:03:22.249326\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.3457 - accuracy: 0.5074\n",
      "Training: batch 9 begins at 15:03:22.250330\n",
      "\n",
      "Training: batch 9 ends at 15:03:23.852474\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.3316 - accuracy: 0.5155\n",
      "Training: batch 10 begins at 15:03:23.853459\n",
      "\n",
      "Training: batch 10 ends at 15:03:25.436772\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.3232 - accuracy: 0.5187\n",
      "Training: batch 11 begins at 15:03:25.437840\n",
      "\n",
      "Training: batch 11 ends at 15:03:27.023460\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.3256 - accuracy: 0.5193 \n",
      "Training: batch 12 begins at 15:03:27.024484\n",
      "\n",
      "Training: batch 12 ends at 15:03:28.621876\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.3099 - accuracy: 0.5300\n",
      "Training: batch 13 begins at 15:03:28.623043\n",
      "\n",
      "Training: batch 13 ends at 15:03:30.231425\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.3152 - accuracy: 0.5282\n",
      "Training: batch 14 begins at 15:03:30.232465\n",
      "\n",
      "Training: batch 14 ends at 15:03:31.845424\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.3202 - accuracy: 0.5249\n",
      "Training: batch 15 begins at 15:03:31.846539\n",
      "\n",
      "Training: batch 15 ends at 15:03:33.454333\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.3050 - accuracy: 0.5328\n",
      "Training: batch 16 begins at 15:03:33.455389\n",
      "\n",
      "Training: batch 16 ends at 15:03:35.026228\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2937 - accuracy: 0.5352\n",
      "Training: batch 17 begins at 15:03:35.027349\n",
      "\n",
      "Training: batch 17 ends at 15:03:36.622567\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2867 - accuracy: 0.5385\n",
      "Evaluating: batch 0 begins at 15:03:36.631072\n",
      "\n",
      "Evaluating: batch 0 ends at 15:03:37.151997\n",
      "\n",
      "Evaluating: batch 1 begins at 15:03:37.152490\n",
      "\n",
      "Evaluating: batch 1 ends at 15:03:37.629528\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2867 - accuracy: 0.5385 - val_loss: 1.2688 - val_accuracy: 0.5726\n",
      "Epoch 3/35\n",
      "\n",
      "Training: batch 0 begins at 15:03:37.638798\n",
      "\n",
      "Training: batch 0 ends at 15:03:39.232121\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.1015 - accuracy: 0.6478\n",
      "Training: batch 1 begins at 15:03:39.233107\n",
      "\n",
      "Training: batch 1 ends at 15:03:40.816633\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2935 - accuracy: 0.5270\n",
      "Training: batch 2 begins at 15:03:40.817771\n",
      "\n",
      "Training: batch 2 ends at 15:03:42.397785\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.3016 - accuracy: 0.4843\n",
      "Training: batch 3 begins at 15:03:42.398835\n",
      "\n",
      "Training: batch 3 ends at 15:03:43.991861\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.2438 - accuracy: 0.5203\n",
      "Training: batch 4 begins at 15:03:43.993029\n",
      "\n",
      "Training: batch 4 ends at 15:03:45.570114\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.1834 - accuracy: 0.5498\n",
      "Training: batch 5 begins at 15:03:45.571369\n",
      "\n",
      "Training: batch 5 ends at 15:03:47.145797\n",
      " 6/18 [=========>....................] - ETA: 18s - loss: 1.1735 - accuracy: 0.5644\n",
      "Training: batch 6 begins at 15:03:47.146832\n",
      "\n",
      "Training: batch 6 ends at 15:03:48.752329\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2242 - accuracy: 0.5542\n",
      "Training: batch 7 begins at 15:03:48.753588\n",
      "\n",
      "Training: batch 7 ends at 15:03:50.359319\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.1961 - accuracy: 0.5587\n",
      "Training: batch 8 begins at 15:03:50.360437\n",
      "\n",
      "Training: batch 8 ends at 15:03:51.954145\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2020 - accuracy: 0.5564\n",
      "Training: batch 9 begins at 15:03:51.955229\n",
      "\n",
      "Training: batch 9 ends at 15:03:53.537329\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2069 - accuracy: 0.5613\n",
      "Training: batch 10 begins at 15:03:53.538342\n",
      "\n",
      "Training: batch 10 ends at 15:03:55.108024\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2189 - accuracy: 0.5576\n",
      "Training: batch 11 begins at 15:03:55.109160\n",
      "\n",
      "Training: batch 11 ends at 15:03:56.709971\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2331 - accuracy: 0.5568 \n",
      "Training: batch 12 begins at 15:03:56.711021\n",
      "\n",
      "Training: batch 12 ends at 15:03:58.302026\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2123 - accuracy: 0.5712\n",
      "Training: batch 13 begins at 15:03:58.303087\n",
      "\n",
      "Training: batch 13 ends at 15:03:59.900093\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2191 - accuracy: 0.5717\n",
      "Training: batch 14 begins at 15:03:59.901154\n",
      "\n",
      "Training: batch 14 ends at 15:04:01.508707\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2270 - accuracy: 0.5692\n",
      "Training: batch 15 begins at 15:04:01.509813\n",
      "\n",
      "Training: batch 15 ends at 15:04:03.099290\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2412 - accuracy: 0.5607\n",
      "Training: batch 16 begins at 15:04:03.100305\n",
      "\n",
      "Training: batch 16 ends at 15:04:04.701935\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2427 - accuracy: 0.5598\n",
      "Training: batch 17 begins at 15:04:04.702948\n",
      "\n",
      "Training: batch 17 ends at 15:04:06.321206\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2418 - accuracy: 0.5611\n",
      "Evaluating: batch 0 begins at 15:04:06.332072\n",
      "\n",
      "Evaluating: batch 0 ends at 15:04:06.831632\n",
      "\n",
      "Evaluating: batch 1 begins at 15:04:06.832144\n",
      "\n",
      "Evaluating: batch 1 ends at 15:04:07.304046\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2418 - accuracy: 0.5611 - val_loss: 1.1885 - val_accuracy: 0.5940\n",
      "Epoch 4/35\n",
      "\n",
      "Training: batch 0 begins at 15:04:07.314139\n",
      "\n",
      "Training: batch 0 ends at 15:04:08.919226\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2851 - accuracy: 0.5475\n",
      "Training: batch 1 begins at 15:04:08.920268\n",
      "\n",
      "Training: batch 1 ends at 15:04:10.518548\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2536 - accuracy: 0.5847\n",
      "Training: batch 2 begins at 15:04:10.519606\n",
      "\n",
      "Training: batch 2 ends at 15:04:12.113646\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.1847 - accuracy: 0.6144\n",
      "Training: batch 3 begins at 15:04:12.114786\n",
      "\n",
      "Training: batch 3 ends at 15:04:13.723838\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1820 - accuracy: 0.6095\n",
      "Training: batch 4 begins at 15:04:13.724907\n",
      "\n",
      "Training: batch 4 ends at 15:04:15.355809\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.1485 - accuracy: 0.6104\n",
      "Training: batch 5 begins at 15:04:15.358601\n",
      "\n",
      "Training: batch 5 ends at 15:04:16.962534\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.1901 - accuracy: 0.5970\n",
      "Training: batch 6 begins at 15:04:16.963588\n",
      "\n",
      "Training: batch 6 ends at 15:04:18.552012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.1884 - accuracy: 0.5905\n",
      "Training: batch 7 begins at 15:04:18.553094\n",
      "\n",
      "Training: batch 7 ends at 15:04:20.146913\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.1833 - accuracy: 0.5876\n",
      "Training: batch 8 begins at 15:04:20.147979\n",
      "\n",
      "Training: batch 8 ends at 15:04:21.788699\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.1996 - accuracy: 0.5878\n",
      "Training: batch 9 begins at 15:04:21.789803\n",
      "\n",
      "Training: batch 9 ends at 15:04:23.378777\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2194 - accuracy: 0.5759\n",
      "Training: batch 10 begins at 15:04:23.379914\n",
      "\n",
      "Training: batch 10 ends at 15:04:24.968259\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2243 - accuracy: 0.5711\n",
      "Training: batch 11 begins at 15:04:24.969349\n",
      "\n",
      "Training: batch 11 ends at 15:04:26.575687\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2183 - accuracy: 0.5741 \n",
      "Training: batch 12 begins at 15:04:26.577162\n",
      "\n",
      "Training: batch 12 ends at 15:04:28.209415\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.2140 - accuracy: 0.5751\n",
      "Training: batch 13 begins at 15:04:28.210539\n",
      "\n",
      "Training: batch 13 ends at 15:04:29.803347\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2122 - accuracy: 0.5749\n",
      "Training: batch 14 begins at 15:04:29.804392\n",
      "\n",
      "Training: batch 14 ends at 15:04:31.419937\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.1966 - accuracy: 0.5811\n",
      "Training: batch 15 begins at 15:04:31.420940\n",
      "\n",
      "Training: batch 15 ends at 15:04:33.011071\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.1836 - accuracy: 0.5904\n",
      "Training: batch 16 begins at 15:04:33.012067\n",
      "\n",
      "Training: batch 16 ends at 15:04:34.599400\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.1970 - accuracy: 0.5799\n",
      "Training: batch 17 begins at 15:04:34.600404\n",
      "\n",
      "Training: batch 17 ends at 15:04:36.229096\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2023 - accuracy: 0.5795\n",
      "Evaluating: batch 0 begins at 15:04:36.237677\n",
      "\n",
      "Evaluating: batch 0 ends at 15:04:36.770345\n",
      "\n",
      "Evaluating: batch 1 begins at 15:04:36.770896\n",
      "\n",
      "Evaluating: batch 1 ends at 15:04:37.244602\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2023 - accuracy: 0.5795 - val_loss: 1.3114 - val_accuracy: 0.5574\n",
      "Epoch 5/35\n",
      "\n",
      "Training: batch 0 begins at 15:04:37.254302\n",
      "\n",
      "Training: batch 0 ends at 15:04:38.856231\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.0506 - accuracy: 0.6162\n",
      "Training: batch 1 begins at 15:04:38.858126\n",
      "\n",
      "Training: batch 1 ends at 15:04:40.450310\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9933 - accuracy: 0.6709\n",
      "Training: batch 2 begins at 15:04:40.451757\n",
      "\n",
      "Training: batch 2 ends at 15:04:42.041269\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.1484 - accuracy: 0.5966\n",
      "Training: batch 3 begins at 15:04:42.042288\n",
      "\n",
      "Training: batch 3 ends at 15:04:43.634515\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1155 - accuracy: 0.6022\n",
      "Training: batch 4 begins at 15:04:43.635595\n",
      "\n",
      "Training: batch 4 ends at 15:04:45.239816\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.0894 - accuracy: 0.6177\n",
      "Training: batch 5 begins at 15:04:45.240856\n",
      "\n",
      "Training: batch 5 ends at 15:04:46.841249\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.0935 - accuracy: 0.6169\n",
      "Training: batch 6 begins at 15:04:46.842255\n",
      "\n",
      "Training: batch 6 ends at 15:04:48.416639\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.1564 - accuracy: 0.5924\n",
      "Training: batch 7 begins at 15:04:48.417771\n",
      "\n",
      "Training: batch 7 ends at 15:04:50.016982\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.1459 - accuracy: 0.6010\n",
      "Training: batch 8 begins at 15:04:50.018033\n",
      "\n",
      "Training: batch 8 ends at 15:04:51.592920\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.1314 - accuracy: 0.6092\n",
      "Training: batch 9 begins at 15:04:51.593941\n",
      "\n",
      "Training: batch 9 ends at 15:04:53.187175\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.1503 - accuracy: 0.6085\n",
      "Training: batch 10 begins at 15:04:53.188250\n",
      "\n",
      "Training: batch 10 ends at 15:04:54.786853\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.1537 - accuracy: 0.6028\n",
      "Training: batch 11 begins at 15:04:54.787936\n",
      "\n",
      "Training: batch 11 ends at 15:04:56.377781\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.1570 - accuracy: 0.5989 \n",
      "Training: batch 12 begins at 15:04:56.378825\n",
      "\n",
      "Training: batch 12 ends at 15:04:57.978555\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.1598 - accuracy: 0.5933\n",
      "Training: batch 13 begins at 15:04:57.979708\n",
      "\n",
      "Training: batch 13 ends at 15:04:59.566628\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.1509 - accuracy: 0.6002\n",
      "Training: batch 14 begins at 15:04:59.567734\n",
      "\n",
      "Training: batch 14 ends at 15:05:01.147975\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.1451 - accuracy: 0.6013\n",
      "Training: batch 15 begins at 15:05:01.149087\n",
      "\n",
      "Training: batch 15 ends at 15:05:02.742149\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.1437 - accuracy: 0.6051\n",
      "Training: batch 16 begins at 15:05:02.743280\n",
      "\n",
      "Training: batch 16 ends at 15:05:04.341843\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.1531 - accuracy: 0.6000\n",
      "Training: batch 17 begins at 15:05:04.343128\n",
      "\n",
      "Training: batch 17 ends at 15:05:05.922786\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.1626 - accuracy: 0.5974\n",
      "Evaluating: batch 0 begins at 15:05:05.934020\n",
      "\n",
      "Evaluating: batch 0 ends at 15:05:06.442477\n",
      "\n",
      "Evaluating: batch 1 begins at 15:05:06.442938\n",
      "\n",
      "Evaluating: batch 1 ends at 15:05:06.918644\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.1626 - accuracy: 0.5974 - val_loss: 1.2148 - val_accuracy: 0.5817\n",
      "Epoch 6/35\n",
      "\n",
      "Training: batch 0 begins at 15:05:06.928657\n",
      "\n",
      "Training: batch 0 ends at 15:05:08.523569\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2060 - accuracy: 0.5090\n",
      "Training: batch 1 begins at 15:05:08.524585\n",
      "\n",
      "Training: batch 1 ends at 15:05:10.117168\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0802 - accuracy: 0.5882\n",
      "Training: batch 2 begins at 15:05:10.118231\n",
      "\n",
      "Training: batch 2 ends at 15:05:11.722442\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.1402 - accuracy: 0.5923\n",
      "Training: batch 3 begins at 15:05:11.723455\n",
      "\n",
      "Training: batch 3 ends at 15:05:13.312211\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1003 - accuracy: 0.6175\n",
      "Training: batch 4 begins at 15:05:13.313240\n",
      "\n",
      "Training: batch 4 ends at 15:05:14.927152\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.1030 - accuracy: 0.5952\n",
      "Training: batch 5 begins at 15:05:14.928141\n",
      "\n",
      "Training: batch 5 ends at 15:05:16.518971\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.0806 - accuracy: 0.6047\n",
      "Training: batch 6 begins at 15:05:16.520062\n",
      "\n",
      "Training: batch 6 ends at 15:05:18.107814\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.1090 - accuracy: 0.5884\n",
      "Training: batch 7 begins at 15:05:18.108880\n",
      "\n",
      "Training: batch 7 ends at 15:05:19.697186\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.1048 - accuracy: 0.6029\n",
      "Training: batch 8 begins at 15:05:19.698178\n",
      "\n",
      "Training: batch 8 ends at 15:05:21.274805\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.0883 - accuracy: 0.6106\n",
      "Training: batch 9 begins at 15:05:21.275988\n",
      "\n",
      "Training: batch 9 ends at 15:05:22.887114\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.0904 - accuracy: 0.6083\n",
      "Training: batch 10 begins at 15:05:22.888232\n",
      "\n",
      "Training: batch 10 ends at 15:05:24.493462\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.0837 - accuracy: 0.6107\n",
      "Training: batch 11 begins at 15:05:24.494577\n",
      "\n",
      "Training: batch 11 ends at 15:05:26.104993\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.1010 - accuracy: 0.6078 \n",
      "Training: batch 12 begins at 15:05:26.106080\n",
      "\n",
      "Training: batch 12 ends at 15:05:27.712948\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.1048 - accuracy: 0.6047\n",
      "Training: batch 13 begins at 15:05:27.713981\n",
      "\n",
      "Training: batch 13 ends at 15:05:29.315854\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.1478 - accuracy: 0.5912\n",
      "Training: batch 14 begins at 15:05:29.316891\n",
      "\n",
      "Training: batch 14 ends at 15:05:30.900255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/18 [========================>.....] - ETA: 4s - loss: 1.1486 - accuracy: 0.5961\n",
      "Training: batch 15 begins at 15:05:30.901253\n",
      "\n",
      "Training: batch 15 ends at 15:05:32.499576\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.1373 - accuracy: 0.6008\n",
      "Training: batch 16 begins at 15:05:32.500604\n",
      "\n",
      "Training: batch 16 ends at 15:05:34.100597\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.1456 - accuracy: 0.5964\n",
      "Training: batch 17 begins at 15:05:34.101842\n",
      "\n",
      "Training: batch 17 ends at 15:05:35.692146\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.1598 - accuracy: 0.5967\n",
      "Evaluating: batch 0 begins at 15:05:35.700684\n",
      "\n",
      "Evaluating: batch 0 ends at 15:05:36.226086\n",
      "\n",
      "Evaluating: batch 1 begins at 15:05:36.226621\n",
      "\n",
      "Evaluating: batch 1 ends at 15:05:36.702190\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.1598 - accuracy: 0.5967 - val_loss: 1.2171 - val_accuracy: 0.5805\n",
      "Epoch 7/35\n",
      "\n",
      "Training: batch 0 begins at 15:05:36.712023\n",
      "\n",
      "Training: batch 0 ends at 15:05:38.312437\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2447 - accuracy: 0.6018\n",
      "Training: batch 1 begins at 15:05:38.315381\n",
      "\n",
      "Training: batch 1 ends at 15:05:39.918467\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2750 - accuracy: 0.5505\n",
      "Training: batch 2 begins at 15:05:39.919534\n",
      "\n",
      "Training: batch 2 ends at 15:05:41.509219\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.2067 - accuracy: 0.5870\n",
      "Training: batch 3 begins at 15:05:41.510327\n",
      "\n",
      "Training: batch 3 ends at 15:05:43.092570\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.2064 - accuracy: 0.5673\n",
      "Training: batch 4 begins at 15:05:43.093671\n",
      "\n",
      "Training: batch 4 ends at 15:05:44.699630\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2738 - accuracy: 0.5486\n",
      "Training: batch 5 begins at 15:05:44.700885\n",
      "\n",
      "Training: batch 5 ends at 15:05:46.281042\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2616 - accuracy: 0.5517\n",
      "Training: batch 6 begins at 15:05:46.282117\n",
      "\n",
      "Training: batch 6 ends at 15:05:47.881435\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2580 - accuracy: 0.5490\n",
      "Training: batch 7 begins at 15:05:47.882560\n",
      "\n",
      "Training: batch 7 ends at 15:05:49.494684\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.2605 - accuracy: 0.5592\n",
      "Training: batch 8 begins at 15:05:49.495717\n",
      "\n",
      "Training: batch 8 ends at 15:05:51.099842\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2305 - accuracy: 0.5733\n",
      "Training: batch 9 begins at 15:05:51.100874\n",
      "\n",
      "Training: batch 9 ends at 15:05:52.685573\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2068 - accuracy: 0.5821\n",
      "Training: batch 10 begins at 15:05:52.686612\n",
      "\n",
      "Training: batch 10 ends at 15:05:54.271762\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2127 - accuracy: 0.5774\n",
      "Training: batch 11 begins at 15:05:54.272870\n",
      "\n",
      "Training: batch 11 ends at 15:05:55.862963\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2369 - accuracy: 0.5713 \n",
      "Training: batch 12 begins at 15:05:55.863996\n",
      "\n",
      "Training: batch 12 ends at 15:05:57.437808\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2284 - accuracy: 0.5727\n",
      "Training: batch 13 begins at 15:05:57.438886\n",
      "\n",
      "Training: batch 13 ends at 15:05:59.026898\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2102 - accuracy: 0.5790\n",
      "Training: batch 14 begins at 15:05:59.027901\n",
      "\n",
      "Training: batch 14 ends at 15:06:00.635112\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2014 - accuracy: 0.5802\n",
      "Training: batch 15 begins at 15:06:00.636178\n",
      "\n",
      "Training: batch 15 ends at 15:06:02.211963\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.2180 - accuracy: 0.5721\n",
      "Training: batch 16 begins at 15:06:02.212932\n",
      "\n",
      "Training: batch 16 ends at 15:06:03.802690\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.2020 - accuracy: 0.5804\n",
      "Training: batch 17 begins at 15:06:03.803679\n",
      "\n",
      "Training: batch 17 ends at 15:06:05.389441\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.2049 - accuracy: 0.5811\n",
      "Evaluating: batch 0 begins at 15:06:05.400397\n",
      "\n",
      "Evaluating: batch 0 ends at 15:06:05.916921\n",
      "\n",
      "Evaluating: batch 1 begins at 15:06:05.917463\n",
      "\n",
      "Evaluating: batch 1 ends at 15:06:06.390093\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.2049 - accuracy: 0.5811 - val_loss: 1.2145 - val_accuracy: 0.5887\n",
      "Epoch 8/35\n",
      "\n",
      "Training: batch 0 begins at 15:06:06.400506\n",
      "\n",
      "Training: batch 0 ends at 15:06:08.012583\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.1522 - accuracy: 0.6611\n",
      "Training: batch 1 begins at 15:06:08.013640\n",
      "\n",
      "Training: batch 1 ends at 15:06:09.597755\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.1585 - accuracy: 0.6168\n",
      "Training: batch 2 begins at 15:06:09.599036\n",
      "\n",
      "Training: batch 2 ends at 15:06:11.198361\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.0996 - accuracy: 0.6347\n",
      "Training: batch 3 begins at 15:06:11.199415\n",
      "\n",
      "Training: batch 3 ends at 15:06:12.813973\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1767 - accuracy: 0.6060\n",
      "Training: batch 4 begins at 15:06:12.815116\n",
      "\n",
      "Training: batch 4 ends at 15:06:14.402624\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.1406 - accuracy: 0.6260\n",
      "Training: batch 5 begins at 15:06:14.403599\n",
      "\n",
      "Training: batch 5 ends at 15:06:16.004955\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.1431 - accuracy: 0.6260\n",
      "Training: batch 6 begins at 15:06:16.006003\n",
      "\n",
      "Training: batch 6 ends at 15:06:17.599522\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.1617 - accuracy: 0.6074\n",
      "Training: batch 7 begins at 15:06:17.600595\n",
      "\n",
      "Training: batch 7 ends at 15:06:19.202995\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.1762 - accuracy: 0.6034\n",
      "Training: batch 8 begins at 15:06:19.204084\n",
      "\n",
      "Training: batch 8 ends at 15:06:20.805794\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.1637 - accuracy: 0.6021\n",
      "Training: batch 9 begins at 15:06:20.808307\n",
      "\n",
      "Training: batch 9 ends at 15:06:22.422791\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.1504 - accuracy: 0.6076\n",
      "Training: batch 10 begins at 15:06:22.423893\n",
      "\n",
      "Training: batch 10 ends at 15:06:24.038328\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.1184 - accuracy: 0.6185\n",
      "Training: batch 11 begins at 15:06:24.039418\n",
      "\n",
      "Training: batch 11 ends at 15:06:25.625985\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.1341 - accuracy: 0.6056 \n",
      "Training: batch 12 begins at 15:06:25.627585\n",
      "\n",
      "Training: batch 12 ends at 15:06:27.236933\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.1248 - accuracy: 0.6118\n",
      "Training: batch 13 begins at 15:06:27.238058\n",
      "\n",
      "Training: batch 13 ends at 15:06:28.843084\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.1280 - accuracy: 0.6116\n",
      "Training: batch 14 begins at 15:06:28.844099\n",
      "\n",
      "Training: batch 14 ends at 15:06:30.424581\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.1258 - accuracy: 0.6100\n",
      "Training: batch 15 begins at 15:06:30.425733\n",
      "\n",
      "Training: batch 15 ends at 15:06:32.024003\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.1180 - accuracy: 0.6122\n",
      "Training: batch 16 begins at 15:06:32.025010\n",
      "\n",
      "Training: batch 16 ends at 15:06:33.617933\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.1319 - accuracy: 0.6048\n",
      "Training: batch 17 begins at 15:06:33.618940\n",
      "\n",
      "Training: batch 17 ends at 15:06:35.196231\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.1471 - accuracy: 0.6027\n",
      "Evaluating: batch 0 begins at 15:06:35.204586\n",
      "\n",
      "Evaluating: batch 0 ends at 15:06:35.731310\n",
      "\n",
      "Evaluating: batch 1 begins at 15:06:35.731799\n",
      "\n",
      "Evaluating: batch 1 ends at 15:06:36.208296\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.1471 - accuracy: 0.6027 - val_loss: 1.2106 - val_accuracy: 0.6043\n",
      "Epoch 9/35\n",
      "\n",
      "Training: batch 0 begins at 15:06:36.219217\n",
      "\n",
      "Training: batch 0 ends at 15:06:37.863396\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.0834 - accuracy: 0.6431\n",
      "Training: batch 1 begins at 15:06:37.864692\n",
      "\n",
      "Training: batch 1 ends at 15:06:39.466834\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.2445 - accuracy: 0.5616\n",
      "Training: batch 2 begins at 15:06:39.467896\n",
      "\n",
      "Training: batch 2 ends at 15:06:41.066007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.3221 - accuracy: 0.5327\n",
      "Training: batch 3 begins at 15:06:41.067089\n",
      "\n",
      "Training: batch 3 ends at 15:06:42.640902\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.2715 - accuracy: 0.5418\n",
      "Training: batch 4 begins at 15:06:42.641976\n",
      "\n",
      "Training: batch 4 ends at 15:06:44.238378\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.2954 - accuracy: 0.5457\n",
      "Training: batch 5 begins at 15:06:44.239507\n",
      "\n",
      "Training: batch 5 ends at 15:06:45.827989\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.2594 - accuracy: 0.5581\n",
      "Training: batch 6 begins at 15:06:45.829022\n",
      "\n",
      "Training: batch 6 ends at 15:06:47.435740\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.2564 - accuracy: 0.5610\n",
      "Training: batch 7 begins at 15:06:47.436817\n",
      "\n",
      "Training: batch 7 ends at 15:06:49.023190\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.2064 - accuracy: 0.5837\n",
      "Training: batch 8 begins at 15:06:49.024410\n",
      "\n",
      "Training: batch 8 ends at 15:06:50.616975\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.2280 - accuracy: 0.5771\n",
      "Training: batch 9 begins at 15:06:50.618005\n",
      "\n",
      "Training: batch 9 ends at 15:06:52.213332\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.2401 - accuracy: 0.5752\n",
      "Training: batch 10 begins at 15:06:52.214330\n",
      "\n",
      "Training: batch 10 ends at 15:06:53.806386\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.2478 - accuracy: 0.5655\n",
      "Training: batch 11 begins at 15:06:53.807435\n",
      "\n",
      "Training: batch 11 ends at 15:06:55.403228\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.2450 - accuracy: 0.5668 \n",
      "Training: batch 12 begins at 15:06:55.404323\n",
      "\n",
      "Training: batch 12 ends at 15:06:57.002360\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.2255 - accuracy: 0.5766\n",
      "Training: batch 13 begins at 15:06:57.003399\n",
      "\n",
      "Training: batch 13 ends at 15:06:58.598433\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.2197 - accuracy: 0.5789\n",
      "Training: batch 14 begins at 15:06:58.599503\n",
      "\n",
      "Training: batch 14 ends at 15:07:00.188745\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.2124 - accuracy: 0.5804\n",
      "Training: batch 15 begins at 15:07:00.189822\n",
      "\n",
      "Training: batch 15 ends at 15:07:01.779612\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.1988 - accuracy: 0.5838\n",
      "Training: batch 16 begins at 15:07:01.780626\n",
      "\n",
      "Training: batch 16 ends at 15:07:03.375170\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.1808 - accuracy: 0.5912\n",
      "Training: batch 17 begins at 15:07:03.376259\n",
      "\n",
      "Training: batch 17 ends at 15:07:04.969503\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.1773 - accuracy: 0.5896\n",
      "Evaluating: batch 0 begins at 15:07:04.980176\n",
      "\n",
      "Evaluating: batch 0 ends at 15:07:05.481649\n",
      "\n",
      "Evaluating: batch 1 begins at 15:07:05.482211\n",
      "\n",
      "Evaluating: batch 1 ends at 15:07:05.958239\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.1773 - accuracy: 0.5896 - val_loss: 1.2329 - val_accuracy: 0.6025\n",
      "Epoch 10/35\n",
      "\n",
      "Training: batch 0 begins at 15:07:05.968969\n",
      "\n",
      "Training: batch 0 ends at 15:07:07.558447\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.0285 - accuracy: 0.5998\n",
      "Training: batch 1 begins at 15:07:07.559571\n",
      "\n",
      "Training: batch 1 ends at 15:07:09.157965\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9946 - accuracy: 0.6445\n",
      "Training: batch 2 begins at 15:07:09.159013\n",
      "\n",
      "Training: batch 2 ends at 15:07:10.755101\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9560 - accuracy: 0.6797\n",
      "Training: batch 3 begins at 15:07:10.756180\n",
      "\n",
      "Training: batch 3 ends at 15:07:12.355624\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9768 - accuracy: 0.6634\n",
      "Training: batch 4 begins at 15:07:12.356626\n",
      "\n",
      "Training: batch 4 ends at 15:07:13.962175\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9825 - accuracy: 0.6622\n",
      "Training: batch 5 begins at 15:07:13.963723\n",
      "\n",
      "Training: batch 5 ends at 15:07:15.552517\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.9926 - accuracy: 0.6594\n",
      "Training: batch 6 begins at 15:07:15.553517\n",
      "\n",
      "Training: batch 6 ends at 15:07:17.147881\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.0447 - accuracy: 0.6445\n",
      "Training: batch 7 begins at 15:07:17.148925\n",
      "\n",
      "Training: batch 7 ends at 15:07:18.736988\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.0255 - accuracy: 0.6515\n",
      "Training: batch 8 begins at 15:07:18.738081\n",
      "\n",
      "Training: batch 8 ends at 15:07:20.345601\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.0522 - accuracy: 0.6390\n",
      "Training: batch 9 begins at 15:07:20.347061\n",
      "\n",
      "Training: batch 9 ends at 15:07:21.958487\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.0628 - accuracy: 0.6333\n",
      "Training: batch 10 begins at 15:07:21.959640\n",
      "\n",
      "Training: batch 10 ends at 15:07:23.543624\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.0702 - accuracy: 0.6294\n",
      "Training: batch 11 begins at 15:07:23.544682\n",
      "\n",
      "Training: batch 11 ends at 15:07:25.126291\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.0947 - accuracy: 0.6202 \n",
      "Training: batch 12 begins at 15:07:25.127293\n",
      "\n",
      "Training: batch 12 ends at 15:07:26.734088\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.0790 - accuracy: 0.6264\n",
      "Training: batch 13 begins at 15:07:26.735122\n",
      "\n",
      "Training: batch 13 ends at 15:07:28.334761\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.1047 - accuracy: 0.6174\n",
      "Training: batch 14 begins at 15:07:28.335914\n",
      "\n",
      "Training: batch 14 ends at 15:07:29.909323\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.1068 - accuracy: 0.6158\n",
      "Training: batch 15 begins at 15:07:29.910330\n",
      "\n",
      "Training: batch 15 ends at 15:07:31.497959\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.1110 - accuracy: 0.6129\n",
      "Training: batch 16 begins at 15:07:31.499170\n",
      "\n",
      "Training: batch 16 ends at 15:07:33.088528\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.1035 - accuracy: 0.6139\n",
      "Training: batch 17 begins at 15:07:33.089520\n",
      "\n",
      "Training: batch 17 ends at 15:07:34.678346\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.1077 - accuracy: 0.6120\n",
      "Evaluating: batch 0 begins at 15:07:34.687580\n",
      "\n",
      "Evaluating: batch 0 ends at 15:07:35.221988\n",
      "\n",
      "Evaluating: batch 1 begins at 15:07:35.222535\n",
      "\n",
      "Evaluating: batch 1 ends at 15:07:35.697249\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.1077 - accuracy: 0.6120 - val_loss: 1.1078 - val_accuracy: 0.6340\n",
      "Epoch 11/35\n",
      "\n",
      "Training: batch 0 begins at 15:07:35.706861\n",
      "\n",
      "Training: batch 0 ends at 15:07:37.267670\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 0.9994 - accuracy: 0.6996\n",
      "Training: batch 1 begins at 15:07:37.268799\n",
      "\n",
      "Training: batch 1 ends at 15:07:38.875037\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.1265 - accuracy: 0.6401\n",
      "Training: batch 2 begins at 15:07:38.876084\n",
      "\n",
      "Training: batch 2 ends at 15:07:40.477994\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.1329 - accuracy: 0.6334\n",
      "Training: batch 3 begins at 15:07:40.478982\n",
      "\n",
      "Training: batch 3 ends at 15:07:42.071461\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.0825 - accuracy: 0.6423\n",
      "Training: batch 4 begins at 15:07:42.072524\n",
      "\n",
      "Training: batch 4 ends at 15:07:43.653417\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.1232 - accuracy: 0.6315\n",
      "Training: batch 5 begins at 15:07:43.654461\n",
      "\n",
      "Training: batch 5 ends at 15:07:45.256106\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.1633 - accuracy: 0.6169\n",
      "Training: batch 6 begins at 15:07:45.257124\n",
      "\n",
      "Training: batch 6 ends at 15:07:46.822603\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.1478 - accuracy: 0.6121\n",
      "Training: batch 7 begins at 15:07:46.823709\n",
      "\n",
      "Training: batch 7 ends at 15:07:48.410361\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.1303 - accuracy: 0.6185\n",
      "Training: batch 8 begins at 15:07:48.411502\n",
      "\n",
      "Training: batch 8 ends at 15:07:50.007181\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.1011 - accuracy: 0.6239\n",
      "Training: batch 9 begins at 15:07:50.008188\n",
      "\n",
      "Training: batch 9 ends at 15:07:51.585606\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.1416 - accuracy: 0.6098\n",
      "Training: batch 10 begins at 15:07:51.586585\n",
      "\n",
      "Training: batch 10 ends at 15:07:53.184013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 [=================>............] - ETA: 11s - loss: 1.1255 - accuracy: 0.6182\n",
      "Training: batch 11 begins at 15:07:53.185024\n",
      "\n",
      "Training: batch 11 ends at 15:07:54.797215\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.1148 - accuracy: 0.6204 \n",
      "Training: batch 12 begins at 15:07:54.798284\n",
      "\n",
      "Training: batch 12 ends at 15:07:56.398976\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.1083 - accuracy: 0.6247\n",
      "Training: batch 13 begins at 15:07:56.400055\n",
      "\n",
      "Training: batch 13 ends at 15:07:57.990795\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.1047 - accuracy: 0.6205\n",
      "Training: batch 14 begins at 15:07:57.991871\n",
      "\n",
      "Training: batch 14 ends at 15:07:59.591746\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.1138 - accuracy: 0.6160\n",
      "Training: batch 15 begins at 15:07:59.592816\n",
      "\n",
      "Training: batch 15 ends at 15:08:01.196264\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.1302 - accuracy: 0.6096\n",
      "Training: batch 16 begins at 15:08:01.197328\n",
      "\n",
      "Training: batch 16 ends at 15:08:02.789582\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.1332 - accuracy: 0.6108\n",
      "Training: batch 17 begins at 15:08:02.790706\n",
      "\n",
      "Training: batch 17 ends at 15:08:04.387357\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.1161 - accuracy: 0.6174\n",
      "Evaluating: batch 0 begins at 15:08:04.398219\n",
      "\n",
      "Evaluating: batch 0 ends at 15:08:04.907001\n",
      "\n",
      "Evaluating: batch 1 begins at 15:08:04.907512\n",
      "\n",
      "Evaluating: batch 1 ends at 15:08:05.379505\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.1161 - accuracy: 0.6174 - val_loss: 1.1375 - val_accuracy: 0.6251\n",
      "Epoch 12/35\n",
      "\n",
      "Training: batch 0 begins at 15:08:05.389778\n",
      "\n",
      "Training: batch 0 ends at 15:08:07.005657\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.2361 - accuracy: 0.5784\n",
      "Training: batch 1 begins at 15:08:07.006661\n",
      "\n",
      "Training: batch 1 ends at 15:08:08.573790\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.1797 - accuracy: 0.6013\n",
      "Training: batch 2 begins at 15:08:08.574915\n",
      "\n",
      "Training: batch 2 ends at 15:08:10.158677\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.2314 - accuracy: 0.5872\n",
      "Training: batch 3 begins at 15:08:10.159773\n",
      "\n",
      "Training: batch 3 ends at 15:08:11.754408\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1992 - accuracy: 0.5791\n",
      "Training: batch 4 begins at 15:08:11.755479\n",
      "\n",
      "Training: batch 4 ends at 15:08:13.376226\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.1948 - accuracy: 0.5847\n",
      "Training: batch 5 begins at 15:08:13.377365\n",
      "\n",
      "Training: batch 5 ends at 15:08:14.980791\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.1542 - accuracy: 0.5968\n",
      "Training: batch 6 begins at 15:08:14.981789\n",
      "\n",
      "Training: batch 6 ends at 15:08:16.548402\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.1463 - accuracy: 0.5942\n",
      "Training: batch 7 begins at 15:08:16.549523\n",
      "\n",
      "Training: batch 7 ends at 15:08:18.153815\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.1361 - accuracy: 0.5948\n",
      "Training: batch 8 begins at 15:08:18.154818\n",
      "\n",
      "Training: batch 8 ends at 15:08:19.753606\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.1167 - accuracy: 0.6034\n",
      "Training: batch 9 begins at 15:08:19.754624\n",
      "\n",
      "Training: batch 9 ends at 15:08:21.368263\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.0921 - accuracy: 0.6122\n",
      "Training: batch 10 begins at 15:08:21.369384\n",
      "\n",
      "Training: batch 10 ends at 15:08:22.980412\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.0832 - accuracy: 0.6128\n",
      "Training: batch 11 begins at 15:08:22.981402\n",
      "\n",
      "Training: batch 11 ends at 15:08:24.542204\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.0687 - accuracy: 0.6159 \n",
      "Training: batch 12 begins at 15:08:24.543349\n",
      "\n",
      "Training: batch 12 ends at 15:08:26.134459\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.0644 - accuracy: 0.6210\n",
      "Training: batch 13 begins at 15:08:26.135591\n",
      "\n",
      "Training: batch 13 ends at 15:08:27.743973\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.0709 - accuracy: 0.6191\n",
      "Training: batch 14 begins at 15:08:27.745053\n",
      "\n",
      "Training: batch 14 ends at 15:08:29.331939\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.0586 - accuracy: 0.6257\n",
      "Training: batch 15 begins at 15:08:29.332966\n",
      "\n",
      "Training: batch 15 ends at 15:08:30.909584\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.0678 - accuracy: 0.6237\n",
      "Training: batch 16 begins at 15:08:30.910681\n",
      "\n",
      "Training: batch 16 ends at 15:08:32.496733\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.0724 - accuracy: 0.6204\n",
      "Training: batch 17 begins at 15:08:32.497755\n",
      "\n",
      "Training: batch 17 ends at 15:08:34.076757\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.0835 - accuracy: 0.6170\n",
      "Evaluating: batch 0 begins at 15:08:34.085145\n",
      "\n",
      "Evaluating: batch 0 ends at 15:08:34.614324\n",
      "\n",
      "Evaluating: batch 1 begins at 15:08:34.614882\n",
      "\n",
      "Evaluating: batch 1 ends at 15:08:35.087096\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.0835 - accuracy: 0.6170 - val_loss: 1.0554 - val_accuracy: 0.6444\n",
      "Epoch 13/35\n",
      "\n",
      "Training: batch 0 begins at 15:08:35.096795\n",
      "\n",
      "Training: batch 0 ends at 15:08:36.703777\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.0475 - accuracy: 0.6536\n",
      "Training: batch 1 begins at 15:08:36.706286\n",
      "\n",
      "Training: batch 1 ends at 15:08:38.292130\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0772 - accuracy: 0.6407\n",
      "Training: batch 2 begins at 15:08:38.293302\n",
      "\n",
      "Training: batch 2 ends at 15:08:39.896438\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.0858 - accuracy: 0.6335\n",
      "Training: batch 3 begins at 15:08:39.897475\n",
      "\n",
      "Training: batch 3 ends at 15:08:41.505912\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.1193 - accuracy: 0.6324\n",
      "Training: batch 4 begins at 15:08:41.507009\n",
      "\n",
      "Training: batch 4 ends at 15:08:43.114159\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.0734 - accuracy: 0.6558\n",
      "Training: batch 5 begins at 15:08:43.115261\n",
      "\n",
      "Training: batch 5 ends at 15:08:44.710640\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.0727 - accuracy: 0.6558\n",
      "Training: batch 6 begins at 15:08:44.711748\n",
      "\n",
      "Training: batch 6 ends at 15:08:46.306207\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.0583 - accuracy: 0.6621\n",
      "Training: batch 7 begins at 15:08:46.307389\n",
      "\n",
      "Training: batch 7 ends at 15:08:47.884717\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.0354 - accuracy: 0.6588\n",
      "Training: batch 8 begins at 15:08:47.885806\n",
      "\n",
      "Training: batch 8 ends at 15:08:49.471773\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.0633 - accuracy: 0.6505\n",
      "Training: batch 9 begins at 15:08:49.472853\n",
      "\n",
      "Training: batch 9 ends at 15:08:51.069638\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.0692 - accuracy: 0.6475\n",
      "Training: batch 10 begins at 15:08:51.070812\n",
      "\n",
      "Training: batch 10 ends at 15:08:52.655481\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.0555 - accuracy: 0.6522\n",
      "Training: batch 11 begins at 15:08:52.656567\n",
      "\n",
      "Training: batch 11 ends at 15:08:54.256847\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.0394 - accuracy: 0.6545 \n",
      "Training: batch 12 begins at 15:08:54.257966\n",
      "\n",
      "Training: batch 12 ends at 15:08:55.848993\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.0498 - accuracy: 0.6452\n",
      "Training: batch 13 begins at 15:08:55.850048\n",
      "\n",
      "Training: batch 13 ends at 15:08:57.446643\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.0469 - accuracy: 0.6474\n",
      "Training: batch 14 begins at 15:08:57.447711\n",
      "\n",
      "Training: batch 14 ends at 15:08:59.028073\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.0495 - accuracy: 0.6442\n",
      "Training: batch 15 begins at 15:08:59.029140\n",
      "\n",
      "Training: batch 15 ends at 15:09:00.612044\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.0418 - accuracy: 0.6450\n",
      "Training: batch 16 begins at 15:09:00.613075\n",
      "\n",
      "Training: batch 16 ends at 15:09:02.202767\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.0465 - accuracy: 0.6431\n",
      "Training: batch 17 begins at 15:09:02.203832\n",
      "\n",
      "Training: batch 17 ends at 15:09:03.775936\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.0599 - accuracy: 0.6402\n",
      "Evaluating: batch 0 begins at 15:09:03.787420\n",
      "\n",
      "Evaluating: batch 0 ends at 15:09:04.297665\n",
      "\n",
      "Evaluating: batch 1 begins at 15:09:04.299603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: batch 1 ends at 15:09:04.772070\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.0599 - accuracy: 0.6402 - val_loss: 1.0554 - val_accuracy: 0.6322\n",
      "Epoch 14/35\n",
      "\n",
      "Training: batch 0 begins at 15:09:04.782106\n",
      "\n",
      "Training: batch 0 ends at 15:09:06.394879\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 0.8283 - accuracy: 0.7124\n",
      "Training: batch 1 begins at 15:09:06.395886\n",
      "\n",
      "Training: batch 1 ends at 15:09:07.993591\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.8949 - accuracy: 0.6654\n",
      "Training: batch 2 begins at 15:09:07.994672\n",
      "\n",
      "Training: batch 2 ends at 15:09:09.588495\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.8590 - accuracy: 0.6894\n",
      "Training: batch 3 begins at 15:09:09.589640\n",
      "\n",
      "Training: batch 3 ends at 15:09:11.172796\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.8733 - accuracy: 0.6812\n",
      "Training: batch 4 begins at 15:09:11.173975\n",
      "\n",
      "Training: batch 4 ends at 15:09:12.774221\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9151 - accuracy: 0.6738\n",
      "Training: batch 5 begins at 15:09:12.775253\n",
      "\n",
      "Training: batch 5 ends at 15:09:14.360577\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.9482 - accuracy: 0.6736\n",
      "Training: batch 6 begins at 15:09:14.361607\n",
      "\n",
      "Training: batch 6 ends at 15:09:15.952685\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.0174 - accuracy: 0.6531\n",
      "Training: batch 7 begins at 15:09:15.953725\n",
      "\n",
      "Training: batch 7 ends at 15:09:17.565554\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 1.0188 - accuracy: 0.6501\n",
      "Training: batch 8 begins at 15:09:17.566694\n",
      "\n",
      "Training: batch 8 ends at 15:09:19.160056\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.0311 - accuracy: 0.6475\n",
      "Training: batch 9 begins at 15:09:19.161039\n",
      "\n",
      "Training: batch 9 ends at 15:09:20.750204\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.0340 - accuracy: 0.6497\n",
      "Training: batch 10 begins at 15:09:20.751321\n",
      "\n",
      "Training: batch 10 ends at 15:09:22.355163\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.0152 - accuracy: 0.6548\n",
      "Training: batch 11 begins at 15:09:22.356332\n",
      "\n",
      "Training: batch 11 ends at 15:09:23.946762\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.0161 - accuracy: 0.6587 \n",
      "Training: batch 12 begins at 15:09:23.947780\n",
      "\n",
      "Training: batch 12 ends at 15:09:25.546355\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.0181 - accuracy: 0.6550\n",
      "Training: batch 13 begins at 15:09:25.547565\n",
      "\n",
      "Training: batch 13 ends at 15:09:27.140727\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.0086 - accuracy: 0.6597\n",
      "Training: batch 14 begins at 15:09:27.141835\n",
      "\n",
      "Training: batch 14 ends at 15:09:28.721400\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.0090 - accuracy: 0.6607\n",
      "Training: batch 15 begins at 15:09:28.722511\n",
      "\n",
      "Training: batch 15 ends at 15:09:30.298370\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9970 - accuracy: 0.6666\n",
      "Training: batch 16 begins at 15:09:30.299425\n",
      "\n",
      "Training: batch 16 ends at 15:09:31.881433\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.0177 - accuracy: 0.6570\n",
      "Training: batch 17 begins at 15:09:31.882604\n",
      "\n",
      "Training: batch 17 ends at 15:09:33.475232\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.0357 - accuracy: 0.6508\n",
      "Evaluating: batch 0 begins at 15:09:33.483658\n",
      "\n",
      "Evaluating: batch 0 ends at 15:09:34.017730\n",
      "\n",
      "Evaluating: batch 1 begins at 15:09:34.018223\n",
      "\n",
      "Evaluating: batch 1 ends at 15:09:34.489893\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.0357 - accuracy: 0.6508 - val_loss: 1.0976 - val_accuracy: 0.6553\n",
      "Epoch 15/35\n",
      "\n",
      "Training: batch 0 begins at 15:09:34.499262\n",
      "\n",
      "Training: batch 0 ends at 15:09:36.092401\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 0.7695 - accuracy: 0.7431\n",
      "Training: batch 1 begins at 15:09:36.093532\n",
      "\n",
      "Training: batch 1 ends at 15:09:37.707106\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.6615 - accuracy: 0.7831\n",
      "Training: batch 2 begins at 15:09:37.708159\n",
      "\n",
      "Training: batch 2 ends at 15:09:39.282066\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.7907 - accuracy: 0.7349\n",
      "Training: batch 3 begins at 15:09:39.283087\n",
      "\n",
      "Training: batch 3 ends at 15:09:40.878004\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.8846 - accuracy: 0.7050\n",
      "Training: batch 4 begins at 15:09:40.879086\n",
      "\n",
      "Training: batch 4 ends at 15:09:42.487877\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8588 - accuracy: 0.7146\n",
      "Training: batch 5 begins at 15:09:42.489203\n",
      "\n",
      "Training: batch 5 ends at 15:09:44.116641\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8466 - accuracy: 0.7220\n",
      "Training: batch 6 begins at 15:09:44.118135\n",
      "\n",
      "Training: batch 6 ends at 15:09:45.728647\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.9138 - accuracy: 0.6964\n",
      "Training: batch 7 begins at 15:09:45.729722\n",
      "\n",
      "Training: batch 7 ends at 15:09:47.363237\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 0.9663 - accuracy: 0.6825\n",
      "Training: batch 8 begins at 15:09:47.364344\n",
      "\n",
      "Training: batch 8 ends at 15:09:48.963057\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9481 - accuracy: 0.6830\n",
      "Training: batch 9 begins at 15:09:48.964172\n",
      "\n",
      "Training: batch 9 ends at 15:09:50.571461\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9553 - accuracy: 0.6829\n",
      "Training: batch 10 begins at 15:09:50.572637\n",
      "\n",
      "Training: batch 10 ends at 15:09:52.200375\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9371 - accuracy: 0.6870\n",
      "Training: batch 11 begins at 15:09:52.201415\n",
      "\n",
      "Training: batch 11 ends at 15:09:53.810532\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9470 - accuracy: 0.6848 \n",
      "Training: batch 12 begins at 15:09:53.811616\n",
      "\n",
      "Training: batch 12 ends at 15:09:55.446990\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 0.9656 - accuracy: 0.6753\n",
      "Training: batch 13 begins at 15:09:55.448248\n",
      "\n",
      "Training: batch 13 ends at 15:09:57.079176\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9758 - accuracy: 0.6750\n",
      "Training: batch 14 begins at 15:09:57.080355\n",
      "\n",
      "Training: batch 14 ends at 15:09:58.676397\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9888 - accuracy: 0.6680\n",
      "Training: batch 15 begins at 15:09:58.677536\n",
      "\n",
      "Training: batch 15 ends at 15:10:00.271639\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9828 - accuracy: 0.6699\n",
      "Training: batch 16 begins at 15:10:00.272766\n",
      "\n",
      "Training: batch 16 ends at 15:10:01.945438\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9774 - accuracy: 0.6701\n",
      "Training: batch 17 begins at 15:10:01.946653\n",
      "\n",
      "Training: batch 17 ends at 15:10:03.557459\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9950 - accuracy: 0.6661\n",
      "Evaluating: batch 0 begins at 15:10:03.568625\n",
      "\n",
      "Evaluating: batch 0 ends at 15:10:04.090224\n",
      "\n",
      "Evaluating: batch 1 begins at 15:10:04.091419\n",
      "\n",
      "Evaluating: batch 1 ends at 15:10:04.564641\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9950 - accuracy: 0.6661 - val_loss: 1.0672 - val_accuracy: 0.6568\n",
      "Epoch 16/35\n",
      "\n",
      "Training: batch 0 begins at 15:10:04.575098\n",
      "\n",
      "Training: batch 0 ends at 15:10:06.190541\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.1599 - accuracy: 0.5718\n",
      "Training: batch 1 begins at 15:10:06.191618\n",
      "\n",
      "Training: batch 1 ends at 15:10:07.770727\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0088 - accuracy: 0.6330\n",
      "Training: batch 2 begins at 15:10:07.771800\n",
      "\n",
      "Training: batch 2 ends at 15:10:09.382871\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.0110 - accuracy: 0.6382\n",
      "Training: batch 3 begins at 15:10:09.383930\n",
      "\n",
      "Training: batch 3 ends at 15:10:10.996317\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.0190 - accuracy: 0.6410\n",
      "Training: batch 4 begins at 15:10:10.997433\n",
      "\n",
      "Training: batch 4 ends at 15:10:12.598565\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9936 - accuracy: 0.6538\n",
      "Training: batch 5 begins at 15:10:12.599594\n",
      "\n",
      "Training: batch 5 ends at 15:10:14.209433\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.0144 - accuracy: 0.6411\n",
      "Training: batch 6 begins at 15:10:14.210462\n",
      "\n",
      "Training: batch 6 ends at 15:10:15.838775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.0366 - accuracy: 0.6319\n",
      "Training: batch 7 begins at 15:10:15.839769\n",
      "\n",
      "Training: batch 7 ends at 15:10:17.447628\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.0340 - accuracy: 0.6350\n",
      "Training: batch 8 begins at 15:10:17.448697\n",
      "\n",
      "Training: batch 8 ends at 15:10:19.030934\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.0296 - accuracy: 0.6366\n",
      "Training: batch 9 begins at 15:10:19.032097\n",
      "\n",
      "Training: batch 9 ends at 15:10:20.632745\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.0274 - accuracy: 0.6356\n",
      "Training: batch 10 begins at 15:10:20.633818\n",
      "\n",
      "Training: batch 10 ends at 15:10:22.213876\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.0218 - accuracy: 0.6395\n",
      "Training: batch 11 begins at 15:10:22.214889\n",
      "\n",
      "Training: batch 11 ends at 15:10:23.823206\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.0164 - accuracy: 0.6388 \n",
      "Training: batch 12 begins at 15:10:23.824268\n",
      "\n",
      "Training: batch 12 ends at 15:10:25.426600\n",
      "13/18 [====================>.........] - ETA: 8s - loss: 1.0057 - accuracy: 0.6440\n",
      "Training: batch 13 begins at 15:10:25.427602\n",
      "\n",
      "Training: batch 13 ends at 15:10:26.999818\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9708 - accuracy: 0.6571\n",
      "Training: batch 14 begins at 15:10:27.000827\n",
      "\n",
      "Training: batch 14 ends at 15:10:28.573724\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.0115 - accuracy: 0.6444\n",
      "Training: batch 15 begins at 15:10:28.574812\n",
      "\n",
      "Training: batch 15 ends at 15:10:30.168353\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.0106 - accuracy: 0.6466\n",
      "Training: batch 16 begins at 15:10:30.169311\n",
      "\n",
      "Training: batch 16 ends at 15:10:31.753835\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.0038 - accuracy: 0.6485\n",
      "Training: batch 17 begins at 15:10:31.754846\n",
      "\n",
      "Training: batch 17 ends at 15:10:33.339465\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.0256 - accuracy: 0.6431\n",
      "Evaluating: batch 0 begins at 15:10:33.348296\n",
      "\n",
      "Evaluating: batch 0 ends at 15:10:33.875197\n",
      "\n",
      "Evaluating: batch 1 begins at 15:10:33.875715\n",
      "\n",
      "Evaluating: batch 1 ends at 15:10:34.345970\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.0256 - accuracy: 0.6431 - val_loss: 1.0529 - val_accuracy: 0.6599\n",
      "Epoch 17/35\n",
      "\n",
      "Training: batch 0 begins at 15:10:34.355368\n",
      "\n",
      "Training: batch 0 ends at 15:10:35.950685\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.0447 - accuracy: 0.6422\n",
      "Training: batch 1 begins at 15:10:35.951708\n",
      "\n",
      "Training: batch 1 ends at 15:10:37.541634\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9939 - accuracy: 0.6677\n",
      "Training: batch 2 begins at 15:10:37.542632\n",
      "\n",
      "Training: batch 2 ends at 15:10:39.157880\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 1.0028 - accuracy: 0.6778\n",
      "Training: batch 3 begins at 15:10:39.158903\n",
      "\n",
      "Training: batch 3 ends at 15:10:40.764159\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.0157 - accuracy: 0.6668\n",
      "Training: batch 4 begins at 15:10:40.765152\n",
      "\n",
      "Training: batch 4 ends at 15:10:42.357685\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.0714 - accuracy: 0.6455\n",
      "Training: batch 5 begins at 15:10:42.358833\n",
      "\n",
      "Training: batch 5 ends at 15:10:43.962738\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.0903 - accuracy: 0.6391\n",
      "Training: batch 6 begins at 15:10:43.963867\n",
      "\n",
      "Training: batch 6 ends at 15:10:45.562520\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.0653 - accuracy: 0.6438\n",
      "Training: batch 7 begins at 15:10:45.563603\n",
      "\n",
      "Training: batch 7 ends at 15:10:47.166141\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.0511 - accuracy: 0.6493\n",
      "Training: batch 8 begins at 15:10:47.167266\n",
      "\n",
      "Training: batch 8 ends at 15:10:48.766825\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.0445 - accuracy: 0.6518\n",
      "Training: batch 9 begins at 15:10:48.767898\n",
      "\n",
      "Training: batch 9 ends at 15:10:50.340378\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 1.0441 - accuracy: 0.6527\n",
      "Training: batch 10 begins at 15:10:50.341447\n",
      "\n",
      "Training: batch 10 ends at 15:10:51.929683\n",
      "11/18 [=================>............] - ETA: 11s - loss: 1.0536 - accuracy: 0.6434\n",
      "Training: batch 11 begins at 15:10:51.930762\n",
      "\n",
      "Training: batch 11 ends at 15:10:53.521526\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 1.0430 - accuracy: 0.6488 \n",
      "Training: batch 12 begins at 15:10:53.522525\n",
      "\n",
      "Training: batch 12 ends at 15:10:55.124391\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 1.0327 - accuracy: 0.6513\n",
      "Training: batch 13 begins at 15:10:55.126147\n",
      "\n",
      "Training: batch 13 ends at 15:10:56.720445\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.0303 - accuracy: 0.6491\n",
      "Training: batch 14 begins at 15:10:56.721506\n",
      "\n",
      "Training: batch 14 ends at 15:10:58.289569\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.0168 - accuracy: 0.6541\n",
      "Training: batch 15 begins at 15:10:58.290600\n",
      "\n",
      "Training: batch 15 ends at 15:10:59.893633\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.0178 - accuracy: 0.6553\n",
      "Training: batch 16 begins at 15:10:59.894721\n",
      "\n",
      "Training: batch 16 ends at 15:11:01.499411\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.0131 - accuracy: 0.6564\n",
      "Training: batch 17 begins at 15:11:01.500394\n",
      "\n",
      "Training: batch 17 ends at 15:11:03.089890\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.0075 - accuracy: 0.6588\n",
      "Evaluating: batch 0 begins at 15:11:03.098469\n",
      "\n",
      "Evaluating: batch 0 ends at 15:11:03.598015\n",
      "\n",
      "Evaluating: batch 1 begins at 15:11:03.598529\n",
      "\n",
      "Evaluating: batch 1 ends at 15:11:04.073778\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.0075 - accuracy: 0.6588 - val_loss: 1.1140 - val_accuracy: 0.6398\n",
      "Epoch 18/35\n",
      "\n",
      "Training: batch 0 begins at 15:11:04.083456\n",
      "\n",
      "Training: batch 0 ends at 15:11:05.667147\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 0.7325 - accuracy: 0.7111\n",
      "Training: batch 1 begins at 15:11:05.668168\n",
      "\n",
      "Training: batch 1 ends at 15:11:07.243739\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.7698 - accuracy: 0.7225\n",
      "Training: batch 2 begins at 15:11:07.244769\n",
      "\n",
      "Training: batch 2 ends at 15:11:08.858514\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.8077 - accuracy: 0.7165\n",
      "Training: batch 3 begins at 15:11:08.859697\n",
      "\n",
      "Training: batch 3 ends at 15:11:10.449435\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.8183 - accuracy: 0.7080\n",
      "Training: batch 4 begins at 15:11:10.450561\n",
      "\n",
      "Training: batch 4 ends at 15:11:12.073646\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8725 - accuracy: 0.6967\n",
      "Training: batch 5 begins at 15:11:12.075041\n",
      "\n",
      "Training: batch 5 ends at 15:11:13.703438\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8519 - accuracy: 0.7065\n",
      "Training: batch 6 begins at 15:11:13.704604\n",
      "\n",
      "Training: batch 6 ends at 15:11:15.283873\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8576 - accuracy: 0.7067\n",
      "Training: batch 7 begins at 15:11:15.284882\n",
      "\n",
      "Training: batch 7 ends at 15:11:16.873208\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 0.8778 - accuracy: 0.6957\n",
      "Training: batch 8 begins at 15:11:16.874240\n",
      "\n",
      "Training: batch 8 ends at 15:11:18.480283\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.8762 - accuracy: 0.6985\n",
      "Training: batch 9 begins at 15:11:18.481327\n",
      "\n",
      "Training: batch 9 ends at 15:11:20.066558\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.8785 - accuracy: 0.6980\n",
      "Training: batch 10 begins at 15:11:20.067614\n",
      "\n",
      "Training: batch 10 ends at 15:11:21.632903\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.8984 - accuracy: 0.6943\n",
      "Training: batch 11 begins at 15:11:21.634030\n",
      "\n",
      "Training: batch 11 ends at 15:11:23.235506\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.8980 - accuracy: 0.6944 \n",
      "Training: batch 12 begins at 15:11:23.236658\n",
      "\n",
      "Training: batch 12 ends at 15:11:24.845761\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9413 - accuracy: 0.6785\n",
      "Training: batch 13 begins at 15:11:24.846759\n",
      "\n",
      "Training: batch 13 ends at 15:11:26.475927\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9521 - accuracy: 0.6749\n",
      "Training: batch 14 begins at 15:11:26.476966\n",
      "\n",
      "Training: batch 14 ends at 15:11:28.096198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9525 - accuracy: 0.6736\n",
      "Training: batch 15 begins at 15:11:28.097344\n",
      "\n",
      "Training: batch 15 ends at 15:11:29.713370\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9546 - accuracy: 0.6696\n",
      "Training: batch 16 begins at 15:11:29.714407\n",
      "\n",
      "Training: batch 16 ends at 15:11:31.331056\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9448 - accuracy: 0.6736\n",
      "Training: batch 17 begins at 15:11:31.332082\n",
      "\n",
      "Training: batch 17 ends at 15:11:32.913994\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.6664\n",
      "Evaluating: batch 0 begins at 15:11:32.922977\n",
      "\n",
      "Evaluating: batch 0 ends at 15:11:33.442206\n",
      "\n",
      "Evaluating: batch 1 begins at 15:11:33.442710\n",
      "\n",
      "Evaluating: batch 1 ends at 15:11:33.929551\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9607 - accuracy: 0.6664 - val_loss: 1.0190 - val_accuracy: 0.6687\n",
      "Epoch 19/35\n",
      "\n",
      "Training: batch 0 begins at 15:11:33.940557\n",
      "\n",
      "Training: batch 0 ends at 15:11:35.565615\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 0.7934 - accuracy: 0.7253\n",
      "Training: batch 1 begins at 15:11:35.567047\n",
      "\n",
      "Training: batch 1 ends at 15:11:37.139371\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9366 - accuracy: 0.6564\n",
      "Training: batch 2 begins at 15:11:37.140395\n",
      "\n",
      "Training: batch 2 ends at 15:11:38.704240\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.0551 - accuracy: 0.6134\n",
      "Training: batch 3 begins at 15:11:38.706210\n",
      "\n",
      "Training: batch 3 ends at 15:11:40.282369\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 1.0418 - accuracy: 0.6275\n",
      "Training: batch 4 begins at 15:11:40.283498\n",
      "\n",
      "Training: batch 4 ends at 15:11:41.995972\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.0367 - accuracy: 0.6350\n",
      "Training: batch 5 begins at 15:11:41.997528\n",
      "\n",
      "Training: batch 5 ends at 15:11:43.607512\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 1.0120 - accuracy: 0.6354\n",
      "Training: batch 6 begins at 15:11:43.609006\n",
      "\n",
      "Training: batch 6 ends at 15:11:45.188824\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 1.0438 - accuracy: 0.6184\n",
      "Training: batch 7 begins at 15:11:45.190032\n",
      "\n",
      "Training: batch 7 ends at 15:11:46.800033\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 1.0197 - accuracy: 0.6325\n",
      "Training: batch 8 begins at 15:11:46.801273\n",
      "\n",
      "Training: batch 8 ends at 15:11:48.392843\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 1.0013 - accuracy: 0.6340\n",
      "Training: batch 9 begins at 15:11:48.393968\n",
      "\n",
      "Training: batch 9 ends at 15:11:49.975781\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9976 - accuracy: 0.6395\n",
      "Training: batch 10 begins at 15:11:49.976805\n",
      "\n",
      "Training: batch 10 ends at 15:11:51.548128\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9900 - accuracy: 0.6441\n",
      "Training: batch 11 begins at 15:11:51.549144\n",
      "\n",
      "Training: batch 11 ends at 15:11:53.131957\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9723 - accuracy: 0.6512 \n",
      "Training: batch 12 begins at 15:11:53.132998\n",
      "\n",
      "Training: batch 12 ends at 15:11:54.712995\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9644 - accuracy: 0.6537\n",
      "Training: batch 13 begins at 15:11:54.714087\n",
      "\n",
      "Training: batch 13 ends at 15:11:56.299369\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9648 - accuracy: 0.6547\n",
      "Training: batch 14 begins at 15:11:56.300456\n",
      "\n",
      "Training: batch 14 ends at 15:11:57.914151\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9708 - accuracy: 0.6540\n",
      "Training: batch 15 begins at 15:11:57.915180\n",
      "\n",
      "Training: batch 15 ends at 15:11:59.494304\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9719 - accuracy: 0.6536\n",
      "Training: batch 16 begins at 15:11:59.495449\n",
      "\n",
      "Training: batch 16 ends at 15:12:01.064626\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9746 - accuracy: 0.6530\n",
      "Training: batch 17 begins at 15:12:01.065902\n",
      "\n",
      "Training: batch 17 ends at 15:12:02.647563\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9883 - accuracy: 0.6497\n",
      "Evaluating: batch 0 begins at 15:12:02.658254\n",
      "\n",
      "Evaluating: batch 0 ends at 15:12:03.164687\n",
      "\n",
      "Evaluating: batch 1 begins at 15:12:03.165617\n",
      "\n",
      "Evaluating: batch 1 ends at 15:12:03.635021\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9883 - accuracy: 0.6497 - val_loss: 1.2364 - val_accuracy: 0.5902\n",
      "Epoch 20/35\n",
      "\n",
      "Training: batch 0 begins at 15:12:03.644914\n",
      "\n",
      "Training: batch 0 ends at 15:12:05.247808\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.1500 - accuracy: 0.6114\n",
      "Training: batch 1 begins at 15:12:05.248876\n",
      "\n",
      "Training: batch 1 ends at 15:12:06.840528\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0512 - accuracy: 0.6264\n",
      "Training: batch 2 begins at 15:12:06.841558\n",
      "\n",
      "Training: batch 2 ends at 15:12:08.444855\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9960 - accuracy: 0.6331\n",
      "Training: batch 3 begins at 15:12:08.445880\n",
      "\n",
      "Training: batch 3 ends at 15:12:10.045294\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9551 - accuracy: 0.6440\n",
      "Training: batch 4 begins at 15:12:10.046317\n",
      "\n",
      "Training: batch 4 ends at 15:12:11.643846\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9841 - accuracy: 0.6451\n",
      "Training: batch 5 begins at 15:12:11.644808\n",
      "\n",
      "Training: batch 5 ends at 15:12:13.241686\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.9817 - accuracy: 0.6494\n",
      "Training: batch 6 begins at 15:12:13.242745\n",
      "\n",
      "Training: batch 6 ends at 15:12:14.849794\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.9460 - accuracy: 0.6629\n",
      "Training: batch 7 begins at 15:12:14.850867\n",
      "\n",
      "Training: batch 7 ends at 15:12:16.435697\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.9862 - accuracy: 0.6495\n",
      "Training: batch 8 begins at 15:12:16.436741\n",
      "\n",
      "Training: batch 8 ends at 15:12:18.021612\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9933 - accuracy: 0.6487\n",
      "Training: batch 9 begins at 15:12:18.022598\n",
      "\n",
      "Training: batch 9 ends at 15:12:19.623038\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9825 - accuracy: 0.6544\n",
      "Training: batch 10 begins at 15:12:19.624175\n",
      "\n",
      "Training: batch 10 ends at 15:12:21.208754\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9876 - accuracy: 0.6551\n",
      "Training: batch 11 begins at 15:12:21.209823\n",
      "\n",
      "Training: batch 11 ends at 15:12:22.806737\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9806 - accuracy: 0.6556 \n",
      "Training: batch 12 begins at 15:12:22.807801\n",
      "\n",
      "Training: batch 12 ends at 15:12:24.365621\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9827 - accuracy: 0.6555\n",
      "Training: batch 13 begins at 15:12:24.366656\n",
      "\n",
      "Training: batch 13 ends at 15:12:25.947803\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9737 - accuracy: 0.6590\n",
      "Training: batch 14 begins at 15:12:25.948952\n",
      "\n",
      "Training: batch 14 ends at 15:12:27.546049\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9780 - accuracy: 0.6579\n",
      "Training: batch 15 begins at 15:12:27.547109\n",
      "\n",
      "Training: batch 15 ends at 15:12:29.115829\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9905 - accuracy: 0.6532\n",
      "Training: batch 16 begins at 15:12:29.116939\n",
      "\n",
      "Training: batch 16 ends at 15:12:30.694522\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9834 - accuracy: 0.6547\n",
      "Training: batch 17 begins at 15:12:30.695562\n",
      "\n",
      "Training: batch 17 ends at 15:12:32.308030\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9832 - accuracy: 0.6542\n",
      "Evaluating: batch 0 begins at 15:12:32.317112\n",
      "\n",
      "Evaluating: batch 0 ends at 15:12:32.844981\n",
      "\n",
      "Evaluating: batch 1 begins at 15:12:32.845474\n",
      "\n",
      "Evaluating: batch 1 ends at 15:12:33.316143\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9832 - accuracy: 0.6542 - val_loss: 0.9801 - val_accuracy: 0.6844\n",
      "Epoch 21/35\n",
      "\n",
      "Training: batch 0 begins at 15:12:33.325793\n",
      "\n",
      "Training: batch 0 ends at 15:12:34.914940\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.0571 - accuracy: 0.6476\n",
      "Training: batch 1 begins at 15:12:34.915944\n",
      "\n",
      "Training: batch 1 ends at 15:12:36.510305\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0012 - accuracy: 0.6577\n",
      "Training: batch 2 begins at 15:12:36.511410\n",
      "\n",
      "Training: batch 2 ends at 15:12:38.086490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/18 [====>.........................] - ETA: 23s - loss: 1.0007 - accuracy: 0.6549\n",
      "Training: batch 3 begins at 15:12:38.087779\n",
      "\n",
      "Training: batch 3 ends at 15:12:39.674437\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9698 - accuracy: 0.6640\n",
      "Training: batch 4 begins at 15:12:39.675528\n",
      "\n",
      "Training: batch 4 ends at 15:12:41.262891\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 1.0045 - accuracy: 0.6491\n",
      "Training: batch 5 begins at 15:12:41.264039\n",
      "\n",
      "Training: batch 5 ends at 15:12:42.837376\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.9678 - accuracy: 0.6610\n",
      "Training: batch 6 begins at 15:12:42.838499\n",
      "\n",
      "Training: batch 6 ends at 15:12:44.435553\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.9665 - accuracy: 0.6665\n",
      "Training: batch 7 begins at 15:12:44.436823\n",
      "\n",
      "Training: batch 7 ends at 15:12:46.028230\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.9435 - accuracy: 0.6764\n",
      "Training: batch 8 begins at 15:12:46.029325\n",
      "\n",
      "Training: batch 8 ends at 15:12:47.620637\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9331 - accuracy: 0.6793\n",
      "Training: batch 9 begins at 15:12:47.621718\n",
      "\n",
      "Training: batch 9 ends at 15:12:49.222201\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9391 - accuracy: 0.6766\n",
      "Training: batch 10 begins at 15:12:49.223246\n",
      "\n",
      "Training: batch 10 ends at 15:12:50.797398\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9906 - accuracy: 0.6554\n",
      "Training: batch 11 begins at 15:12:50.798335\n",
      "\n",
      "Training: batch 11 ends at 15:12:52.386416\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9676 - accuracy: 0.6655 \n",
      "Training: batch 12 begins at 15:12:52.387488\n",
      "\n",
      "Training: batch 12 ends at 15:12:53.979362\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9965 - accuracy: 0.6520\n",
      "Training: batch 13 begins at 15:12:53.980402\n",
      "\n",
      "Training: batch 13 ends at 15:12:55.591347\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9903 - accuracy: 0.6552\n",
      "Training: batch 14 begins at 15:12:55.592417\n",
      "\n",
      "Training: batch 14 ends at 15:12:57.182685\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9948 - accuracy: 0.6539\n",
      "Training: batch 15 begins at 15:12:57.183829\n",
      "\n",
      "Training: batch 15 ends at 15:12:58.806676\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9814 - accuracy: 0.6600\n",
      "Training: batch 16 begins at 15:12:58.807678\n",
      "\n",
      "Training: batch 16 ends at 15:13:00.396299\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9793 - accuracy: 0.6603\n",
      "Training: batch 17 begins at 15:13:00.397274\n",
      "\n",
      "Training: batch 17 ends at 15:13:01.994001\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9709 - accuracy: 0.6615\n",
      "Evaluating: batch 0 begins at 15:13:02.005169\n",
      "\n",
      "Evaluating: batch 0 ends at 15:13:02.503966\n",
      "\n",
      "Evaluating: batch 1 begins at 15:13:02.504453\n",
      "\n",
      "Evaluating: batch 1 ends at 15:13:02.984644\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9709 - accuracy: 0.6615 - val_loss: 1.0114 - val_accuracy: 0.6361\n",
      "Epoch 22/35\n",
      "\n",
      "Training: batch 0 begins at 15:13:02.995125\n",
      "\n",
      "Training: batch 0 ends at 15:13:04.571338\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 0.7903 - accuracy: 0.6970\n",
      "Training: batch 1 begins at 15:13:04.572506\n",
      "\n",
      "Training: batch 1 ends at 15:13:06.150629\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.8573 - accuracy: 0.6998\n",
      "Training: batch 2 begins at 15:13:06.151634\n",
      "\n",
      "Training: batch 2 ends at 15:13:07.738621\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.8764 - accuracy: 0.6889\n",
      "Training: batch 3 begins at 15:13:07.739624\n",
      "\n",
      "Training: batch 3 ends at 15:13:09.323019\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9135 - accuracy: 0.6693\n",
      "Training: batch 4 begins at 15:13:09.324056\n",
      "\n",
      "Training: batch 4 ends at 15:13:10.935609\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9307 - accuracy: 0.6683\n",
      "Training: batch 5 begins at 15:13:10.936670\n",
      "\n",
      "Training: batch 5 ends at 15:13:12.508378\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8776 - accuracy: 0.6923\n",
      "Training: batch 6 begins at 15:13:12.509447\n",
      "\n",
      "Training: batch 6 ends at 15:13:14.108778\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.9354 - accuracy: 0.6691\n",
      "Training: batch 7 begins at 15:13:14.109867\n",
      "\n",
      "Training: batch 7 ends at 15:13:15.706147\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.9541 - accuracy: 0.6698\n",
      "Training: batch 8 begins at 15:13:15.707315\n",
      "\n",
      "Training: batch 8 ends at 15:13:17.289455\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9576 - accuracy: 0.6732\n",
      "Training: batch 9 begins at 15:13:17.290525\n",
      "\n",
      "Training: batch 9 ends at 15:13:18.904144\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9512 - accuracy: 0.6739\n",
      "Training: batch 10 begins at 15:13:18.905148\n",
      "\n",
      "Training: batch 10 ends at 15:13:20.480727\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9243 - accuracy: 0.6831\n",
      "Training: batch 11 begins at 15:13:20.481808\n",
      "\n",
      "Training: batch 11 ends at 15:13:22.057034\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9229 - accuracy: 0.6838 \n",
      "Training: batch 12 begins at 15:13:22.058552\n",
      "\n",
      "Training: batch 12 ends at 15:13:23.618521\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9133 - accuracy: 0.6866\n",
      "Training: batch 13 begins at 15:13:23.619563\n",
      "\n",
      "Training: batch 13 ends at 15:13:25.213242\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9155 - accuracy: 0.6860\n",
      "Training: batch 14 begins at 15:13:25.214253\n",
      "\n",
      "Training: batch 14 ends at 15:13:26.795407\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9407 - accuracy: 0.6735\n",
      "Training: batch 15 begins at 15:13:26.796531\n",
      "\n",
      "Training: batch 15 ends at 15:13:28.379472\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9397 - accuracy: 0.6730\n",
      "Training: batch 16 begins at 15:13:28.380584\n",
      "\n",
      "Training: batch 16 ends at 15:13:29.970585\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9303 - accuracy: 0.6750\n",
      "Training: batch 17 begins at 15:13:29.971649\n",
      "\n",
      "Training: batch 17 ends at 15:13:31.561367\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9306 - accuracy: 0.6731\n",
      "Evaluating: batch 0 begins at 15:13:31.569811\n",
      "\n",
      "Evaluating: batch 0 ends at 15:13:32.094726\n",
      "\n",
      "Evaluating: batch 1 begins at 15:13:32.095258\n",
      "\n",
      "Evaluating: batch 1 ends at 15:13:32.563944\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9306 - accuracy: 0.6731 - val_loss: 0.9695 - val_accuracy: 0.6607\n",
      "Epoch 23/35\n",
      "\n",
      "Training: batch 0 begins at 15:13:32.575928\n",
      "\n",
      "Training: batch 0 ends at 15:13:34.156814\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 1.0733 - accuracy: 0.6181\n",
      "Training: batch 1 begins at 15:13:34.157877\n",
      "\n",
      "Training: batch 1 ends at 15:13:35.727935\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0134 - accuracy: 0.6453\n",
      "Training: batch 2 begins at 15:13:35.729132\n",
      "\n",
      "Training: batch 2 ends at 15:13:37.324401\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9503 - accuracy: 0.6763\n",
      "Training: batch 3 begins at 15:13:37.325530\n",
      "\n",
      "Training: batch 3 ends at 15:13:38.910806\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9468 - accuracy: 0.6867\n",
      "Training: batch 4 begins at 15:13:38.911877\n",
      "\n",
      "Training: batch 4 ends at 15:13:40.507937\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9363 - accuracy: 0.6864\n",
      "Training: batch 5 begins at 15:13:40.509080\n",
      "\n",
      "Training: batch 5 ends at 15:13:42.101556\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.9360 - accuracy: 0.6860\n",
      "Training: batch 6 begins at 15:13:42.102589\n",
      "\n",
      "Training: batch 6 ends at 15:13:43.713080\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.9123 - accuracy: 0.6927\n",
      "Training: batch 7 begins at 15:13:43.714201\n",
      "\n",
      "Training: batch 7 ends at 15:13:45.320370\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.9017 - accuracy: 0.6956\n",
      "Training: batch 8 begins at 15:13:45.321356\n",
      "\n",
      "Training: batch 8 ends at 15:13:46.923133\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9007 - accuracy: 0.6974\n",
      "Training: batch 9 begins at 15:13:46.924127\n",
      "\n",
      "Training: batch 9 ends at 15:13:48.512798\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9073 - accuracy: 0.6941\n",
      "Training: batch 10 begins at 15:13:48.513898\n",
      "\n",
      "Training: batch 10 ends at 15:13:50.095105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 [=================>............] - ETA: 11s - loss: 0.8928 - accuracy: 0.6965\n",
      "Training: batch 11 begins at 15:13:50.096157\n",
      "\n",
      "Training: batch 11 ends at 15:13:51.682747\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.8758 - accuracy: 0.7018 \n",
      "Training: batch 12 begins at 15:13:51.683857\n",
      "\n",
      "Training: batch 12 ends at 15:13:53.265813\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.8777 - accuracy: 0.7005\n",
      "Training: batch 13 begins at 15:13:53.266938\n",
      "\n",
      "Training: batch 13 ends at 15:13:54.872797\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.8772 - accuracy: 0.6967\n",
      "Training: batch 14 begins at 15:13:54.873907\n",
      "\n",
      "Training: batch 14 ends at 15:13:56.467646\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9121 - accuracy: 0.6885\n",
      "Training: batch 15 begins at 15:13:56.468715\n",
      "\n",
      "Training: batch 15 ends at 15:13:58.071010\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9126 - accuracy: 0.6893\n",
      "Training: batch 16 begins at 15:13:58.072007\n",
      "\n",
      "Training: batch 16 ends at 15:13:59.644958\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9200 - accuracy: 0.6856\n",
      "Training: batch 17 begins at 15:13:59.646063\n",
      "\n",
      "Training: batch 17 ends at 15:14:01.249757\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9194 - accuracy: 0.6870\n",
      "Evaluating: batch 0 begins at 15:14:01.260533\n",
      "\n",
      "Evaluating: batch 0 ends at 15:14:01.772199\n",
      "\n",
      "Evaluating: batch 1 begins at 15:14:01.772693\n",
      "\n",
      "Evaluating: batch 1 ends at 15:14:02.243089\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9194 - accuracy: 0.6870 - val_loss: 1.1824 - val_accuracy: 0.5880\n",
      "Epoch 24/35\n",
      "\n",
      "Training: batch 0 begins at 15:14:02.253446\n",
      "\n",
      "Training: batch 0 ends at 15:14:03.867586\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 0.8530 - accuracy: 0.7162\n",
      "Training: batch 1 begins at 15:14:03.868594\n",
      "\n",
      "Training: batch 1 ends at 15:14:05.456320\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.8578 - accuracy: 0.7108\n",
      "Training: batch 2 begins at 15:14:05.457375\n",
      "\n",
      "Training: batch 2 ends at 15:14:07.043846\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.7807 - accuracy: 0.7419\n",
      "Training: batch 3 begins at 15:14:07.044879\n",
      "\n",
      "Training: batch 3 ends at 15:14:08.628617\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.7889 - accuracy: 0.7349\n",
      "Training: batch 4 begins at 15:14:08.629781\n",
      "\n",
      "Training: batch 4 ends at 15:14:10.217373\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8826 - accuracy: 0.6951\n",
      "Training: batch 5 begins at 15:14:10.218423\n",
      "\n",
      "Training: batch 5 ends at 15:14:11.792243\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8877 - accuracy: 0.6927\n",
      "Training: batch 6 begins at 15:14:11.795114\n",
      "\n",
      "Training: batch 6 ends at 15:14:13.366133\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8966 - accuracy: 0.6916\n",
      "Training: batch 7 begins at 15:14:13.367148\n",
      "\n",
      "Training: batch 7 ends at 15:14:14.966210\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.9073 - accuracy: 0.6887\n",
      "Training: batch 8 begins at 15:14:14.967176\n",
      "\n",
      "Training: batch 8 ends at 15:14:16.550499\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9148 - accuracy: 0.6844\n",
      "Training: batch 9 begins at 15:14:16.551570\n",
      "\n",
      "Training: batch 9 ends at 15:14:18.142833\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9317 - accuracy: 0.6796\n",
      "Training: batch 10 begins at 15:14:18.143865\n",
      "\n",
      "Training: batch 10 ends at 15:14:19.736389\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9289 - accuracy: 0.6821\n",
      "Training: batch 11 begins at 15:14:19.737350\n",
      "\n",
      "Training: batch 11 ends at 15:14:21.335514\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9563 - accuracy: 0.6683 \n",
      "Training: batch 12 begins at 15:14:21.336517\n",
      "\n",
      "Training: batch 12 ends at 15:14:22.925997\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9946 - accuracy: 0.6564\n",
      "Training: batch 13 begins at 15:14:22.926992\n",
      "\n",
      "Training: batch 13 ends at 15:14:24.498336\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 1.0164 - accuracy: 0.6512\n",
      "Training: batch 14 begins at 15:14:24.499325\n",
      "\n",
      "Training: batch 14 ends at 15:14:26.093300\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 1.0267 - accuracy: 0.6449\n",
      "Training: batch 15 begins at 15:14:26.094361\n",
      "\n",
      "Training: batch 15 ends at 15:14:27.671206\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 1.0296 - accuracy: 0.6439\n",
      "Training: batch 16 begins at 15:14:27.672330\n",
      "\n",
      "Training: batch 16 ends at 15:14:29.262140\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 1.0323 - accuracy: 0.6408\n",
      "Training: batch 17 begins at 15:14:29.263187\n",
      "\n",
      "Training: batch 17 ends at 15:14:30.826688\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.0317 - accuracy: 0.6416\n",
      "Evaluating: batch 0 begins at 15:14:30.835807\n",
      "\n",
      "Evaluating: batch 0 ends at 15:14:31.356648\n",
      "\n",
      "Evaluating: batch 1 begins at 15:14:31.357200\n",
      "\n",
      "Evaluating: batch 1 ends at 15:14:31.830643\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.0317 - accuracy: 0.6416 - val_loss: 1.0476 - val_accuracy: 0.6431\n",
      "Epoch 25/35\n",
      "\n",
      "Training: batch 0 begins at 15:14:31.839969\n",
      "\n",
      "Training: batch 0 ends at 15:14:33.438160\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.1058 - accuracy: 0.5901\n",
      "Training: batch 1 begins at 15:14:33.439269\n",
      "\n",
      "Training: batch 1 ends at 15:14:35.022536\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0025 - accuracy: 0.6425\n",
      "Training: batch 2 begins at 15:14:35.023625\n",
      "\n",
      "Training: batch 2 ends at 15:14:36.598756\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9273 - accuracy: 0.6759\n",
      "Training: batch 3 begins at 15:14:36.599820\n",
      "\n",
      "Training: batch 3 ends at 15:14:38.190547\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9172 - accuracy: 0.6819\n",
      "Training: batch 4 begins at 15:14:38.191895\n",
      "\n",
      "Training: batch 4 ends at 15:14:39.774499\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8877 - accuracy: 0.6939\n",
      "Training: batch 5 begins at 15:14:39.775500\n",
      "\n",
      "Training: batch 5 ends at 15:14:41.378042\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8965 - accuracy: 0.6949\n",
      "Training: batch 6 begins at 15:14:41.379069\n",
      "\n",
      "Training: batch 6 ends at 15:14:42.959468\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8917 - accuracy: 0.7016\n",
      "Training: batch 7 begins at 15:14:42.960513\n",
      "\n",
      "Training: batch 7 ends at 15:14:44.564431\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.8883 - accuracy: 0.7036\n",
      "Training: batch 8 begins at 15:14:44.566480\n",
      "\n",
      "Training: batch 8 ends at 15:14:46.176508\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.8912 - accuracy: 0.7031\n",
      "Training: batch 9 begins at 15:14:46.177556\n",
      "\n",
      "Training: batch 9 ends at 15:14:47.755623\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9014 - accuracy: 0.7005\n",
      "Training: batch 10 begins at 15:14:47.756715\n",
      "\n",
      "Training: batch 10 ends at 15:14:49.350017\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9311 - accuracy: 0.6885\n",
      "Training: batch 11 begins at 15:14:49.351063\n",
      "\n",
      "Training: batch 11 ends at 15:14:50.944795\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9249 - accuracy: 0.6895 \n",
      "Training: batch 12 begins at 15:14:50.945819\n",
      "\n",
      "Training: batch 12 ends at 15:14:52.519207\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9429 - accuracy: 0.6799\n",
      "Training: batch 13 begins at 15:14:52.520272\n",
      "\n",
      "Training: batch 13 ends at 15:14:54.104466\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9530 - accuracy: 0.6783\n",
      "Training: batch 14 begins at 15:14:54.105587\n",
      "\n",
      "Training: batch 14 ends at 15:14:55.684817\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9802 - accuracy: 0.6677\n",
      "Training: batch 15 begins at 15:14:55.685900\n",
      "\n",
      "Training: batch 15 ends at 15:14:57.276949\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9976 - accuracy: 0.6601\n",
      "Training: batch 16 begins at 15:14:57.277899\n",
      "\n",
      "Training: batch 16 ends at 15:14:58.874631\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9892 - accuracy: 0.6626\n",
      "Training: batch 17 begins at 15:14:58.875648\n",
      "\n",
      "Training: batch 17 ends at 15:15:00.459512\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9907 - accuracy: 0.6588\n",
      "Evaluating: batch 0 begins at 15:15:00.468543\n",
      "\n",
      "Evaluating: batch 0 ends at 15:15:00.967045\n",
      "\n",
      "Evaluating: batch 1 begins at 15:15:00.967510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: batch 1 ends at 15:15:01.437754\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9907 - accuracy: 0.6588 - val_loss: 1.6741 - val_accuracy: 0.6326\n",
      "Epoch 26/35\n",
      "\n",
      "Training: batch 0 begins at 15:15:01.447661\n",
      "\n",
      "Training: batch 0 ends at 15:15:03.051677\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.1448 - accuracy: 0.5856\n",
      "Training: batch 1 begins at 15:15:03.052758\n",
      "\n",
      "Training: batch 1 ends at 15:15:04.650299\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0116 - accuracy: 0.6362\n",
      "Training: batch 2 begins at 15:15:04.651468\n",
      "\n",
      "Training: batch 2 ends at 15:15:06.229670\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9690 - accuracy: 0.6504\n",
      "Training: batch 3 begins at 15:15:06.230700\n",
      "\n",
      "Training: batch 3 ends at 15:15:07.804975\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9313 - accuracy: 0.6625\n",
      "Training: batch 4 begins at 15:15:07.805984\n",
      "\n",
      "Training: batch 4 ends at 15:15:09.383476\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9662 - accuracy: 0.6501\n",
      "Training: batch 5 begins at 15:15:09.384464\n",
      "\n",
      "Training: batch 5 ends at 15:15:10.980984\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.9293 - accuracy: 0.6636\n",
      "Training: batch 6 begins at 15:15:10.982028\n",
      "\n",
      "Training: batch 6 ends at 15:15:12.582141\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8899 - accuracy: 0.6804\n",
      "Training: batch 7 begins at 15:15:12.583149\n",
      "\n",
      "Training: batch 7 ends at 15:15:14.177118\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.8942 - accuracy: 0.6776\n",
      "Training: batch 8 begins at 15:15:14.178123\n",
      "\n",
      "Training: batch 8 ends at 15:15:15.774888\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9042 - accuracy: 0.6658\n",
      "Training: batch 9 begins at 15:15:15.775951\n",
      "\n",
      "Training: batch 9 ends at 15:15:17.362874\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9331 - accuracy: 0.6580\n",
      "Training: batch 10 begins at 15:15:17.363905\n",
      "\n",
      "Training: batch 10 ends at 15:15:18.953860\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9211 - accuracy: 0.6662\n",
      "Training: batch 11 begins at 15:15:18.954934\n",
      "\n",
      "Training: batch 11 ends at 15:15:20.515786\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9197 - accuracy: 0.6675 \n",
      "Training: batch 12 begins at 15:15:20.516859\n",
      "\n",
      "Training: batch 12 ends at 15:15:22.115791\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9258 - accuracy: 0.6667\n",
      "Training: batch 13 begins at 15:15:22.116842\n",
      "\n",
      "Training: batch 13 ends at 15:15:23.731475\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9162 - accuracy: 0.6727\n",
      "Training: batch 14 begins at 15:15:23.732574\n",
      "\n",
      "Training: batch 14 ends at 15:15:25.309520\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.9188 - accuracy: 0.6747\n",
      "Training: batch 15 begins at 15:15:25.310517\n",
      "\n",
      "Training: batch 15 ends at 15:15:26.892471\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.9395 - accuracy: 0.6683\n",
      "Training: batch 16 begins at 15:15:26.893553\n",
      "\n",
      "Training: batch 16 ends at 15:15:28.479007\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.9447 - accuracy: 0.6660\n",
      "Training: batch 17 begins at 15:15:28.480011\n",
      "\n",
      "Training: batch 17 ends at 15:15:30.052766\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.9379 - accuracy: 0.6681\n",
      "Evaluating: batch 0 begins at 15:15:30.061408\n",
      "\n",
      "Evaluating: batch 0 ends at 15:15:30.574364\n",
      "\n",
      "Evaluating: batch 1 begins at 15:15:30.574870\n",
      "\n",
      "Evaluating: batch 1 ends at 15:15:31.055995\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.9379 - accuracy: 0.6681 - val_loss: 1.0653 - val_accuracy: 0.6359\n",
      "Epoch 27/35\n",
      "\n",
      "Training: batch 0 begins at 15:15:31.066109\n",
      "\n",
      "Training: batch 0 ends at 15:15:32.680099\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.1818 - accuracy: 0.5551\n",
      "Training: batch 1 begins at 15:15:32.681587\n",
      "\n",
      "Training: batch 1 ends at 15:15:34.280961\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9697 - accuracy: 0.6449\n",
      "Training: batch 2 begins at 15:15:34.281981\n",
      "\n",
      "Training: batch 2 ends at 15:15:35.880745\n",
      " 3/18 [====>.........................] - ETA: 24s - loss: 0.9306 - accuracy: 0.6786\n",
      "Training: batch 3 begins at 15:15:35.881710\n",
      "\n",
      "Training: batch 3 ends at 15:15:37.466334\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9032 - accuracy: 0.6810\n",
      "Training: batch 4 begins at 15:15:37.467467\n",
      "\n",
      "Training: batch 4 ends at 15:15:39.040808\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8930 - accuracy: 0.6800\n",
      "Training: batch 5 begins at 15:15:39.042033\n",
      "\n",
      "Training: batch 5 ends at 15:15:40.638610\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8774 - accuracy: 0.6865\n",
      "Training: batch 6 begins at 15:15:40.639625\n",
      "\n",
      "Training: batch 6 ends at 15:15:42.238424\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8879 - accuracy: 0.6875\n",
      "Training: batch 7 begins at 15:15:42.239466\n",
      "\n",
      "Training: batch 7 ends at 15:15:43.830820\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.8914 - accuracy: 0.6885\n",
      "Training: batch 8 begins at 15:15:43.831976\n",
      "\n",
      "Training: batch 8 ends at 15:15:45.437714\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9159 - accuracy: 0.6785\n",
      "Training: batch 9 begins at 15:15:45.438670\n",
      "\n",
      "Training: batch 9 ends at 15:15:47.032110\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9306 - accuracy: 0.6758\n",
      "Training: batch 10 begins at 15:15:47.033038\n",
      "\n",
      "Training: batch 10 ends at 15:15:48.612769\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.9194 - accuracy: 0.6801\n",
      "Training: batch 11 begins at 15:15:48.613761\n",
      "\n",
      "Training: batch 11 ends at 15:15:50.208306\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9202 - accuracy: 0.6792 \n",
      "Training: batch 12 begins at 15:15:50.209316\n",
      "\n",
      "Training: batch 12 ends at 15:15:51.808526\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9015 - accuracy: 0.6851\n",
      "Training: batch 13 begins at 15:15:51.809531\n",
      "\n",
      "Training: batch 13 ends at 15:15:53.393035\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.9050 - accuracy: 0.6836\n",
      "Training: batch 14 begins at 15:15:53.394075\n",
      "\n",
      "Training: batch 14 ends at 15:15:54.972496\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.8968 - accuracy: 0.6887\n",
      "Training: batch 15 begins at 15:15:54.973480\n",
      "\n",
      "Training: batch 15 ends at 15:15:56.541713\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.8876 - accuracy: 0.6931\n",
      "Training: batch 16 begins at 15:15:56.542723\n",
      "\n",
      "Training: batch 16 ends at 15:15:58.137796\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.8870 - accuracy: 0.6931\n",
      "Training: batch 17 begins at 15:15:58.138856\n",
      "\n",
      "Training: batch 17 ends at 15:15:59.707732\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8776 - accuracy: 0.6950\n",
      "Evaluating: batch 0 begins at 15:15:59.716892\n",
      "\n",
      "Evaluating: batch 0 ends at 15:16:00.226996\n",
      "\n",
      "Evaluating: batch 1 begins at 15:16:00.227511\n",
      "\n",
      "Evaluating: batch 1 ends at 15:16:00.699324\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.8776 - accuracy: 0.6950 - val_loss: 0.9675 - val_accuracy: 0.6730\n",
      "Epoch 28/35\n",
      "\n",
      "Training: batch 0 begins at 15:16:00.709194\n",
      "\n",
      "Training: batch 0 ends at 15:16:02.299783\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 1.0812 - accuracy: 0.6088\n",
      "Training: batch 1 begins at 15:16:02.300944\n",
      "\n",
      "Training: batch 1 ends at 15:16:03.889425\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9172 - accuracy: 0.6821\n",
      "Training: batch 2 begins at 15:16:03.890530\n",
      "\n",
      "Training: batch 2 ends at 15:16:05.485618\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.8501 - accuracy: 0.7064\n",
      "Training: batch 3 begins at 15:16:05.486680\n",
      "\n",
      "Training: batch 3 ends at 15:16:07.101615\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.8426 - accuracy: 0.7122\n",
      "Training: batch 4 begins at 15:16:07.102726\n",
      "\n",
      "Training: batch 4 ends at 15:16:08.702864\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8538 - accuracy: 0.7054\n",
      "Training: batch 5 begins at 15:16:08.703878\n",
      "\n",
      "Training: batch 5 ends at 15:16:10.299893\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8818 - accuracy: 0.6841\n",
      "Training: batch 6 begins at 15:16:10.300956\n",
      "\n",
      "Training: batch 6 ends at 15:16:11.898995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8951 - accuracy: 0.6821\n",
      "Training: batch 7 begins at 15:16:11.900071\n",
      "\n",
      "Training: batch 7 ends at 15:16:13.503691\n",
      " 8/18 [============>.................] - ETA: 16s - loss: 0.8884 - accuracy: 0.6859\n",
      "Training: batch 8 begins at 15:16:13.504824\n",
      "\n",
      "Training: batch 8 ends at 15:16:15.083066\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.8669 - accuracy: 0.6940\n",
      "Training: batch 9 begins at 15:16:15.084906\n",
      "\n",
      "Training: batch 9 ends at 15:16:16.669522\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.8612 - accuracy: 0.6945\n",
      "Training: batch 10 begins at 15:16:16.670610\n",
      "\n",
      "Training: batch 10 ends at 15:16:18.260890\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.8684 - accuracy: 0.6904\n",
      "Training: batch 11 begins at 15:16:18.262011\n",
      "\n",
      "Training: batch 11 ends at 15:16:19.864898\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.8661 - accuracy: 0.6935 \n",
      "Training: batch 12 begins at 15:16:19.865949\n",
      "\n",
      "Training: batch 12 ends at 15:16:21.445972\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.8910 - accuracy: 0.6857\n",
      "Training: batch 13 begins at 15:16:21.446914\n",
      "\n",
      "Training: batch 13 ends at 15:16:23.043231\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.8900 - accuracy: 0.6890\n",
      "Training: batch 14 begins at 15:16:23.044266\n",
      "\n",
      "Training: batch 14 ends at 15:16:24.631001\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.8892 - accuracy: 0.6903\n",
      "Training: batch 15 begins at 15:16:24.631996\n",
      "\n",
      "Training: batch 15 ends at 15:16:26.219209\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.8745 - accuracy: 0.6986\n",
      "Training: batch 16 begins at 15:16:26.220486\n",
      "\n",
      "Training: batch 16 ends at 15:16:27.819455\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.8718 - accuracy: 0.6993\n",
      "Training: batch 17 begins at 15:16:27.820789\n",
      "\n",
      "Training: batch 17 ends at 15:16:29.406626\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8647 - accuracy: 0.7013\n",
      "Evaluating: batch 0 begins at 15:16:29.415547\n",
      "\n",
      "Evaluating: batch 0 ends at 15:16:29.945495\n",
      "\n",
      "Evaluating: batch 1 begins at 15:16:29.946096\n",
      "\n",
      "Evaluating: batch 1 ends at 15:16:30.417035\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.8647 - accuracy: 0.7013 - val_loss: 1.0040 - val_accuracy: 0.6587\n",
      "Epoch 29/35\n",
      "\n",
      "Training: batch 0 begins at 15:16:30.426814\n",
      "\n",
      "Training: batch 0 ends at 15:16:32.031016\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 0.7582 - accuracy: 0.7227\n",
      "Training: batch 1 begins at 15:16:32.032078\n",
      "\n",
      "Training: batch 1 ends at 15:16:33.623323\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9444 - accuracy: 0.6585\n",
      "Training: batch 2 begins at 15:16:33.624299\n",
      "\n",
      "Training: batch 2 ends at 15:16:35.209562\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9240 - accuracy: 0.6726\n",
      "Training: batch 3 begins at 15:16:35.210699\n",
      "\n",
      "Training: batch 3 ends at 15:16:36.800270\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9488 - accuracy: 0.6704\n",
      "Training: batch 4 begins at 15:16:36.801402\n",
      "\n",
      "Training: batch 4 ends at 15:16:38.400105\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9205 - accuracy: 0.6842\n",
      "Training: batch 5 begins at 15:16:38.401275\n",
      "\n",
      "Training: batch 5 ends at 15:16:39.984339\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8656 - accuracy: 0.7054\n",
      "Training: batch 6 begins at 15:16:39.985467\n",
      "\n",
      "Training: batch 6 ends at 15:16:41.582719\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8785 - accuracy: 0.6989\n",
      "Training: batch 7 begins at 15:16:41.583778\n",
      "\n",
      "Training: batch 7 ends at 15:16:43.178461\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.9005 - accuracy: 0.6875\n",
      "Training: batch 8 begins at 15:16:43.179470\n",
      "\n",
      "Training: batch 8 ends at 15:16:44.760732\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.8783 - accuracy: 0.6961\n",
      "Training: batch 9 begins at 15:16:44.761733\n",
      "\n",
      "Training: batch 9 ends at 15:16:46.357584\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.8800 - accuracy: 0.6976\n",
      "Training: batch 10 begins at 15:16:46.358565\n",
      "\n",
      "Training: batch 10 ends at 15:16:47.947508\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.8897 - accuracy: 0.6916\n",
      "Training: batch 11 begins at 15:16:47.948590\n",
      "\n",
      "Training: batch 11 ends at 15:16:49.531053\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9022 - accuracy: 0.6881 \n",
      "Training: batch 12 begins at 15:16:49.532108\n",
      "\n",
      "Training: batch 12 ends at 15:16:51.117929\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.8859 - accuracy: 0.6942\n",
      "Training: batch 13 begins at 15:16:51.119361\n",
      "\n",
      "Training: batch 13 ends at 15:16:52.713160\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.8746 - accuracy: 0.6965\n",
      "Training: batch 14 begins at 15:16:52.714183\n",
      "\n",
      "Training: batch 14 ends at 15:16:54.304087\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.8584 - accuracy: 0.7032\n",
      "Training: batch 15 begins at 15:16:54.305086\n",
      "\n",
      "Training: batch 15 ends at 15:16:55.891978\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.8681 - accuracy: 0.7008\n",
      "Training: batch 16 begins at 15:16:55.892975\n",
      "\n",
      "Training: batch 16 ends at 15:16:57.479060\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.8667 - accuracy: 0.7000\n",
      "Training: batch 17 begins at 15:16:57.480208\n",
      "\n",
      "Training: batch 17 ends at 15:16:59.075037\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8790 - accuracy: 0.6927\n",
      "Evaluating: batch 0 begins at 15:16:59.085768\n",
      "\n",
      "Evaluating: batch 0 ends at 15:16:59.594919\n",
      "\n",
      "Evaluating: batch 1 begins at 15:16:59.595442\n",
      "\n",
      "Evaluating: batch 1 ends at 15:17:00.067798\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.8790 - accuracy: 0.6927 - val_loss: 1.0415 - val_accuracy: 0.6353\n",
      "Epoch 30/35\n",
      "\n",
      "Training: batch 0 begins at 15:17:00.078187\n",
      "\n",
      "Training: batch 0 ends at 15:17:01.663743\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 1.1864 - accuracy: 0.5502\n",
      "Training: batch 1 begins at 15:17:01.664887\n",
      "\n",
      "Training: batch 1 ends at 15:17:03.244894\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 1.0511 - accuracy: 0.6150\n",
      "Training: batch 2 begins at 15:17:03.245850\n",
      "\n",
      "Training: batch 2 ends at 15:17:04.823747\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9930 - accuracy: 0.6512\n",
      "Training: batch 3 begins at 15:17:04.824871\n",
      "\n",
      "Training: batch 3 ends at 15:17:06.410399\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9292 - accuracy: 0.6734\n",
      "Training: batch 4 begins at 15:17:06.411526\n",
      "\n",
      "Training: batch 4 ends at 15:17:08.002429\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.9040 - accuracy: 0.6830\n",
      "Training: batch 5 begins at 15:17:08.003419\n",
      "\n",
      "Training: batch 5 ends at 15:17:09.580534\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8888 - accuracy: 0.6784\n",
      "Training: batch 6 begins at 15:17:09.581602\n",
      "\n",
      "Training: batch 6 ends at 15:17:11.162389\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8980 - accuracy: 0.6797\n",
      "Training: batch 7 begins at 15:17:11.163797\n",
      "\n",
      "Training: batch 7 ends at 15:17:12.746218\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.9026 - accuracy: 0.6790\n",
      "Training: batch 8 begins at 15:17:12.747224\n",
      "\n",
      "Training: batch 8 ends at 15:17:14.348590\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.9051 - accuracy: 0.6779\n",
      "Training: batch 9 begins at 15:17:14.349564\n",
      "\n",
      "Training: batch 9 ends at 15:17:15.927856\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.9079 - accuracy: 0.6780\n",
      "Training: batch 10 begins at 15:17:15.928944\n",
      "\n",
      "Training: batch 10 ends at 15:17:17.521896\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.8938 - accuracy: 0.6856\n",
      "Training: batch 11 begins at 15:17:17.522853\n",
      "\n",
      "Training: batch 11 ends at 15:17:19.098235\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.9050 - accuracy: 0.6834 \n",
      "Training: batch 12 begins at 15:17:19.099382\n",
      "\n",
      "Training: batch 12 ends at 15:17:20.679359\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.9012 - accuracy: 0.6820\n",
      "Training: batch 13 begins at 15:17:20.680410\n",
      "\n",
      "Training: batch 13 ends at 15:17:22.292659\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.8907 - accuracy: 0.6868\n",
      "Training: batch 14 begins at 15:17:22.293742\n",
      "\n",
      "Training: batch 14 ends at 15:17:23.872134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/18 [========================>.....] - ETA: 4s - loss: 0.8730 - accuracy: 0.6950\n",
      "Training: batch 15 begins at 15:17:23.873211\n",
      "\n",
      "Training: batch 15 ends at 15:17:25.463633\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.8793 - accuracy: 0.6937\n",
      "Training: batch 16 begins at 15:17:25.464626\n",
      "\n",
      "Training: batch 16 ends at 15:17:27.041837\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.8749 - accuracy: 0.6970\n",
      "Training: batch 17 begins at 15:17:27.042842\n",
      "\n",
      "Training: batch 17 ends at 15:17:28.627012\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.6988\n",
      "Evaluating: batch 0 begins at 15:17:28.635434\n",
      "\n",
      "Evaluating: batch 0 ends at 15:17:29.140325\n",
      "\n",
      "Evaluating: batch 1 begins at 15:17:29.140845\n",
      "\n",
      "Evaluating: batch 1 ends at 15:17:29.618583\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.8707 - accuracy: 0.6988 - val_loss: 0.9645 - val_accuracy: 0.6684\n",
      "Epoch 31/35\n",
      "\n",
      "Training: batch 0 begins at 15:17:29.627928\n",
      "\n",
      "Training: batch 0 ends at 15:17:31.215674\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 0.9881 - accuracy: 0.6401\n",
      "Training: batch 1 begins at 15:17:31.216700\n",
      "\n",
      "Training: batch 1 ends at 15:17:32.801555\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.8719 - accuracy: 0.6935\n",
      "Training: batch 2 begins at 15:17:32.802908\n",
      "\n",
      "Training: batch 2 ends at 15:17:34.375957\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.8410 - accuracy: 0.7104\n",
      "Training: batch 3 begins at 15:17:34.376973\n",
      "\n",
      "Training: batch 3 ends at 15:17:35.977032\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.8986 - accuracy: 0.6901\n",
      "Training: batch 4 begins at 15:17:35.978012\n",
      "\n",
      "Training: batch 4 ends at 15:17:37.554271\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8832 - accuracy: 0.6866\n",
      "Training: batch 5 begins at 15:17:37.555383\n",
      "\n",
      "Training: batch 5 ends at 15:17:39.124783\n",
      " 6/18 [=========>....................] - ETA: 18s - loss: 0.8785 - accuracy: 0.6913\n",
      "Training: batch 6 begins at 15:17:39.125903\n",
      "\n",
      "Training: batch 6 ends at 15:17:40.719613\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8637 - accuracy: 0.6945\n",
      "Training: batch 7 begins at 15:17:40.720579\n",
      "\n",
      "Training: batch 7 ends at 15:17:42.303741\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.8937 - accuracy: 0.6806\n",
      "Training: batch 8 begins at 15:17:42.304814\n",
      "\n",
      "Training: batch 8 ends at 15:17:43.905813\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.8902 - accuracy: 0.6826\n",
      "Training: batch 9 begins at 15:17:43.906849\n",
      "\n",
      "Training: batch 9 ends at 15:17:45.497072\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.8700 - accuracy: 0.6935\n",
      "Training: batch 10 begins at 15:17:45.498135\n",
      "\n",
      "Training: batch 10 ends at 15:17:47.092111\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.8612 - accuracy: 0.6992\n",
      "Training: batch 11 begins at 15:17:47.093098\n",
      "\n",
      "Training: batch 11 ends at 15:17:48.684535\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.8570 - accuracy: 0.6992 \n",
      "Training: batch 12 begins at 15:17:48.685574\n",
      "\n",
      "Training: batch 12 ends at 15:17:50.268765\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.8545 - accuracy: 0.7013\n",
      "Training: batch 13 begins at 15:17:50.269760\n",
      "\n",
      "Training: batch 13 ends at 15:17:51.871914\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.8504 - accuracy: 0.7008\n",
      "Training: batch 14 begins at 15:17:51.872949\n",
      "\n",
      "Training: batch 14 ends at 15:17:53.451962\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.8651 - accuracy: 0.6953\n",
      "Training: batch 15 begins at 15:17:53.453024\n",
      "\n",
      "Training: batch 15 ends at 15:17:55.017327\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.8681 - accuracy: 0.6956\n",
      "Training: batch 16 begins at 15:17:55.018487\n",
      "\n",
      "Training: batch 16 ends at 15:17:56.601155\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.8691 - accuracy: 0.6943\n",
      "Training: batch 17 begins at 15:17:56.602159\n",
      "\n",
      "Training: batch 17 ends at 15:17:58.166301\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.7001\n",
      "Evaluating: batch 0 begins at 15:17:58.175255\n",
      "\n",
      "Evaluating: batch 0 ends at 15:17:58.677834\n",
      "\n",
      "Evaluating: batch 1 begins at 15:17:58.678355\n",
      "\n",
      "Evaluating: batch 1 ends at 15:17:59.156059\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.8564 - accuracy: 0.7001 - val_loss: 0.9937 - val_accuracy: 0.6511\n",
      "Epoch 32/35\n",
      "\n",
      "Training: batch 0 begins at 15:17:59.165757\n",
      "\n",
      "Training: batch 0 ends at 15:18:00.777210\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 0.6607 - accuracy: 0.8004\n",
      "Training: batch 1 begins at 15:18:00.778278\n",
      "\n",
      "Training: batch 1 ends at 15:18:02.354106\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9489 - accuracy: 0.6956\n",
      "Training: batch 2 begins at 15:18:02.355154\n",
      "\n",
      "Training: batch 2 ends at 15:18:03.949797\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9417 - accuracy: 0.6780\n",
      "Training: batch 3 begins at 15:18:03.950794\n",
      "\n",
      "Training: batch 3 ends at 15:18:05.528244\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.8899 - accuracy: 0.6949\n",
      "Training: batch 4 begins at 15:18:05.529372\n",
      "\n",
      "Training: batch 4 ends at 15:18:07.098282\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8696 - accuracy: 0.7030\n",
      "Training: batch 5 begins at 15:18:07.099328\n",
      "\n",
      "Training: batch 5 ends at 15:18:08.663651\n",
      " 6/18 [=========>....................] - ETA: 18s - loss: 0.8762 - accuracy: 0.6885\n",
      "Training: batch 6 begins at 15:18:08.664648\n",
      "\n",
      "Training: batch 6 ends at 15:18:10.263766\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.9103 - accuracy: 0.6836\n",
      "Training: batch 7 begins at 15:18:10.264871\n",
      "\n",
      "Training: batch 7 ends at 15:18:11.845109\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.9068 - accuracy: 0.6839\n",
      "Training: batch 8 begins at 15:18:11.846169\n",
      "\n",
      "Training: batch 8 ends at 15:18:13.432923\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.8924 - accuracy: 0.6862\n",
      "Training: batch 9 begins at 15:18:13.434060\n",
      "\n",
      "Training: batch 9 ends at 15:18:15.013715\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.8830 - accuracy: 0.6875\n",
      "Training: batch 10 begins at 15:18:15.014693\n",
      "\n",
      "Training: batch 10 ends at 15:18:16.590975\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.8732 - accuracy: 0.6911\n",
      "Training: batch 11 begins at 15:18:16.592050\n",
      "\n",
      "Training: batch 11 ends at 15:18:18.172011\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.8663 - accuracy: 0.6937 \n",
      "Training: batch 12 begins at 15:18:18.172999\n",
      "\n",
      "Training: batch 12 ends at 15:18:19.756357\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.8686 - accuracy: 0.6935\n",
      "Training: batch 13 begins at 15:18:19.757435\n",
      "\n",
      "Training: batch 13 ends at 15:18:21.333678\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.8521 - accuracy: 0.6988\n",
      "Training: batch 14 begins at 15:18:21.334800\n",
      "\n",
      "Training: batch 14 ends at 15:18:22.922458\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.8562 - accuracy: 0.6981\n",
      "Training: batch 15 begins at 15:18:22.923525\n",
      "\n",
      "Training: batch 15 ends at 15:18:24.508793\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.8643 - accuracy: 0.6963\n",
      "Training: batch 16 begins at 15:18:24.509906\n",
      "\n",
      "Training: batch 16 ends at 15:18:26.077598\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.8704 - accuracy: 0.6937\n",
      "Training: batch 17 begins at 15:18:26.078674\n",
      "\n",
      "Training: batch 17 ends at 15:18:27.646955\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8636 - accuracy: 0.6931\n",
      "Evaluating: batch 0 begins at 15:18:27.655354\n",
      "\n",
      "Evaluating: batch 0 ends at 15:18:28.165771\n",
      "\n",
      "Evaluating: batch 1 begins at 15:18:28.166308\n",
      "\n",
      "Evaluating: batch 1 ends at 15:18:28.638917\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.8636 - accuracy: 0.6931 - val_loss: 0.9528 - val_accuracy: 0.6715\n",
      "Epoch 33/35\n",
      "\n",
      "Training: batch 0 begins at 15:18:28.648440\n",
      "\n",
      "Training: batch 0 ends at 15:18:30.226836\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 0.8488 - accuracy: 0.7138\n",
      "Training: batch 1 begins at 15:18:30.228062\n",
      "\n",
      "Training: batch 1 ends at 15:18:31.811910\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.8222 - accuracy: 0.7189\n",
      "Training: batch 2 begins at 15:18:31.812950\n",
      "\n",
      "Training: batch 2 ends at 15:18:33.414464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.8817 - accuracy: 0.7026\n",
      "Training: batch 3 begins at 15:18:33.415545\n",
      "\n",
      "Training: batch 3 ends at 15:18:34.991340\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.8337 - accuracy: 0.7188\n",
      "Training: batch 4 begins at 15:18:34.992405\n",
      "\n",
      "Training: batch 4 ends at 15:18:36.574257\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8578 - accuracy: 0.7091\n",
      "Training: batch 5 begins at 15:18:36.575203\n",
      "\n",
      "Training: batch 5 ends at 15:18:38.167563\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8185 - accuracy: 0.7253\n",
      "Training: batch 6 begins at 15:18:38.169155\n",
      "\n",
      "Training: batch 6 ends at 15:18:39.763196\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8147 - accuracy: 0.7281\n",
      "Training: batch 7 begins at 15:18:39.764377\n",
      "\n",
      "Training: batch 7 ends at 15:18:41.366715\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.7952 - accuracy: 0.7372\n",
      "Training: batch 8 begins at 15:18:41.367773\n",
      "\n",
      "Training: batch 8 ends at 15:18:42.964435\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.7967 - accuracy: 0.7367\n",
      "Training: batch 9 begins at 15:18:42.965459\n",
      "\n",
      "Training: batch 9 ends at 15:18:44.527152\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.8135 - accuracy: 0.7270\n",
      "Training: batch 10 begins at 15:18:44.528301\n",
      "\n",
      "Training: batch 10 ends at 15:18:46.104694\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.8092 - accuracy: 0.7265\n",
      "Training: batch 11 begins at 15:18:46.105706\n",
      "\n",
      "Training: batch 11 ends at 15:18:47.691162\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.8394 - accuracy: 0.7140 \n",
      "Training: batch 12 begins at 15:18:47.692143\n",
      "\n",
      "Training: batch 12 ends at 15:18:49.270063\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.8382 - accuracy: 0.7125\n",
      "Training: batch 13 begins at 15:18:49.271031\n",
      "\n",
      "Training: batch 13 ends at 15:18:50.855595\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.8340 - accuracy: 0.7143\n",
      "Training: batch 14 begins at 15:18:50.856625\n",
      "\n",
      "Training: batch 14 ends at 15:18:52.440443\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.8158 - accuracy: 0.7216\n",
      "Training: batch 15 begins at 15:18:52.441626\n",
      "\n",
      "Training: batch 15 ends at 15:18:54.046445\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.8365 - accuracy: 0.7137\n",
      "Training: batch 16 begins at 15:18:54.047483\n",
      "\n",
      "Training: batch 16 ends at 15:18:55.626032\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.8230 - accuracy: 0.7183\n",
      "Training: batch 17 begins at 15:18:55.627058\n",
      "\n",
      "Training: batch 17 ends at 15:18:57.219229\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8217 - accuracy: 0.7159\n",
      "Evaluating: batch 0 begins at 15:18:57.230063\n",
      "\n",
      "Evaluating: batch 0 ends at 15:18:57.728980\n",
      "\n",
      "Evaluating: batch 1 begins at 15:18:57.729455\n",
      "\n",
      "Evaluating: batch 1 ends at 15:18:58.198824\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.8217 - accuracy: 0.7159 - val_loss: 0.9789 - val_accuracy: 0.6387\n",
      "Epoch 34/35\n",
      "\n",
      "Training: batch 0 begins at 15:18:58.208158\n",
      "\n",
      "Training: batch 0 ends at 15:18:59.819808\n",
      " 1/18 [>.............................] - ETA: 27s - loss: 0.9501 - accuracy: 0.6781\n",
      "Training: batch 1 begins at 15:18:59.820931\n",
      "\n",
      "Training: batch 1 ends at 15:19:01.406718\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.9504 - accuracy: 0.6811\n",
      "Training: batch 2 begins at 15:19:01.407761\n",
      "\n",
      "Training: batch 2 ends at 15:19:03.006569\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.9244 - accuracy: 0.6905\n",
      "Training: batch 3 begins at 15:19:03.007559\n",
      "\n",
      "Training: batch 3 ends at 15:19:04.591623\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.9125 - accuracy: 0.6727\n",
      "Training: batch 4 begins at 15:19:04.592651\n",
      "\n",
      "Training: batch 4 ends at 15:19:06.180995\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.8768 - accuracy: 0.6864\n",
      "Training: batch 5 begins at 15:19:06.181965\n",
      "\n",
      "Training: batch 5 ends at 15:19:07.756311\n",
      " 6/18 [=========>....................] - ETA: 19s - loss: 0.8486 - accuracy: 0.7048\n",
      "Training: batch 6 begins at 15:19:07.757412\n",
      "\n",
      "Training: batch 6 ends at 15:19:09.339196\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.8380 - accuracy: 0.7096\n",
      "Training: batch 7 begins at 15:19:09.340215\n",
      "\n",
      "Training: batch 7 ends at 15:19:10.933929\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.8168 - accuracy: 0.7199\n",
      "Training: batch 8 begins at 15:19:10.935765\n",
      "\n",
      "Training: batch 8 ends at 15:19:12.522848\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.8039 - accuracy: 0.7229\n",
      "Training: batch 9 begins at 15:19:12.524054\n",
      "\n",
      "Training: batch 9 ends at 15:19:14.122455\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.8150 - accuracy: 0.7171\n",
      "Training: batch 10 begins at 15:19:14.123505\n",
      "\n",
      "Training: batch 10 ends at 15:19:15.734259\n",
      "11/18 [=================>............] - ETA: 11s - loss: 0.8291 - accuracy: 0.7118\n",
      "Training: batch 11 begins at 15:19:15.735261\n",
      "\n",
      "Training: batch 11 ends at 15:19:17.307565\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.8319 - accuracy: 0.7067 \n",
      "Training: batch 12 begins at 15:19:17.308557\n",
      "\n",
      "Training: batch 12 ends at 15:19:18.919909\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.8177 - accuracy: 0.7112\n",
      "Training: batch 13 begins at 15:19:18.920987\n",
      "\n",
      "Training: batch 13 ends at 15:19:20.496340\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.8051 - accuracy: 0.7170\n",
      "Training: batch 14 begins at 15:19:20.497363\n",
      "\n",
      "Training: batch 14 ends at 15:19:22.082895\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.8146 - accuracy: 0.7141\n",
      "Training: batch 15 begins at 15:19:22.084005\n",
      "\n",
      "Training: batch 15 ends at 15:19:23.663180\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.8112 - accuracy: 0.7144\n",
      "Training: batch 16 begins at 15:19:23.664255\n",
      "\n",
      "Training: batch 16 ends at 15:19:25.249583\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.8108 - accuracy: 0.7173\n",
      "Training: batch 17 begins at 15:19:25.250608\n",
      "\n",
      "Training: batch 17 ends at 15:19:26.841011\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8092 - accuracy: 0.7190\n",
      "Evaluating: batch 0 begins at 15:19:26.849552\n",
      "\n",
      "Evaluating: batch 0 ends at 15:19:27.355051\n",
      "\n",
      "Evaluating: batch 1 begins at 15:19:27.355569\n",
      "\n",
      "Evaluating: batch 1 ends at 15:19:27.828161\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.8092 - accuracy: 0.7190 - val_loss: 0.9983 - val_accuracy: 0.6412\n",
      "Epoch 35/35\n",
      "\n",
      "Training: batch 0 begins at 15:19:27.837637\n",
      "\n",
      "Training: batch 0 ends at 15:19:29.422629\n",
      " 1/18 [>.............................] - ETA: 26s - loss: 0.6002 - accuracy: 0.8006\n",
      "Training: batch 1 begins at 15:19:29.423706\n",
      "\n",
      "Training: batch 1 ends at 15:19:31.006904\n",
      " 2/18 [==>...........................] - ETA: 25s - loss: 0.6759 - accuracy: 0.7736\n",
      "Training: batch 2 begins at 15:19:31.008430\n",
      "\n",
      "Training: batch 2 ends at 15:19:32.594723\n",
      " 3/18 [====>.........................] - ETA: 23s - loss: 0.7382 - accuracy: 0.7472\n",
      "Training: batch 3 begins at 15:19:32.595771\n",
      "\n",
      "Training: batch 3 ends at 15:19:34.177277\n",
      " 4/18 [=====>........................] - ETA: 22s - loss: 0.7429 - accuracy: 0.7449\n",
      "Training: batch 4 begins at 15:19:34.178299\n",
      "\n",
      "Training: batch 4 ends at 15:19:35.763458\n",
      " 5/18 [=======>......................] - ETA: 20s - loss: 0.7135 - accuracy: 0.7578\n",
      "Training: batch 5 begins at 15:19:35.764447\n",
      "\n",
      "Training: batch 5 ends at 15:19:37.339246\n",
      " 6/18 [=========>....................] - ETA: 18s - loss: 0.7612 - accuracy: 0.7427\n",
      "Training: batch 6 begins at 15:19:37.340300\n",
      "\n",
      "Training: batch 6 ends at 15:19:38.943552\n",
      " 7/18 [==========>...................] - ETA: 17s - loss: 0.7833 - accuracy: 0.7372\n",
      "Training: batch 7 begins at 15:19:38.944578\n",
      "\n",
      "Training: batch 7 ends at 15:19:40.535609\n",
      " 8/18 [============>.................] - ETA: 15s - loss: 0.7574 - accuracy: 0.7478\n",
      "Training: batch 8 begins at 15:19:40.536670\n",
      "\n",
      "Training: batch 8 ends at 15:19:42.127092\n",
      " 9/18 [==============>...............] - ETA: 14s - loss: 0.7701 - accuracy: 0.7441\n",
      "Training: batch 9 begins at 15:19:42.129042\n",
      "\n",
      "Training: batch 9 ends at 15:19:43.738298\n",
      "10/18 [===============>..............] - ETA: 12s - loss: 0.7512 - accuracy: 0.7509\n",
      "Training: batch 10 begins at 15:19:43.739371\n",
      "\n",
      "Training: batch 10 ends at 15:19:45.320135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 [=================>............] - ETA: 11s - loss: 0.7556 - accuracy: 0.7477\n",
      "Training: batch 11 begins at 15:19:45.321269\n",
      "\n",
      "Training: batch 11 ends at 15:19:46.906565\n",
      "12/18 [===================>..........] - ETA: 9s - loss: 0.7542 - accuracy: 0.7471 \n",
      "Training: batch 12 begins at 15:19:46.907616\n",
      "\n",
      "Training: batch 12 ends at 15:19:48.491664\n",
      "13/18 [====================>.........] - ETA: 7s - loss: 0.7678 - accuracy: 0.7424\n",
      "Training: batch 13 begins at 15:19:48.492704\n",
      "\n",
      "Training: batch 13 ends at 15:19:50.065457\n",
      "14/18 [======================>.......] - ETA: 6s - loss: 0.7677 - accuracy: 0.7418\n",
      "Training: batch 14 begins at 15:19:50.066566\n",
      "\n",
      "Training: batch 14 ends at 15:19:51.641018\n",
      "15/18 [========================>.....] - ETA: 4s - loss: 0.7626 - accuracy: 0.7425\n",
      "Training: batch 15 begins at 15:19:51.642077\n",
      "\n",
      "Training: batch 15 ends at 15:19:53.220163\n",
      "16/18 [=========================>....] - ETA: 3s - loss: 0.7761 - accuracy: 0.7349\n",
      "Training: batch 16 begins at 15:19:53.221189\n",
      "\n",
      "Training: batch 16 ends at 15:19:54.799336\n",
      "17/18 [===========================>..] - ETA: 1s - loss: 0.7847 - accuracy: 0.7322\n",
      "Training: batch 17 begins at 15:19:54.800390\n",
      "\n",
      "Training: batch 17 ends at 15:19:56.404448\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.7829 - accuracy: 0.7338\n",
      "Evaluating: batch 0 begins at 15:19:56.412835\n",
      "\n",
      "Evaluating: batch 0 ends at 15:19:56.945686\n",
      "\n",
      "Evaluating: batch 1 begins at 15:19:56.946165\n",
      "\n",
      "Evaluating: batch 1 ends at 15:19:57.417712\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.7829 - accuracy: 0.7338 - val_loss: 1.0627 - val_accuracy: 0.5904\n",
      "Saving the model\n",
      "INFO:tensorflow:Assets written to: saved_models/training_15/assets\n",
      "Saved the model at saved_models/training_15/\n",
      " EPACHS set to  5\n",
      "UNet model loaded from  saved_models/training_15/\n",
      "Reading train data\n",
      "x train ----  51\n",
      "x val ----  10\n",
      "Train and Validation data created\n",
      "Epoch 1/5\n",
      "\n",
      "Training: batch 0 begins at 15:20:10.705664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 15:20:10.994092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: batch 0 ends at 15:20:12.828095\n",
      " 1/11 [=>............................] - ETA: 21s - loss: 1.0417 - accuracy: 0.6380\n",
      "Training: batch 1 begins at 15:20:12.866667\n",
      "\n",
      "Training: batch 1 ends at 15:20:14.433311\n",
      " 2/11 [====>.........................] - ETA: 14s - loss: 1.3555 - accuracy: 0.5859\n",
      "Training: batch 2 begins at 15:20:14.434362\n",
      "\n",
      "Training: batch 2 ends at 15:20:15.984623\n",
      " 3/11 [=======>......................] - ETA: 12s - loss: 1.3648 - accuracy: 0.5791\n",
      "Training: batch 3 begins at 15:20:15.985648\n",
      "\n",
      "Training: batch 3 ends at 15:20:17.570856\n",
      " 4/11 [=========>....................] - ETA: 10s - loss: 1.1899 - accuracy: 0.6356\n",
      "Training: batch 4 begins at 15:20:17.571934\n",
      "\n",
      "Training: batch 4 ends at 15:20:19.142848\n",
      " 5/11 [============>.................] - ETA: 9s - loss: 1.2117 - accuracy: 0.6261 \n",
      "Training: batch 5 begins at 15:20:19.143889\n",
      "\n",
      "Training: batch 5 ends at 15:20:20.715341\n",
      " 6/11 [===============>..............] - ETA: 7s - loss: 1.2349 - accuracy: 0.6218\n",
      "Training: batch 6 begins at 15:20:20.716316\n",
      "\n",
      "Training: batch 6 ends at 15:20:22.270935\n",
      " 7/11 [==================>...........] - ETA: 6s - loss: 1.2352 - accuracy: 0.6219\n",
      "Training: batch 7 begins at 15:20:22.271963\n",
      "\n",
      "Training: batch 7 ends at 15:20:23.835696\n",
      " 8/11 [====================>.........] - ETA: 4s - loss: 1.2191 - accuracy: 0.6259\n",
      "Training: batch 8 begins at 15:20:23.836773\n",
      "\n",
      "Training: batch 8 ends at 15:20:25.404075\n",
      " 9/11 [=======================>......] - ETA: 3s - loss: 1.1945 - accuracy: 0.6287\n",
      "Training: batch 9 begins at 15:20:25.405038\n",
      "\n",
      "Training: batch 9 ends at 15:20:26.976304\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 1.1817 - accuracy: 0.6337\n",
      "Training: batch 10 begins at 15:20:26.977340\n",
      "\n",
      "Training: batch 10 ends at 15:20:27.425447\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1814 - accuracy: 0.6330\n",
      "Evaluating: batch 0 begins at 15:20:27.598266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 15:20:27.652579: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: batch 0 ends at 15:20:28.235474\n",
      "\n",
      "Evaluating: batch 1 begins at 15:20:28.235993\n",
      "\n",
      "Evaluating: batch 1 ends at 15:20:28.711913\n",
      "11/11 [==============================] - 18s 2s/step - loss: 1.1814 - accuracy: 0.6330 - val_loss: 1.3048 - val_accuracy: 0.6254\n",
      "Epoch 2/5\n",
      "\n",
      "Training: batch 0 begins at 15:20:28.721613\n",
      "\n",
      "Training: batch 0 ends at 15:20:30.271817\n",
      " 1/11 [=>............................] - ETA: 15s - loss: 0.8215 - accuracy: 0.7331\n",
      "Training: batch 1 begins at 15:20:30.272793\n",
      "\n",
      "Training: batch 1 ends at 15:20:31.876985\n",
      " 2/11 [====>.........................] - ETA: 14s - loss: 1.0080 - accuracy: 0.6858\n",
      "Training: batch 2 begins at 15:20:31.878076\n",
      "\n",
      "Training: batch 2 ends at 15:20:33.445174\n",
      " 3/11 [=======>......................] - ETA: 12s - loss: 1.0659 - accuracy: 0.6772\n",
      "Training: batch 3 begins at 15:20:33.446181\n",
      "\n",
      "Training: batch 3 ends at 15:20:35.019762\n",
      " 4/11 [=========>....................] - ETA: 11s - loss: 1.0891 - accuracy: 0.6627\n",
      "Training: batch 4 begins at 15:20:35.020831\n",
      "\n",
      "Training: batch 4 ends at 15:20:36.583689\n",
      " 5/11 [============>.................] - ETA: 9s - loss: 1.1772 - accuracy: 0.6415 \n",
      "Training: batch 5 begins at 15:20:36.584703\n",
      "\n",
      "Training: batch 5 ends at 15:20:38.150474\n",
      " 6/11 [===============>..............] - ETA: 7s - loss: 1.1656 - accuracy: 0.6406\n",
      "Training: batch 6 begins at 15:20:38.151472\n",
      "\n",
      "Training: batch 6 ends at 15:20:39.718852\n",
      " 7/11 [==================>...........] - ETA: 6s - loss: 1.1564 - accuracy: 0.6404\n",
      "Training: batch 7 begins at 15:20:39.719918\n",
      "\n",
      "Training: batch 7 ends at 15:20:41.303432\n",
      " 8/11 [====================>.........] - ETA: 4s - loss: 1.1290 - accuracy: 0.6478\n",
      "Training: batch 8 begins at 15:20:41.304397\n",
      "\n",
      "Training: batch 8 ends at 15:20:42.859048\n",
      " 9/11 [=======================>......] - ETA: 3s - loss: 1.1025 - accuracy: 0.6485\n",
      "Training: batch 9 begins at 15:20:42.860087\n",
      "\n",
      "Training: batch 9 ends at 15:20:44.427412\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 1.1301 - accuracy: 0.6440\n",
      "Training: batch 10 begins at 15:20:44.428428\n",
      "\n",
      "Training: batch 10 ends at 15:20:44.812734\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1389 - accuracy: 0.6437\n",
      "Evaluating: batch 0 begins at 15:20:44.821569\n",
      "\n",
      "Evaluating: batch 0 ends at 15:20:45.346614\n",
      "\n",
      "Evaluating: batch 1 begins at 15:20:45.347102\n",
      "\n",
      "Evaluating: batch 1 ends at 15:20:45.818006\n",
      "11/11 [==============================] - 17s 2s/step - loss: 1.1389 - accuracy: 0.6437 - val_loss: 1.0853 - val_accuracy: 0.6891\n",
      "Epoch 3/5\n",
      "\n",
      "Training: batch 0 begins at 15:20:45.827471\n",
      "\n",
      "Training: batch 0 ends at 15:20:47.408094\n",
      " 1/11 [=>............................] - ETA: 15s - loss: 0.7803 - accuracy: 0.7835\n",
      "Training: batch 1 begins at 15:20:47.409142\n",
      "\n",
      "Training: batch 1 ends at 15:20:48.976484\n",
      " 2/11 [====>.........................] - ETA: 14s - loss: 0.8988 - accuracy: 0.7076\n",
      "Training: batch 2 begins at 15:20:48.977447\n",
      "\n",
      "Training: batch 2 ends at 15:20:50.528427\n",
      " 3/11 [=======>......................] - ETA: 12s - loss: 0.8493 - accuracy: 0.7171\n",
      "Training: batch 3 begins at 15:20:50.529431\n",
      "\n",
      "Training: batch 3 ends at 15:20:52.120223\n",
      " 4/11 [=========>....................] - ETA: 10s - loss: 0.9000 - accuracy: 0.7055\n",
      "Training: batch 4 begins at 15:20:52.121267\n",
      "\n",
      "Training: batch 4 ends at 15:20:53.708836\n",
      " 5/11 [============>.................] - ETA: 9s - loss: 0.9387 - accuracy: 0.6946 \n",
      "Training: batch 5 begins at 15:20:53.709861\n",
      "\n",
      "Training: batch 5 ends at 15:20:55.287127\n",
      " 6/11 [===============>..............] - ETA: 7s - loss: 0.9204 - accuracy: 0.6996\n",
      "Training: batch 6 begins at 15:20:55.288124\n",
      "\n",
      "Training: batch 6 ends at 15:20:56.865459\n",
      " 7/11 [==================>...........] - ETA: 6s - loss: 0.9223 - accuracy: 0.6952\n",
      "Training: batch 7 begins at 15:20:56.866539\n",
      "\n",
      "Training: batch 7 ends at 15:20:58.420767\n",
      " 8/11 [====================>.........] - ETA: 4s - loss: 0.9228 - accuracy: 0.6907\n",
      "Training: batch 8 begins at 15:20:58.422018\n",
      "\n",
      "Training: batch 8 ends at 15:20:59.972103\n",
      " 9/11 [=======================>......] - ETA: 3s - loss: 0.8991 - accuracy: 0.7000\n",
      "Training: batch 9 begins at 15:20:59.973142\n",
      "\n",
      "Training: batch 9 ends at 15:21:01.543440\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 0.9492 - accuracy: 0.6834\n",
      "Training: batch 10 begins at 15:21:01.544543\n",
      "\n",
      "Training: batch 10 ends at 15:21:01.964993\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9453 - accuracy: 0.6851\n",
      "Evaluating: batch 0 begins at 15:21:01.973667\n",
      "\n",
      "Evaluating: batch 0 ends at 15:21:02.509685\n",
      "\n",
      "Evaluating: batch 1 begins at 15:21:02.510189\n",
      "\n",
      "Evaluating: batch 1 ends at 15:21:02.990153\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.9453 - accuracy: 0.6851 - val_loss: 1.0451 - val_accuracy: 0.6767\n",
      "Epoch 4/5\n",
      "\n",
      "Training: batch 0 begins at 15:21:02.999714\n",
      "\n",
      "Training: batch 0 ends at 15:21:04.569735\n",
      " 1/11 [=>............................] - ETA: 15s - loss: 1.1541 - accuracy: 0.6042\n",
      "Training: batch 1 begins at 15:21:04.571049\n",
      "\n",
      "Training: batch 1 ends at 15:21:06.144321\n",
      " 2/11 [====>.........................] - ETA: 14s - loss: 1.0722 - accuracy: 0.6410\n",
      "Training: batch 2 begins at 15:21:06.145507\n",
      "\n",
      "Training: batch 2 ends at 15:21:07.693376\n",
      " 3/11 [=======>......................] - ETA: 12s - loss: 1.0237 - accuracy: 0.6388\n",
      "Training: batch 3 begins at 15:21:07.694507\n",
      "\n",
      "Training: batch 3 ends at 15:21:09.254672\n",
      " 4/11 [=========>....................] - ETA: 10s - loss: 0.9725 - accuracy: 0.6670\n",
      "Training: batch 4 begins at 15:21:09.255728\n",
      "\n",
      "Training: batch 4 ends at 15:21:10.797755\n",
      " 5/11 [============>.................] - ETA: 9s - loss: 0.9237 - accuracy: 0.6853 \n",
      "Training: batch 5 begins at 15:21:10.798746\n",
      "\n",
      "Training: batch 5 ends at 15:21:12.381664\n",
      " 6/11 [===============>..............] - ETA: 7s - loss: 0.9372 - accuracy: 0.6860\n",
      "Training: batch 6 begins at 15:21:12.385363\n",
      "\n",
      "Training: batch 6 ends at 15:21:13.957573\n",
      " 7/11 [==================>...........] - ETA: 6s - loss: 0.9250 - accuracy: 0.6934\n",
      "Training: batch 7 begins at 15:21:13.958525\n",
      "\n",
      "Training: batch 7 ends at 15:21:15.519772\n",
      " 8/11 [====================>.........] - ETA: 4s - loss: 0.9109 - accuracy: 0.6980\n",
      "Training: batch 8 begins at 15:21:15.520733\n",
      "\n",
      "Training: batch 8 ends at 15:21:17.089168\n",
      " 9/11 [=======================>......] - ETA: 3s - loss: 0.8968 - accuracy: 0.7021\n",
      "Training: batch 9 begins at 15:21:17.090348\n",
      "\n",
      "Training: batch 9 ends at 15:21:18.672520\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 0.8752 - accuracy: 0.7119\n",
      "Training: batch 10 begins at 15:21:18.673525\n",
      "\n",
      "Training: batch 10 ends at 15:21:19.054361\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8875 - accuracy: 0.7079\n",
      "Evaluating: batch 0 begins at 15:21:19.063592\n",
      "\n",
      "Evaluating: batch 0 ends at 15:21:19.603760\n",
      "\n",
      "Evaluating: batch 1 begins at 15:21:19.604243\n",
      "\n",
      "Evaluating: batch 1 ends at 15:21:20.074353\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.8875 - accuracy: 0.7079 - val_loss: 1.0606 - val_accuracy: 0.6984\n",
      "Epoch 5/5\n",
      "\n",
      "Training: batch 0 begins at 15:21:20.084069\n",
      "\n",
      "Training: batch 0 ends at 15:21:21.637460\n",
      " 1/11 [=>............................] - ETA: 15s - loss: 0.6163 - accuracy: 0.8055\n",
      "Training: batch 1 begins at 15:21:21.638485\n",
      "\n",
      "Training: batch 1 ends at 15:21:23.214177\n",
      " 2/11 [====>.........................] - ETA: 14s - loss: 0.6971 - accuracy: 0.7722\n",
      "Training: batch 2 begins at 15:21:23.215239\n",
      "\n",
      "Training: batch 2 ends at 15:21:24.790772\n",
      " 3/11 [=======>......................] - ETA: 12s - loss: 0.8085 - accuracy: 0.7264\n",
      "Training: batch 3 begins at 15:21:24.791743\n",
      "\n",
      "Training: batch 3 ends at 15:21:26.350691\n",
      " 4/11 [=========>....................] - ETA: 10s - loss: 0.7700 - accuracy: 0.7417\n",
      "Training: batch 4 begins at 15:21:26.351730\n",
      "\n",
      "Training: batch 4 ends at 15:21:27.906212\n",
      " 5/11 [============>.................] - ETA: 9s - loss: 0.8279 - accuracy: 0.7268 \n",
      "Training: batch 5 begins at 15:21:27.907242\n",
      "\n",
      "Training: batch 5 ends at 15:21:29.465649\n",
      " 6/11 [===============>..............] - ETA: 7s - loss: 0.8827 - accuracy: 0.7060\n",
      "Training: batch 6 begins at 15:21:29.466806\n",
      "\n",
      "Training: batch 6 ends at 15:21:31.016385\n",
      " 7/11 [==================>...........] - ETA: 6s - loss: 0.8712 - accuracy: 0.7107\n",
      "Training: batch 7 begins at 15:21:31.017323\n",
      "\n",
      "Training: batch 7 ends at 15:21:32.573699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/11 [====================>.........] - ETA: 4s - loss: 0.8805 - accuracy: 0.7095\n",
      "Training: batch 8 begins at 15:21:32.575260\n",
      "\n",
      "Training: batch 8 ends at 15:21:34.136400\n",
      " 9/11 [=======================>......] - ETA: 3s - loss: 0.8718 - accuracy: 0.7118\n",
      "Training: batch 9 begins at 15:21:34.137387\n",
      "\n",
      "Training: batch 9 ends at 15:21:35.703474\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 0.8633 - accuracy: 0.7133\n",
      "Training: batch 10 begins at 15:21:35.704761\n",
      "\n",
      "Training: batch 10 ends at 15:21:36.085985\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8612 - accuracy: 0.7145\n",
      "Evaluating: batch 0 begins at 15:21:36.094214\n",
      "\n",
      "Evaluating: batch 0 ends at 15:21:36.593705\n",
      "\n",
      "Evaluating: batch 1 begins at 15:21:36.594234\n",
      "\n",
      "Evaluating: batch 1 ends at 15:21:37.064897\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.8612 - accuracy: 0.7145 - val_loss: 0.9888 - val_accuracy: 0.7048\n",
      "Saving the model\n",
      "INFO:tensorflow:Assets written to: saved_models/training_15/assets\n",
      "Saved the model at saved_models/training_15/\n"
     ]
    }
   ],
   "source": [
    "# Training configs\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "CURRENT_SAVE_LOC = \"saved_models/training_15/\"\n",
    "\n",
    "model = None\n",
    "\n",
    "for img_names in img_names_batches:\n",
    "    \n",
    "    if len(img_names) > 90:\n",
    "        EPOCHS = 35\n",
    "        print(\" EPOCHS set to \", EPOCHS)\n",
    "    elif len(img_names) < 70:\n",
    "        EPOCHS = 5\n",
    "        print(\" EPOCHS set to \", EPOCHS)\n",
    "    else:\n",
    "        EPOCHS = 20\n",
    "        print(\" EPOCHS set to \", EPOCHS)\n",
    "    \n",
    "    # Setting the model\n",
    "    if model is None:\n",
    "        print(\"No model set. Creating new model.\")\n",
    "        model = get_unet()\n",
    "        model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), \n",
    "              metrics=['accuracy'])\n",
    "        INITIAL_TRAIN = False\n",
    "        print(\"UNet model created from scratch\")\n",
    "    else:\n",
    "        model = tf.keras.models.load_model(CURRENT_SAVE_LOC)\n",
    "        print(\"UNet model loaded from \", CURRENT_SAVE_LOC)\n",
    "        \n",
    "    if model is None:\n",
    "            print(\"!!! MODEL NOT SET !!!\")\n",
    "            break\n",
    "              \n",
    "    # Preparing the data\n",
    "    x = []\n",
    "    y = []\n",
    "    print(\"Reading train data\")\n",
    "    for i in img_names:\n",
    "        x.append(np.array(PIL.Image.open(train_x_loc + i + \".jpg\").resize((INPUT_SIZE,INPUT_SIZE),resample=PIL.Image.NEAREST))/255)\n",
    "        y.append(to_categorical(np.array(PIL.Image.open(train_y_loc + i + \".png\").resize((INPUT_SIZE,INPUT_SIZE),resample=PIL.Image.NEAREST)), N_CLASSES))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    # Reserve 20 samples for validation\n",
    "    x_train = x[:-10]\n",
    "    y_train = y[:-10]\n",
    "    print(\"x train ---- \", len(x_train))\n",
    "    x_val = x[-10:]\n",
    "    print(\"x val ---- \", len(x_val))\n",
    "    y_val = y[-10:]\n",
    "    del x,y\n",
    "    print(\"Train and Validation data created\")\n",
    "    \n",
    "\n",
    "    # Training the model\n",
    "    model.fit(x_train, y_train, batch_size=5, epochs=EPOCHS, validation_data=(x_val, y_val), shuffle=True, callbacks=[MyCustomCallback(),tensorboard])\n",
    "    del x_train,y_train,x_val,y_val\n",
    "    \n",
    "    # Saving the model\n",
    "    print(\"Saving the model\")\n",
    "    model.save(CURRENT_SAVE_LOC)\n",
    "#     model.save(CURRENT_SAVE_LOC,save_format='h5')\n",
    "    print(\"Saved the model at\", CURRENT_SAVE_LOC)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training_11 is the best train acc as of now but kaggle acc - 0.60\n",
    "training_13 is the best kaggle acc with 0.62\n",
    "training_12 - 261 - sftm kaggle acc was still 0.60\n",
    "training_15 - reduced epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x28575d4f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data\n",
    "\n",
    "Setting the path to test images. `test_y_loc` is the location where the predicted outputs should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_loc = \"../data/test_images/\"\n",
    "test_y_loc = \"../data/test_preds/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the names of the test images and sort them and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_names = sorted([s[:-4] for s in os.listdir(test_x_loc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images =  112\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test images = \", len(test_img_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `USE_CURRENT_MODEL` is False, then provide the location of the saved model you want to use in `SAVED_MODEL_LOC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CURRENT_MODEL = False\n",
    "SAVED_MODEL_LOC = CURRENT_SAVE_LOC # \"saved_models/training_11/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from  saved_models/training_15/\n"
     ]
    }
   ],
   "source": [
    "if not USE_CURRENT_MODEL:\n",
    "    model = tf.keras.models.load_model(SAVED_MODEL_LOC)\n",
    "    print(\"Model loaded from \", SAVED_MODEL_LOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the output and save the mask as .png file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for 112 images\n",
      "Predicting for img 10170\n",
      "1/1 [==============================] - 0s 212ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 15:42:36.627335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for img 10171\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 10184\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicting for img 10566\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicting for img 10808\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 10812\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6413\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6424\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6427\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6450\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6455\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6457\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6459\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6462\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6463\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6465\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6466\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6476\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6481\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6492\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6499\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6504\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6546\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6550\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6560\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6569\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6574\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6608\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6644\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6648\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicting for img 6654\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6656\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6657\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6662\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6677\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6701\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6710\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6717\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6795\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6804\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6854\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6856\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6901\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6908\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6933\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6963\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 6974\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6982\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6994\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 6996\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7009\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7193\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7235\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7236\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7241\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7251\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7257\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7263\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7265\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7270\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7272\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7300\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7304\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicting for img 7308\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7311\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7323\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7330\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7356\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7366\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7412\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7415\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7422\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7427\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7429\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7438\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7457\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7466\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7481\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7485\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicting for img 7489\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7521\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7541\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7556\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7560\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7580\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7582\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7586\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7593\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7597\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 7673\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7719\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7721\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 7829\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 8361\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 8516\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 8526\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 8774\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 8786\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicting for img 8833\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 8906\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 8947\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 8962\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 9006\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 9070\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 9079\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 9084\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 9087\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicting for img 9101\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 9106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 9110\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 9723\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicting for img 9795\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Creating masks for 112 predictions\n",
      "Image saved:  ../data/test_preds/10170.png\n",
      "Image saved:  ../data/test_preds/10171.png\n",
      "Image saved:  ../data/test_preds/10184.png\n",
      "Image saved:  ../data/test_preds/10566.png\n",
      "Image saved:  ../data/test_preds/10808.png\n",
      "Image saved:  ../data/test_preds/10812.png\n",
      "Image saved:  ../data/test_preds/6413.png\n",
      "Image saved:  ../data/test_preds/6424.png\n",
      "Image saved:  ../data/test_preds/6427.png\n",
      "Image saved:  ../data/test_preds/6450.png\n",
      "Image saved:  ../data/test_preds/6455.png\n",
      "Image saved:  ../data/test_preds/6457.png\n",
      "Image saved:  ../data/test_preds/6459.png\n",
      "Image saved:  ../data/test_preds/6462.png\n",
      "Image saved:  ../data/test_preds/6463.png\n",
      "Image saved:  ../data/test_preds/6465.png\n",
      "Image saved:  ../data/test_preds/6466.png\n",
      "Image saved:  ../data/test_preds/6476.png\n",
      "Image saved:  ../data/test_preds/6481.png\n",
      "Image saved:  ../data/test_preds/6492.png\n",
      "Image saved:  ../data/test_preds/6499.png\n",
      "Image saved:  ../data/test_preds/6504.png\n",
      "Image saved:  ../data/test_preds/6546.png\n",
      "Image saved:  ../data/test_preds/6550.png\n",
      "Image saved:  ../data/test_preds/6560.png\n",
      "Image saved:  ../data/test_preds/6569.png\n",
      "Image saved:  ../data/test_preds/6574.png\n",
      "Image saved:  ../data/test_preds/6608.png\n",
      "Image saved:  ../data/test_preds/6644.png\n",
      "Image saved:  ../data/test_preds/6648.png\n",
      "Image saved:  ../data/test_preds/6654.png\n",
      "Image saved:  ../data/test_preds/6656.png\n",
      "Image saved:  ../data/test_preds/6657.png\n",
      "Image saved:  ../data/test_preds/6662.png\n",
      "Image saved:  ../data/test_preds/6677.png\n",
      "Image saved:  ../data/test_preds/6701.png\n",
      "Image saved:  ../data/test_preds/6710.png\n",
      "Image saved:  ../data/test_preds/6717.png\n",
      "Image saved:  ../data/test_preds/6795.png\n",
      "Image saved:  ../data/test_preds/6804.png\n",
      "Image saved:  ../data/test_preds/6854.png\n",
      "Image saved:  ../data/test_preds/6856.png\n",
      "Image saved:  ../data/test_preds/6901.png\n",
      "Image saved:  ../data/test_preds/6908.png\n",
      "Image saved:  ../data/test_preds/6933.png\n",
      "Image saved:  ../data/test_preds/6963.png\n",
      "Image saved:  ../data/test_preds/6974.png\n",
      "Image saved:  ../data/test_preds/6982.png\n",
      "Image saved:  ../data/test_preds/6994.png\n",
      "Image saved:  ../data/test_preds/6996.png\n",
      "Image saved:  ../data/test_preds/7009.png\n",
      "Image saved:  ../data/test_preds/7193.png\n",
      "Image saved:  ../data/test_preds/7235.png\n",
      "Image saved:  ../data/test_preds/7236.png\n",
      "Image saved:  ../data/test_preds/7241.png\n",
      "Image saved:  ../data/test_preds/7251.png\n",
      "Image saved:  ../data/test_preds/7257.png\n",
      "Image saved:  ../data/test_preds/7263.png\n",
      "Image saved:  ../data/test_preds/7265.png\n",
      "Image saved:  ../data/test_preds/7270.png\n",
      "Image saved:  ../data/test_preds/7272.png\n",
      "Image saved:  ../data/test_preds/7300.png\n",
      "Image saved:  ../data/test_preds/7304.png\n",
      "Image saved:  ../data/test_preds/7308.png\n",
      "Image saved:  ../data/test_preds/7311.png\n",
      "Image saved:  ../data/test_preds/7323.png\n",
      "Image saved:  ../data/test_preds/7330.png\n",
      "Image saved:  ../data/test_preds/7356.png\n",
      "Image saved:  ../data/test_preds/7366.png\n",
      "Image saved:  ../data/test_preds/7412.png\n",
      "Image saved:  ../data/test_preds/7415.png\n",
      "Image saved:  ../data/test_preds/7422.png\n",
      "Image saved:  ../data/test_preds/7427.png\n",
      "Image saved:  ../data/test_preds/7429.png\n",
      "Image saved:  ../data/test_preds/7438.png\n",
      "Image saved:  ../data/test_preds/7457.png\n",
      "Image saved:  ../data/test_preds/7466.png\n",
      "Image saved:  ../data/test_preds/7481.png\n",
      "Image saved:  ../data/test_preds/7485.png\n",
      "Image saved:  ../data/test_preds/7489.png\n",
      "Image saved:  ../data/test_preds/7521.png\n",
      "Image saved:  ../data/test_preds/7541.png\n",
      "Image saved:  ../data/test_preds/7556.png\n",
      "Image saved:  ../data/test_preds/7560.png\n",
      "Image saved:  ../data/test_preds/7580.png\n",
      "Image saved:  ../data/test_preds/7582.png\n",
      "Image saved:  ../data/test_preds/7586.png\n",
      "Image saved:  ../data/test_preds/7593.png\n",
      "Image saved:  ../data/test_preds/7597.png\n",
      "Image saved:  ../data/test_preds/7673.png\n",
      "Image saved:  ../data/test_preds/7719.png\n",
      "Image saved:  ../data/test_preds/7721.png\n",
      "Image saved:  ../data/test_preds/7829.png\n",
      "Image saved:  ../data/test_preds/8361.png\n",
      "Image saved:  ../data/test_preds/8516.png\n",
      "Image saved:  ../data/test_preds/8526.png\n",
      "Image saved:  ../data/test_preds/8774.png\n",
      "Image saved:  ../data/test_preds/8786.png\n",
      "Image saved:  ../data/test_preds/8833.png\n",
      "Image saved:  ../data/test_preds/8906.png\n",
      "Image saved:  ../data/test_preds/8947.png\n",
      "Image saved:  ../data/test_preds/8962.png\n",
      "Image saved:  ../data/test_preds/9006.png\n",
      "Image saved:  ../data/test_preds/9070.png\n",
      "Image saved:  ../data/test_preds/9079.png\n",
      "Image saved:  ../data/test_preds/9084.png\n",
      "Image saved:  ../data/test_preds/9087.png\n",
      "Image saved:  ../data/test_preds/9101.png\n",
      "Image saved:  ../data/test_preds/9106.png\n",
      "Image saved:  ../data/test_preds/9110.png\n",
      "Image saved:  ../data/test_preds/9723.png\n",
      "Image saved:  ../data/test_preds/9795.png\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(image_loc, test_img_names):\n",
    "    y_test = {}\n",
    "    print(\"Predicting for {} images\".format(len(test_img_names)))\n",
    "    for i in test_img_names:\n",
    "        print(\"Predicting for img\",i)\n",
    "        x_test = np.array(PIL.Image.open(image_loc + i + \".jpg\").resize((INPUT_SIZE,INPUT_SIZE),resample=PIL.Image.NEAREST))/255 #\n",
    "        x_test = x_test.reshape((1,512,512,3))\n",
    "        y_test[i] = model.predict(x_test, verbose=1)\n",
    "        del x_test\n",
    "    return y_test\n",
    "\n",
    "def create_mask(image_dict):\n",
    "    y_test_mask = {}\n",
    "    print(\"Creating masks for {} predictions\".format(len(image_dict)))\n",
    "    for name, img in image_dict.items():\n",
    "        pred_mask = tf.argmax(img, axis=3)\n",
    "        pred_mask= np.uint8(pred_mask[0].numpy())\n",
    "        y_test_mask[name] = pred_mask\n",
    "    return y_test_mask\n",
    "        \n",
    "def save_mask(mask_dict):\n",
    "    for name, mask in mask_dict.items():\n",
    "        im = PIL.Image.fromarray(mask)\n",
    "        im.save(test_y_loc + name + '.png')\n",
    "        print(\"Image saved: \", test_y_loc + name + '.png')\n",
    "\n",
    "preds = get_predictions(test_x_loc,test_img_names)\n",
    "masks = create_mask(preds)\n",
    "save_mask(masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the output for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 0/112\n",
      "Saving 1/112\n",
      "Saving 2/112\n",
      "Saving 3/112\n",
      "Saving 4/112\n",
      "Saving 5/112\n",
      "Saving 6/112\n",
      "Saving 7/112\n",
      "Saving 8/112\n",
      "Saving 9/112\n",
      "Saving 10/112\n",
      "Saving 11/112\n",
      "Saving 12/112\n",
      "Saving 13/112\n",
      "Saving 14/112\n",
      "Saving 15/112\n",
      "Saving 16/112\n",
      "Saving 17/112\n",
      "Saving 18/112\n",
      "Saving 19/112\n",
      "Saving 20/112\n",
      "Saving 21/112\n",
      "Saving 22/112\n",
      "Saving 23/112\n",
      "Saving 24/112\n",
      "Saving 25/112\n",
      "Saving 26/112\n",
      "Saving 27/112\n",
      "Saving 28/112\n",
      "Saving 29/112\n",
      "Saving 30/112\n",
      "Saving 31/112\n",
      "Saving 32/112\n",
      "Saving 33/112\n",
      "Saving 34/112\n",
      "Saving 35/112\n",
      "Saving 36/112\n",
      "Saving 37/112\n",
      "Saving 38/112\n",
      "Saving 39/112\n",
      "Saving 40/112\n",
      "Saving 41/112\n",
      "Saving 42/112\n",
      "Saving 43/112\n",
      "Saving 44/112\n",
      "Saving 45/112\n",
      "Saving 46/112\n",
      "Saving 47/112\n",
      "Saving 48/112\n",
      "Saving 49/112\n",
      "Saving 50/112\n",
      "Saving 51/112\n",
      "Saving 52/112\n",
      "Saving 53/112\n",
      "Saving 54/112\n",
      "Saving 55/112\n",
      "Saving 56/112\n",
      "Saving 57/112\n",
      "Saving 58/112\n",
      "Saving 59/112\n",
      "Saving 60/112\n",
      "Saving 61/112\n",
      "Saving 62/112\n",
      "Saving 63/112\n",
      "Saving 64/112\n",
      "Saving 65/112\n",
      "Saving 66/112\n",
      "Saving 67/112\n",
      "Saving 68/112\n",
      "Saving 69/112\n",
      "Saving 70/112\n",
      "Saving 71/112\n",
      "Saving 72/112\n",
      "Saving 73/112\n",
      "Saving 74/112\n",
      "Saving 75/112\n",
      "Saving 76/112\n",
      "Saving 77/112\n",
      "Saving 78/112\n",
      "Saving 79/112\n",
      "Saving 80/112\n",
      "Saving 81/112\n",
      "Saving 82/112\n",
      "Saving 83/112\n",
      "Saving 84/112\n",
      "Saving 85/112\n",
      "Saving 86/112\n",
      "Saving 87/112\n",
      "Saving 88/112\n",
      "Saving 89/112\n",
      "Saving 90/112\n",
      "Saving 91/112\n",
      "Saving 92/112\n",
      "Saving 93/112\n",
      "Saving 94/112\n",
      "Saving 95/112\n",
      "Saving 96/112\n",
      "Saving 97/112\n",
      "Saving 98/112\n",
      "Saving 99/112\n",
      "Saving 100/112\n",
      "Saving 101/112\n",
      "Saving 102/112\n",
      "Saving 103/112\n",
      "Saving 104/112\n",
      "Saving 105/112\n",
      "Saving 106/112\n",
      "Saving 107/112\n",
      "Saving 108/112\n",
      "Saving 109/112\n",
      "Saving 110/112\n",
      "Saving 111/112\n"
     ]
    }
   ],
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "\n",
    "def create_rles(test_pred_dir):\n",
    "    \"\"\"Used for Kaggle submission: predicts and encode all test images\"\"\"\n",
    "    N = len([i for i in list(os.listdir(test_pred_dir)) if i[-3:] == \"png\"])\n",
    "    with open('submissions/submission_file.csv', 'w') as f:\n",
    "        f.write('ImageClassId,rle_mask\\n')\n",
    "        for index, i in enumerate(os.listdir(test_pred_dir)):\n",
    "            if i[-3:] == \"png\":\n",
    "                print('Saving {}/{}'.format(index, N))\n",
    "                mask = PIL.Image.open(test_pred_dir + i)\n",
    "                mask = mask.resize((1024, 1024), resample= PIL.Image.NEAREST)\n",
    "                mask = np.array(mask)\n",
    "\n",
    "                for x in range(1, 25):\n",
    "                    enc = rle_encode(mask == x)\n",
    "                    f.write(f\"{i.split('_')[0]}_{x},{enc}\\n\")\n",
    "\n",
    "create_rles(test_y_loc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the output of the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for 1 images\n",
      "Predicting for img 6456\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Creating masks for 1 predictions\n",
      "dict_keys(['6456'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def visualise_test(image_name):\n",
    "\n",
    "    img1 = np.array(PIL.Image.open(test_x_loc + image_name +'.jpg').resize((INPUT_SIZE,INPUT_SIZE),resample=PIL.Image.NEAREST))/255\n",
    "    img2 = mpimg.imread(test_y_loc + image_name +'.png')\n",
    "    # mpimg.imread(test_x_loc + '6413.jpg')\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 15))\n",
    "    axs[0].imshow(img1)\n",
    "    axs[0].set_title('Processed Img')\n",
    "    axs[1].imshow(img2)\n",
    "    axs[1].set_title('Predicted img')\n",
    "    \n",
    "def visualise_train(image_name):\n",
    "\n",
    "    img1 = np.array(PIL.Image.open(train_x_loc + image_name +'.jpg').resize((INPUT_SIZE,INPUT_SIZE),resample=PIL.Image.NEAREST))/255\n",
    "    img2 = np.array(PIL.Image.open(train_y_loc + image_name + \".png\").resize((INPUT_SIZE,INPUT_SIZE),resample=PIL.Image.NEAREST))\n",
    "    # mpimg.imread(train_y_loc + image_name +'.png')\n",
    "    # mpimg.imread(test_x_loc + '6413.jpg')\n",
    "\n",
    "    img_name = [image_name]\n",
    "    pred = get_predictions(train_x_loc,img_name)\n",
    "    mask = create_mask(pred)\n",
    "    print(mask.keys())\n",
    "    img3 = mask[image_name]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 15))\n",
    "    axs[0].imshow(img1)\n",
    "    axs[0].set_title('Processed Img')\n",
    "    axs[1].imshow(img2)\n",
    "    axs[1].set_title('True Mask')\n",
    "    axs[2].imshow(img3)\n",
    "    axs[2].set_title('Predicted Mask')\n",
    "    \n",
    "assert(model is not None)\n",
    "# visualise_test('') # provide only image names from 'train_images'\n",
    "visualise_train('6456') # provide only image names from 'test_images'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "harvey-img-seg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
